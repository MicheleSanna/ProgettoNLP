Node IP: 10.128.2.151
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
  entrypoint       : train.py
  min_nodes        : 2
  max_nodes        : 2
  nproc_per_node   : 2
  run_id           : 18872
  rdzv_backend     : c10d
  rdzv_endpoint    : 10.128.2.151:29500
  rdzv_configs     : {'timeout': 900}
  max_restarts     : 0
  monitor_interval : 5
  log_dir          : None
  metrics_cfg      : {}

WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
  entrypoint       : train.py
  min_nodes        : 2
  max_nodes        : 2
  nproc_per_node   : 2
  run_id           : 18872
  rdzv_backend     : c10d
  rdzv_endpoint    : 10.128.2.151:29500
  rdzv_configs     : {'timeout': 900}
  max_restarts     : 0
  monitor_interval : 5
  log_dir          : None
  metrics_cfg      : {}

INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /tmp/torchelastic_90x6eyro/18872_b0vjd_se
INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /tmp/torchelastic_i1d9e4tg/18872_2dpfz1ux
INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
  restart_count=0
  master_addr=gpu001.hpc
  master_port=55573
  group_rank=0
  group_world_size=2
  local_ranks=[0, 1]
  role_ranks=[0, 1]
  global_ranks=[0, 1]
  role_world_sizes=[4, 4]
  global_world_sizes=[4, 4]

INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
  restart_count=0
  master_addr=gpu001.hpc
  master_port=55573
  group_rank=1
  group_world_size=2
  local_ranks=[0, 1]
  role_ranks=[2, 3]
  global_ranks=[2, 3]
  role_world_sizes=[4, 4]
  global_world_sizes=[4, 4]

INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_90x6eyro/18872_b0vjd_se/attempt_0/0/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /tmp/torchelastic_90x6eyro/18872_b0vjd_se/attempt_0/1/error.json
INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_i1d9e4tg/18872_2dpfz1ux/attempt_0/0/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /tmp/torchelastic_i1d9e4tg/18872_2dpfz1ux/attempt_0/1/error.json
/u/dssc/msanna00/.conda/envs/deeplearning3/lib/python3.7/site-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML
  warnings.warn("Can't initialize NVML")
/u/dssc/msanna00/.conda/envs/deeplearning3/lib/python3.7/site-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML
  warnings.warn("Can't initialize NVML")
PORT:  55573
WORLD SIZE:  4
MASTER NODE:  gpu001.hpc
My slurm id is:  1
My rank is:  3
PORT:  55573
WORLD SIZE:  4
MASTER NODE:  gpu001.hpc
My slurm id is:  1
My rank is:  2
PORT: PORT:   5557355573

WORLD SIZE: WORLD SIZE:   44

MASTER NODE: MASTER NODE:   gpu001.hpcgpu001.hpc

My slurm id is: My slurm id is:   00

My rank is: My rank is:   01

Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
------------------------

------------------------

Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
------------------------

------------------------

Loading checkpoint...
Loading checkpoint...
Loading checkpoint...
Loading checkpoint...
Retrieving epoch...
Loading model state...
Loading scheduler state...
Loading optmizer state...
LOADED!
I'm process 2 using GPU 0
Retrieving epoch...
Loading model state...
Loading scheduler state...
Loading optmizer state...
LOADED!
I'm process 3 using GPU 1
Retrieving epoch...
Loading model state...
Retrieving epoch...
Loading model state...
Loading scheduler state...
Loading optmizer state...
Loading scheduler state...
Loading optmizer state...
LOADED!
I'm process 0 using GPU 0
LOADED!
I'm process 1 using GPU 1
Labels:  tensor([3, 0, 0, 1, 0, 3, 0, 0, 3, 1, 4, 4, 4, 1, 2, 0], device='cuda:1')
Preds:  tensor([4, 0, 2, 1, 0, 2, 0, 1, 3, 1, 2, 3, 4, 1, 2, 0], device='cuda:1')
Outputs:  tensor([[    0.0004,     0.0006,     0.0145,     0.3833,     0.6012],
        [    0.6832,     0.2919,     0.0234,     0.0008,     0.0007],
        [    0.1754,     0.3506,     0.4461,     0.0267,     0.0011],
        [    0.3229,     0.5455,     0.1297,     0.0017,     0.0002],
        [    0.8291,     0.1504,     0.0204,     0.0001,     0.0000],
        [    0.0196,     0.1235,     0.6426,     0.2069,     0.0074],
        [    0.8989,     0.0953,     0.0058,     0.0000,     0.0000],
        [    0.2777,     0.6910,     0.0303,     0.0009,     0.0001],
        [    0.0000,     0.0015,     0.3596,     0.5866,     0.0523],
        [    0.2286,     0.4900,     0.2720,     0.0087,     0.0007],
        [    0.2704,     0.1530,     0.2870,     0.1310,     0.1587],
        [    0.0483,     0.0580,     0.4082,     0.4131,     0.0724],
        [    0.0003,     0.0002,     0.0040,     0.1706,     0.8248],
        [    0.2077,     0.6354,     0.1158,     0.0323,     0.0087],
        [    0.0015,     0.0863,     0.8877,     0.0243,     0.0002],
        [    0.9889,     0.0110,     0.0001,     0.0000,     0.0000]],
       device='cuda:1')
Metric:  tensor(0.6250, device='cuda:1')
------------------------
Labels:  tensor([3, 1, 1, 4, 0, 2, 4, 1, 3, 0, 2, 3, 2, 2, 4, 4], device='cuda:0')
Preds:  tensor([3, 0, 0, 4, 0, 2, 4, 1, 3, 0, 1, 4, 1, 2, 4, 4], device='cuda:0')
Outputs:  tensor([[    0.0000,     0.0011,     0.0369,     0.9618,     0.0001],
        [    0.4758,     0.4567,     0.0666,     0.0008,     0.0001],
        [    0.4460,     0.4315,     0.1182,     0.0040,     0.0003],
        [    0.0007,     0.0002,     0.0016,     0.0370,     0.9606],
        [    0.7507,     0.0960,     0.0799,     0.0401,     0.0332],
        [    0.0016,     0.0940,     0.8141,     0.0898,     0.0004],
        [    0.0021,     0.0010,     0.0069,     0.1715,     0.8185],
        [    0.4609,     0.5011,     0.0380,     0.0000,     0.0000],
        [    0.0001,     0.0010,     0.3002,     0.6761,     0.0227],
        [    0.5247,     0.2241,     0.2318,     0.0193,     0.0001],
        [    0.1954,     0.5572,     0.2437,     0.0033,     0.0003],
        [    0.0002,     0.0002,     0.0043,     0.2959,     0.6995],
        [    0.0688,     0.6566,     0.2730,     0.0015,     0.0000],
        [    0.0121,     0.0950,     0.5259,     0.3009,     0.0660],
        [    0.0001,     0.0002,     0.0109,     0.3510,     0.6377],
        [    0.0004,     0.0002,     0.0034,     0.1172,     0.8788]],
       device='cuda:0')
Metric:  tensor(0.6875, device='cuda:0')
------------------------
Labels:  tensor([2, 2, 1, 1, 1, 4, 4, 4, 3, 2, 0, 3, 3, 4, 0, 3], device='cuda:0')
Preds:  tensor([3, 3, 2, 1, 0, 4, 4, 4, 2, 2, 1, 2, 4, 4, 0, 3], device='cuda:0')
Outputs:  tensor([[    0.0001,     0.0004,     0.0342,     0.5531,     0.4122],
        [    0.0001,     0.0006,     0.0216,     0.6733,     0.3045],
        [    0.0074,     0.0571,     0.5437,     0.3376,     0.0542],
        [    0.1014,     0.6040,     0.2877,     0.0068,     0.0001],
        [    0.6898,     0.2844,     0.0247,     0.0008,     0.0003],
        [    0.0000,     0.0000,     0.0012,     0.0623,     0.9364],
        [    0.0003,     0.0001,     0.0014,     0.0326,     0.9656],
        [    0.0014,     0.0020,     0.0181,     0.1319,     0.8465],
        [    0.0053,     0.0326,     0.6441,     0.2727,     0.0453],
        [    0.0037,     0.0477,     0.5455,     0.3955,     0.0076],
        [    0.0492,     0.6287,     0.3009,     0.0184,     0.0027],
        [    0.0026,     0.0644,     0.7339,     0.1726,     0.0264],
        [    0.0001,     0.0003,     0.0063,     0.3256,     0.6677],
        [    0.0001,     0.0006,     0.0018,     0.0956,     0.9018],
        [    0.9484,     0.0509,     0.0007,     0.0000,     0.0000],
        [    0.0000,     0.0001,     0.0156,     0.8782,     0.1061]],
       device='cuda:0')
Metric:  tensor(0.5000, device='cuda:0')
------------------------
Labels:  tensor([0, 4, 2, 3, 0, 1, 2, 2, 3, 2, 2, 4, 4, 1, 1, 2], device='cuda:1')
Preds:  tensor([0, 4, 1, 4, 0, 2, 4, 2, 2, 2, 0, 4, 4, 1, 1, 4], device='cuda:1')
Outputs:  tensor([[    0.7834,     0.2058,     0.0108,     0.0001,     0.0000],
        [    0.0002,     0.0001,     0.0008,     0.0552,     0.9437],
        [    0.0327,     0.7971,     0.1391,     0.0270,     0.0041],
        [    0.0001,     0.0000,     0.0002,     0.0185,     0.9811],
        [    0.9931,     0.0053,     0.0005,     0.0002,     0.0009],
        [    0.0744,     0.3415,     0.4741,     0.1078,     0.0022],
        [    0.0009,     0.0053,     0.0788,     0.4405,     0.4745],
        [    0.0005,     0.0143,     0.5556,     0.4223,     0.0073],
        [    0.1014,     0.4293,     0.4337,     0.0351,     0.0005],
        [    0.0019,     0.0357,     0.5901,     0.3526,     0.0196],
        [    0.6567,     0.2964,     0.0456,     0.0009,     0.0004],
        [    0.0000,     0.0000,     0.0008,     0.0673,     0.9318],
        [    0.0003,     0.0000,     0.0001,     0.0007,     0.9989],
        [    0.0121,     0.5072,     0.4113,     0.0607,     0.0087],
        [    0.0021,     0.9956,     0.0016,     0.0006,     0.0001],
        [    0.0034,     0.0021,     0.0231,     0.3124,     0.6590]],
       device='cuda:1')
Metric:  tensor(0.5625, device='cuda:1')
------------------------
Labels:  tensor([0, 1, 4, 2, 3, 2, 1, 0, 2, 2, 2, 0, 2, 4, 3, 4], device='cuda:0')
Preds:  tensor([0, 1, 4, 1, 0, 2, 1, 0, 1, 3, 3, 0, 2, 4, 0, 4], device='cuda:0')
Outputs:  tensor([[    0.5262,     0.4492,     0.0246,     0.0001,     0.0000],
        [    0.1305,     0.8490,     0.0203,     0.0001,     0.0000],
        [    0.0001,     0.0002,     0.0084,     0.2127,     0.7786],
        [    0.3683,     0.5119,     0.1179,     0.0017,     0.0002],
        [    0.6072,     0.2703,     0.1166,     0.0055,     0.0004],
        [    0.0255,     0.0273,     0.9102,     0.0256,     0.0114],
        [    0.1707,     0.5014,     0.3269,     0.0010,     0.0000],
        [    0.9362,     0.0616,     0.0020,     0.0001,     0.0001],
        [    0.3513,     0.3824,     0.2505,     0.0133,     0.0025],
        [    0.0003,     0.0024,     0.1201,     0.6686,     0.2085],
        [    0.0018,     0.0329,     0.4503,     0.4689,     0.0461],
        [    0.9076,     0.0881,     0.0040,     0.0002,     0.0000],
        [    0.0007,     0.0233,     0.5426,     0.4270,     0.0065],
        [    0.0002,     0.0002,     0.0079,     0.2000,     0.7918],
        [    0.5933,     0.3329,     0.0733,     0.0005,     0.0000],
        [    0.0001,     0.0002,     0.0002,     0.0179,     0.9816]],
       device='cuda:0')
Metric:  tensor(0.6250, device='cuda:0')
------------------------
Labels:  tensor([3, 2, 3, 1, 3, 4, 3, 0, 3, 1, 1, 0, 0, 3, 2, 0], device='cuda:1')
Preds:  tensor([3, 2, 3, 1, 2, 4, 3, 1, 4, 1, 1, 0, 0, 3, 2, 2], device='cuda:1')
Outputs:  tensor([[    0.0008,     0.0055,     0.3596,     0.6280,     0.0060],
        [    0.0002,     0.0133,     0.6330,     0.3473,     0.0061],
        [    0.0008,     0.0193,     0.4243,     0.5497,     0.0058],
        [    0.3997,     0.4815,     0.1177,     0.0010,     0.0001],
        [    0.0007,     0.0335,     0.9444,     0.0208,     0.0005],
        [    0.0003,     0.0003,     0.0061,     0.1905,     0.8029],
        [    0.0094,     0.0555,     0.3861,     0.4920,     0.0569],
        [    0.1894,     0.5962,     0.2131,     0.0013,     0.0000],
        [    0.0000,     0.0001,     0.0032,     0.3185,     0.6783],
        [    0.1298,     0.5983,     0.2335,     0.0342,     0.0042],
        [    0.1632,     0.5299,     0.2992,     0.0073,     0.0003],
        [    0.9499,     0.0483,     0.0017,     0.0000,     0.0000],
        [    0.6132,     0.3291,     0.0543,     0.0030,     0.0004],
        [    0.0014,     0.0306,     0.4222,     0.5189,     0.0270],
        [    0.0928,     0.3404,     0.4519,     0.0935,     0.0214],
        [    0.0498,     0.2319,     0.5967,     0.1200,     0.0016]],
       device='cuda:1')
Metric:  tensor(0.7500, device='cuda:1')
------------------------
Labels:  tensor([2, 0, 4, 4, 4, 0, 0, 2, 4, 0, 4, 0, 0, 0, 1, 2], device='cuda:1')
Preds:  tensor([2, 0, 4, 4, 4, 0, 0, 2, 4, 1, 4, 4, 0, 0, 2, 4], device='cuda:1')
Outputs:  tensor([[    0.0109,     0.0253,     0.5071,     0.3895,     0.0671],
        [    0.5180,     0.4333,     0.0464,     0.0017,     0.0006],
        [    0.0002,     0.0008,     0.0002,     0.0137,     0.9851],
        [    0.0001,     0.0000,     0.0003,     0.0423,     0.9573],
        [    0.0005,     0.0007,     0.0112,     0.2221,     0.7655],
        [    0.6011,     0.3222,     0.0721,     0.0037,     0.0009],
        [    0.7558,     0.2102,     0.0320,     0.0019,     0.0001],
        [    0.0342,     0.2554,     0.6924,     0.0178,     0.0002],
        [    0.0002,     0.0007,     0.0217,     0.2906,     0.6869],
        [    0.0817,     0.5068,     0.4041,     0.0071,     0.0002],
        [    0.0006,     0.0005,     0.0088,     0.2140,     0.7761],
        [    0.0972,     0.0687,     0.0809,     0.1244,     0.6289],
        [    0.6098,     0.3658,     0.0223,     0.0006,     0.0015],
        [    0.9131,     0.0857,     0.0012,     0.0000,     0.0000],
        [    0.0122,     0.2794,     0.6876,     0.0207,     0.0000],
        [    0.1141,     0.1741,     0.2645,     0.1134,     0.3339]],
       device='cuda:1')
Metric:  tensor(0.7500, device='cuda:1')
------------------------
Labels:  tensor([1, 1, 1, 1, 2, 1, 0, 0, 4, 4, 2, 1, 3, 0, 0, 1], device='cuda:0')
Preds:  tensor([3, 1, 2, 4, 2, 1, 0, 0, 4, 4, 2, 0, 2, 0, 0, 1], device='cuda:0')
Outputs:  tensor([[    0.0009,     0.0138,     0.2910,     0.5529,     0.1415],
        [    0.3242,     0.3816,     0.2842,     0.0094,     0.0005],
        [    0.0399,     0.3377,     0.5815,     0.0397,     0.0012],
        [    0.1569,     0.0923,     0.1710,     0.2075,     0.3722],
        [    0.0139,     0.4492,     0.4732,     0.0609,     0.0028],
        [    0.0721,     0.4503,     0.4481,     0.0245,     0.0052],
        [    0.8873,     0.0986,     0.0112,     0.0011,     0.0017],
        [    0.7474,     0.2457,     0.0069,     0.0000,     0.0000],
        [    0.0012,     0.0005,     0.0042,     0.1724,     0.8217],
        [    0.0004,     0.0001,     0.0013,     0.0523,     0.9459],
        [    0.0045,     0.1099,     0.8076,     0.0778,     0.0002],
        [    0.5138,     0.3630,     0.1053,     0.0083,     0.0096],
        [    0.0001,     0.0035,     0.6312,     0.3652,     0.0000],
        [    0.6455,     0.3228,     0.0305,     0.0011,     0.0000],
        [    0.7284,     0.2240,     0.0425,     0.0029,     0.0021],
        [    0.1855,     0.5800,     0.2314,     0.0031,     0.0001]],
       device='cuda:0')
Metric:  tensor(0.6875, device='cuda:0')
------------------------
Labels:  tensor([3, 3, 3, 2, 1, 3, 1, 1, 2, 2, 0, 3, 3, 4, 4, 2], device='cuda:0')
Preds:  tensor([3, 2, 2, 2, 1, 3, 1, 0, 2, 2, 0, 4, 2, 4, 4, 0], device='cuda:0')
Outputs:  tensor([[    0.0001,     0.0003,     0.0154,     0.5477,     0.4365],
        [    0.0003,     0.0058,     0.8360,     0.1442,     0.0137],
        [    0.0007,     0.0204,     0.7464,     0.2280,     0.0045],
        [    0.0296,     0.1859,     0.6812,     0.1023,     0.0010],
        [    0.3804,     0.5697,     0.0490,     0.0008,     0.0001],
        [    0.0257,     0.0698,     0.3940,     0.3989,     0.1116],
        [    0.2506,     0.6422,     0.1062,     0.0010,     0.0000],
        [    0.9891,     0.0107,     0.0002,     0.0000,     0.0000],
        [    0.0004,     0.0089,     0.5534,     0.4177,     0.0196],
        [    0.0552,     0.2898,     0.4634,     0.1814,     0.0101],
        [    0.5867,     0.3546,     0.0585,     0.0002,     0.0000],
        [    0.0000,     0.0000,     0.0001,     0.0096,     0.9902],
        [    0.0010,     0.0457,     0.6980,     0.2527,     0.0025],
        [    0.0001,     0.0001,     0.0026,     0.1971,     0.8001],
        [    0.0027,     0.0023,     0.0304,     0.1517,     0.8129],
        [    0.8279,     0.1597,     0.0119,     0.0004,     0.0001]],
       device='cuda:0')
Metric:  tensor(0.6250, device='cuda:0')
------------------------
Labels:  tensor([2, 3, 4, 0, 1, 3, 4, 3, 4, 2, 1, 0, 4, 4, 4, 4], device='cuda:1')
Preds:  tensor([1, 3, 4, 1, 2, 4, 4, 2, 4, 2, 0, 0, 4, 4, 3, 4], device='cuda:1')
Outputs:  tensor([[    0.0367,     0.5582,     0.4020,     0.0030,     0.0001],
        [    0.0001,     0.0004,     0.0559,     0.7850,     0.1587],
        [    0.0017,     0.0007,     0.0018,     0.0139,     0.9819],
        [    0.2735,     0.6689,     0.0570,     0.0005,     0.0001],
        [    0.0508,     0.1902,     0.4065,     0.2839,     0.0686],
        [    0.0010,     0.0014,     0.0234,     0.2450,     0.7293],
        [    0.0007,     0.0001,     0.0009,     0.0093,     0.9890],
        [    0.0056,     0.2617,     0.7255,     0.0071,     0.0001],
        [    0.0001,     0.0003,     0.0001,     0.0013,     0.9982],
        [    0.0008,     0.0296,     0.7441,     0.2203,     0.0052],
        [    0.5373,     0.4122,     0.0492,     0.0010,     0.0003],
        [    0.7953,     0.1885,     0.0159,     0.0003,     0.0000],
        [    0.0001,     0.0001,     0.0014,     0.0738,     0.9246],
        [    0.0020,     0.0013,     0.0257,     0.4094,     0.5615],
        [    0.0022,     0.0064,     0.1232,     0.6121,     0.2560],
        [    0.0003,     0.0001,     0.0021,     0.1526,     0.8449]],
       device='cuda:1')
Metric:  tensor(0.5625, device='cuda:1')
------------------------
Labels:  tensor([3, 2, 3, 2, 3, 0, 2, 4, 1, 1, 1, 1, 0, 0, 0, 0], device='cuda:1')
Preds:  tensor([4, 2, 2, 2, 4, 0, 1, 4, 2, 0, 1, 2, 0, 0, 0, 0], device='cuda:1')
Outputs:  tensor([[    0.0005,     0.0006,     0.0151,     0.2158,     0.7681],
        [    0.0273,     0.1405,     0.6081,     0.2178,     0.0062],
        [    0.0008,     0.0253,     0.9500,     0.0237,     0.0001],
        [    0.0027,     0.0280,     0.9556,     0.0134,     0.0003],
        [    0.0002,     0.0002,     0.0032,     0.1653,     0.8312],
        [    0.7711,     0.2203,     0.0085,     0.0002,     0.0000],
        [    0.4184,     0.4273,     0.1448,     0.0086,     0.0010],
        [    0.0009,     0.0005,     0.0029,     0.1095,     0.8861],
        [    0.0064,     0.1075,     0.7306,     0.1467,     0.0087],
        [    0.7596,     0.1017,     0.0436,     0.0258,     0.0693],
        [    0.2552,     0.6135,     0.1305,     0.0008,     0.0000],
        [    0.3259,     0.2501,     0.3946,     0.0265,     0.0029],
        [    0.9959,     0.0026,     0.0009,     0.0002,     0.0004],
        [    0.7351,     0.2311,     0.0310,     0.0018,     0.0009],
        [    0.9846,     0.0152,     0.0001,     0.0000,     0.0000],
        [    0.9996,     0.0003,     0.0001,     0.0000,     0.0000]],
       device='cuda:1')
Metric:  tensor(0.5625, device='cuda:1')
------------------------
Labels:  tensor([4, 0, 4, 0, 4, 1, 1, 3, 0, 4, 4, 3, 0, 2, 3, 0], device='cuda:0')
Preds:  tensor([4, 0, 4, 0, 4, 1, 1, 4, 0, 3, 4, 3, 1, 1, 4, 0], device='cuda:0')
Outputs:  tensor([[    0.0005,     0.0002,     0.0042,     0.1470,     0.8481],
        [    0.7428,     0.2163,     0.0399,     0.0009,     0.0001],
        [    0.0004,     0.0003,     0.0073,     0.2925,     0.6994],
        [    0.8580,     0.1367,     0.0052,     0.0000,     0.0000],
        [    0.0310,     0.0223,     0.0799,     0.1958,     0.6710],
        [    0.0024,     0.9815,     0.0145,     0.0014,     0.0002],
        [    0.1261,     0.5341,     0.3325,     0.0071,     0.0003],
        [    0.0280,     0.2099,     0.1492,     0.2042,     0.4087],
        [    0.9894,     0.0102,     0.0004,     0.0000,     0.0000],
        [    0.0011,     0.0057,     0.1963,     0.4285,     0.3683],
        [    0.0001,     0.0018,     0.0033,     0.2116,     0.7832],
        [    0.0003,     0.0043,     0.3218,     0.6338,     0.0398],
        [    0.2939,     0.6587,     0.0473,     0.0001,     0.0000],
        [    0.1266,     0.4981,     0.3592,     0.0160,     0.0002],
        [    0.0001,     0.0001,     0.0036,     0.2915,     0.7047],
        [    0.9194,     0.0760,     0.0045,     0.0001,     0.0000]],
       device='cuda:0')
Metric:  tensor(0.6875, device='cuda:0')
------------------------
Labels:  tensor([4, 4, 4, 2, 3, 2, 4, 1, 2, 1, 1, 2, 0, 1, 0, 1], device='cuda:1')
Preds:  tensor([4, 4, 4, 1, 2, 3, 4, 1, 2, 2, 1, 2, 0, 0, 0, 2], device='cuda:1')
Outputs:  tensor([[    0.0001,     0.0003,     0.0101,     0.1346,     0.8549],
        [    0.0002,     0.0001,     0.0065,     0.2778,     0.7154],
        [    0.0002,     0.0001,     0.0012,     0.0374,     0.9611],
        [    0.1977,     0.5720,     0.2285,     0.0017,     0.0000],
        [    0.0028,     0.0231,     0.6251,     0.2866,     0.0624],
        [    0.0001,     0.0017,     0.0993,     0.7676,     0.1312],
        [    0.0009,     0.0003,     0.0012,     0.0076,     0.9900],
        [    0.1040,     0.5158,     0.3466,     0.0327,     0.0008],
        [    0.0012,     0.0882,     0.8740,     0.0365,     0.0001],
        [    0.0319,     0.2789,     0.6081,     0.0801,     0.0010],
        [    0.3130,     0.3409,     0.2806,     0.0627,     0.0028],
        [    0.0024,     0.1556,     0.8229,     0.0190,     0.0002],
        [    0.9930,     0.0069,     0.0001,     0.0000,     0.0000],
        [    0.6873,     0.2907,     0.0216,     0.0004,     0.0000],
        [    0.7771,     0.2143,     0.0084,     0.0002,     0.0000],
        [    0.0048,     0.0952,     0.7364,     0.1626,     0.0010]],
       device='cuda:1')
Metric:  tensor(0.6250, device='cuda:1')
------------------------
Labels:  tensor([4, 1, 1, 0, 0, 1, 2, 4, 2, 4, 4, 1, 0, 1, 2, 1], device='cuda:0')
Preds:  tensor([4, 1, 0, 0, 0, 1, 2, 4, 2, 4, 4, 0, 0, 0, 2, 0], device='cuda:0')
Outputs:  tensor([[    0.0008,     0.0006,     0.0023,     0.0630,     0.9332],
        [    0.2371,     0.6294,     0.1299,     0.0032,     0.0003],
        [    0.9582,     0.0410,     0.0008,     0.0000,     0.0000],
        [    0.8641,     0.1271,     0.0082,     0.0003,     0.0003],
        [    0.7849,     0.2041,     0.0104,     0.0004,     0.0002],
        [    0.0686,     0.6299,     0.3006,     0.0008,     0.0000],
        [    0.0589,     0.2827,     0.4864,     0.1527,     0.0194],
        [    0.0000,     0.0000,     0.0002,     0.1216,     0.8782],
        [    0.0167,     0.3421,     0.6235,     0.0177,     0.0000],
        [    0.0016,     0.0010,     0.0090,     0.3314,     0.6569],
        [    0.0102,     0.0078,     0.0354,     0.0616,     0.8851],
        [    0.4469,     0.0966,     0.0958,     0.1026,     0.2582],
        [    0.9121,     0.0864,     0.0014,     0.0000,     0.0000],
        [    0.5520,     0.3223,     0.1201,     0.0045,     0.0010],
        [    0.1167,     0.2698,     0.4849,     0.1203,     0.0082],
        [    0.5901,     0.3073,     0.0971,     0.0050,     0.0006]],
       device='cuda:0')
Metric:  tensor(0.7500, device='cuda:0')
------------------------
Labels:  tensor([1, 1, 2, 1, 1, 4, 1, 4, 4, 1, 3, 2, 4, 3, 3, 4], device='cuda:1')
Preds:  tensor([2, 1, 2, 0, 1, 4, 0, 3, 4, 1, 2, 2, 4, 2, 4, 4], device='cuda:1')
Outputs:  tensor([[    0.0397,     0.1666,     0.4744,     0.2470,     0.0724],
        [    0.1297,     0.4515,     0.3941,     0.0242,     0.0005],
        [    0.0292,     0.2363,     0.6191,     0.1152,     0.0002],
        [    0.6291,     0.2890,     0.0812,     0.0007,     0.0000],
        [    0.3065,     0.6090,     0.0841,     0.0003,     0.0000],
        [    0.0023,     0.0024,     0.0064,     0.0870,     0.9018],
        [    0.6488,     0.3164,     0.0336,     0.0009,     0.0002],
        [    0.0001,     0.0001,     0.0064,     0.5904,     0.4029],
        [    0.0011,     0.0006,     0.0021,     0.0470,     0.9492],
        [    0.3160,     0.5925,     0.0904,     0.0011,     0.0000],
        [    0.0092,     0.1175,     0.8123,     0.0610,     0.0001],
        [    0.0008,     0.1003,     0.7122,     0.1839,     0.0029],
        [    0.0002,     0.0003,     0.0037,     0.1500,     0.8458],
        [    0.0002,     0.0107,     0.6840,     0.2955,     0.0096],
        [    0.0004,     0.0003,     0.0111,     0.1260,     0.8622],
        [    0.0001,     0.0003,     0.0122,     0.4320,     0.5553]],
       device='cuda:1')
Metric:  tensor(0.5625, device='cuda:1')
------------------------
Labels:  tensor([2, 0, 1, 3, 4, 2, 0, 0, 2, 1, 0, 1, 1, 2, 3, 4], device='cuda:0')
Preds:  tensor([4, 0, 2, 2, 4, 2, 1, 0, 1, 0, 0, 0, 0, 1, 4, 4], device='cuda:0')
Outputs:  tensor([[    0.0001,     0.0001,     0.0029,     0.1773,     0.8197],
        [    0.8379,     0.1444,     0.0171,     0.0004,     0.0001],
        [    0.0016,     0.0580,     0.8535,     0.0867,     0.0001],
        [    0.0007,     0.0467,     0.9239,     0.0285,     0.0001],
        [    0.0020,     0.0007,     0.0038,     0.0320,     0.9615],
        [    0.0048,     0.1848,     0.6285,     0.1799,     0.0019],
        [    0.4075,     0.4944,     0.0968,     0.0012,     0.0000],
        [    0.8230,     0.1472,     0.0295,     0.0003,     0.0000],
        [    0.0413,     0.7891,     0.1492,     0.0186,     0.0017],
        [    0.5409,     0.3473,     0.0979,     0.0087,     0.0051],
        [    0.9934,     0.0065,     0.0001,     0.0000,     0.0000],
        [    0.6669,     0.2484,     0.0809,     0.0038,     0.0000],
        [    0.7970,     0.1411,     0.0550,     0.0051,     0.0018],
        [    0.0181,     0.7984,     0.1580,     0.0238,     0.0016],
        [    0.0010,     0.0030,     0.0583,     0.3772,     0.5605],
        [    0.0001,     0.0001,     0.0001,     0.0412,     0.9585]],
       device='cuda:0')
Metric:  tensor(0.3750, device='cuda:0')
------------------------
Labels:  tensor([4, 4, 2, 0, 0, 4, 4, 1, 4, 2, 0, 1, 1, 2, 2, 1], device='cuda:1')
Preds:  tensor([4, 4, 1, 3, 0, 4, 4, 1, 4, 2, 3, 1, 2, 1, 2, 2], device='cuda:1')
Outputs:  tensor([[    0.0010,     0.0004,     0.0061,     0.0923,     0.9002],
        [    0.0011,     0.0007,     0.0046,     0.1337,     0.8599],
        [    0.4297,     0.4984,     0.0691,     0.0026,     0.0002],
        [    0.0005,     0.0028,     0.0970,     0.5488,     0.3509],
        [    0.4560,     0.1939,     0.2311,     0.0704,     0.0486],
        [    0.0020,     0.0012,     0.0044,     0.0352,     0.9572],
        [    0.0008,     0.0005,     0.0074,     0.1932,     0.7981],
        [    0.1927,     0.6393,     0.1671,     0.0009,     0.0000],
        [    0.0001,     0.0002,     0.0077,     0.1984,     0.7936],
        [    0.0554,     0.1984,     0.5766,     0.1616,     0.0081],
        [    0.0007,     0.0107,     0.3281,     0.5917,     0.0689],
        [    0.3098,     0.3726,     0.2480,     0.0537,     0.0160],
        [    0.0030,     0.0706,     0.9069,     0.0192,     0.0003],
        [    0.1911,     0.5328,     0.2671,     0.0089,     0.0001],
        [    0.0291,     0.3266,     0.4276,     0.2027,     0.0140],
        [    0.0182,     0.3365,     0.6234,     0.0216,     0.0004]],
       device='cuda:1')
Metric:  tensor(0.6250, device='cuda:1')
------------------------
Mean loss[0.9300561165187113] | Mean metric[0.6012384089799903]
Stupid loss[0.0] | Naive soulution metric[0.2]
Freezed:  module.transformer.wte.weight
Freezed:  module.transformer.wpe.weight
Freezed:  module.transformer.h.0.ln_1.weight
Freezed:  module.transformer.h.0.ln_1.bias
Freezed:  module.transformer.h.0.attn.c_attn.weight
Freezed:  module.transformer.h.0.attn.c_attn.bias
Freezed:  module.transformer.h.0.attn.c_proj.weight
Freezed:  module.transformer.h.0.attn.c_proj.bias
Freezed:  module.transformer.h.0.ln_2.weight
Freezed:  module.transformer.h.0.ln_2.bias
Freezed:  module.transformer.h.0.mlp.c_fc.weight
Freezed:  module.transformer.h.0.mlp.c_fc.bias
Freezed:  module.transformer.h.0.mlp.c_proj.weight
Freezed:  module.transformer.h.0.mlp.c_proj.bias
Freezed:  module.transformer.h.1.ln_1.weight
Freezed:  module.transformer.h.1.ln_1.bias
Freezed:  module.transformer.h.1.attn.c_attn.weight
Freezed:  module.transformer.h.1.attn.c_attn.bias
Freezed:  module.transformer.h.1.attn.c_proj.weight
Freezed:  module.transformer.h.1.attn.c_proj.bias
Freezed:  module.transformer.h.1.ln_2.weight
Freezed:  module.transformer.h.1.ln_2.bias
Freezed:  module.transformer.h.1.mlp.c_fc.weight
Freezed:  module.transformer.h.1.mlp.c_fc.bias
Freezed:  module.transformer.h.1.mlp.c_proj.weight
Freezed:  module.transformer.h.1.mlp.c_proj.bias
Freezed:  module.transformer.h.2.ln_1.weight
Freezed:  module.transformer.h.2.ln_1.bias
Freezed:  module.transformer.h.2.attn.c_attn.weight
Freezed:  module.transformer.h.2.attn.c_attn.bias
Freezed:  module.transformer.h.2.attn.c_proj.weight
Freezed:  module.transformer.h.2.attn.c_proj.bias
Freezed:  module.transformer.h.2.ln_2.weight
Freezed:  module.transformer.h.2.ln_2.bias
Freezed:  module.transformer.h.2.mlp.c_fc.weight
Freezed:  module.transformer.h.2.mlp.c_fc.bias
Freezed:  module.transformer.h.2.mlp.c_proj.weight
Freezed:  module.transformer.h.2.mlp.c_proj.bias
Freezed:  module.transformer.h.3.ln_1.weight
Freezed:  module.transformer.h.3.ln_1.bias
Freezed:  module.transformer.h.3.attn.c_attn.weight
Freezed:  module.transformer.h.3.attn.c_attn.bias
Freezed:  module.transformer.h.3.attn.c_proj.weight
Freezed:  module.transformer.h.3.attn.c_proj.bias
Freezed:  module.transformer.h.3.ln_2.weight
Freezed:  module.transformer.h.3.ln_2.bias
Freezed:  module.transformer.h.3.mlp.c_fc.weight
Freezed:  module.transformer.h.3.mlp.c_fc.bias
Freezed:  module.transformer.h.3.mlp.c_proj.weight
Freezed:  module.transformer.h.3.mlp.c_proj.bias
Freezed:  module.transformer.h.4.ln_1.weight
Freezed:  module.transformer.h.4.ln_1.bias
Freezed:  module.transformer.h.4.attn.c_attn.weight
Freezed:  module.transformer.h.4.attn.c_attn.bias
Freezed:  module.transformer.h.4.attn.c_proj.weight
Freezed:  module.transformer.h.4.attn.c_proj.bias
Freezed:  module.transformer.h.4.ln_2.weight
Freezed:  module.transformer.h.4.ln_2.bias
Freezed:  module.transformer.h.4.mlp.c_fc.weight
Freezed:  module.transformer.h.4.mlp.c_fc.bias
Freezed:  module.transformer.h.4.mlp.c_proj.weight
Freezed:  module.transformer.h.4.mlp.c_proj.bias
Freezed:  module.transformer.h.5.ln_1.weight
Freezed:  module.transformer.h.5.ln_1.bias
Freezed:  module.transformer.h.5.attn.c_attn.weight
Freezed:  module.transformer.h.5.attn.c_attn.bias
Freezed:  module.transformer.h.5.attn.c_proj.weight
Freezed:  module.transformer.h.5.attn.c_proj.bias
Freezed:  module.transformer.h.5.ln_2.weight
Freezed:  module.transformer.h.5.ln_2.bias
Freezed:  module.transformer.h.5.mlp.c_fc.weight
Freezed:  module.transformer.h.5.mlp.c_fc.bias
Freezed:  module.transformer.h.5.mlp.c_proj.weight
Freezed:  module.transformer.h.5.mlp.c_proj.bias
EPOCH 4
--------------
Labels:  tensor([1, 1, 2, 4, 2, 4, 0, 2, 3, 2, 0, 1, 1, 3, 2, 0], device='cuda:0')
Preds:  tensor([1, 2, 2, 4, 0, 4, 0, 4, 4, 2, 0, 2, 0, 3, 4, 1], device='cuda:0')
Outputs:  tensor([[    0.2539,     0.5352,     0.2104,     0.0005,     0.0000],
        [    0.0888,     0.3619,     0.4273,     0.0851,     0.0370],
        [    0.0001,     0.0028,     0.9957,     0.0014,     0.0000],
        [    0.0001,     0.0002,     0.0003,     0.0466,     0.9528],
        [    0.7471,     0.1827,     0.0664,     0.0034,     0.0004],
        [    0.0003,     0.0001,     0.0004,     0.0154,     0.9838],
        [    0.9830,     0.0168,     0.0001,     0.0000,     0.0000],
        [    0.0001,     0.0000,     0.0013,     0.1139,     0.8847],
        [    0.0000,     0.0000,     0.0033,     0.3747,     0.6219],
        [    0.0581,     0.4051,     0.5317,     0.0050,     0.0000],
        [    0.4068,     0.3372,     0.2150,     0.0403,     0.0007],
        [    0.0120,     0.1799,     0.7212,     0.0856,     0.0013],
        [    0.7180,     0.2156,     0.0400,     0.0076,     0.0188],
        [    0.0017,     0.0026,     0.0395,     0.5978,     0.3584],
        [    0.0088,     0.0018,     0.0052,     0.0204,     0.9638],
        [    0.0889,     0.5615,     0.3355,     0.0141,     0.0001]],
       device='cuda:0')
Metric:  tensor(0.5000, device='cuda:0')
------------------------
Mean loss[0.9332406294380763] | Mean metric[0.6061188384577842]
Stupid loss[0.0] | Naive soulution metric[0.2]
Freezed:  module.transformer.wte.weight
Freezed:  module.transformer.wpe.weight
Freezed:  module.transformer.h.0.ln_1.weight
Freezed:  module.transformer.h.0.ln_1.bias
Freezed:  module.transformer.h.0.attn.c_attn.weight
Freezed:  module.transformer.h.0.attn.c_attn.bias
Freezed:  module.transformer.h.0.attn.c_proj.weight
Freezed:  module.transformer.h.0.attn.c_proj.bias
Freezed:  module.transformer.h.0.ln_2.weight
Freezed:  module.transformer.h.0.ln_2.bias
Freezed:  module.transformer.h.0.mlp.c_fc.weight
Freezed:  module.transformer.h.0.mlp.c_fc.bias
Freezed:  module.transformer.h.0.mlp.c_proj.weight
Freezed:  module.transformer.h.0.mlp.c_proj.bias
Freezed:  module.transformer.h.1.ln_1.weight
Freezed:  module.transformer.h.1.ln_1.bias
Freezed:  module.transformer.h.1.attn.c_attn.weight
Freezed:  module.transformer.h.1.attn.c_attn.bias
Freezed:  module.transformer.h.1.attn.c_proj.weight
Freezed:  module.transformer.h.1.attn.c_proj.bias
Freezed:  module.transformer.h.1.ln_2.weight
Freezed:  module.transformer.h.1.ln_2.bias
Freezed:  module.transformer.h.1.mlp.c_fc.weight
Freezed:  module.transformer.h.1.mlp.c_fc.bias
Freezed:  module.transformer.h.1.mlp.c_proj.weight
Freezed:  module.transformer.h.1.mlp.c_proj.bias
Freezed:  module.transformer.h.2.ln_1.weight
Freezed:  module.transformer.h.2.ln_1.bias
Freezed:  module.transformer.h.2.attn.c_attn.weight
Freezed:  module.transformer.h.2.attn.c_attn.bias
Freezed:  module.transformer.h.2.attn.c_proj.weight
Freezed:  module.transformer.h.2.attn.c_proj.bias
Freezed:  module.transformer.h.2.ln_2.weight
Freezed:  module.transformer.h.2.ln_2.bias
Freezed:  module.transformer.h.2.mlp.c_fc.weight
Freezed:  module.transformer.h.2.mlp.c_fc.bias
Freezed:  module.transformer.h.2.mlp.c_proj.weight
Freezed:  module.transformer.h.2.mlp.c_proj.bias
Freezed:  module.transformer.h.3.ln_1.weight
Freezed:  module.transformer.h.3.ln_1.bias
Freezed:  module.transformer.h.3.attn.c_attn.weight
Freezed:  module.transformer.h.3.attn.c_attn.bias
Freezed:  module.transformer.h.3.attn.c_proj.weight
Freezed:  module.transformer.h.3.attn.c_proj.bias
Freezed:  module.transformer.h.3.ln_2.weight
Freezed:  module.transformer.h.3.ln_2.bias
Freezed:  module.transformer.h.3.mlp.c_fc.weight
Freezed:  module.transformer.h.3.mlp.c_fc.bias
Freezed:  module.transformer.h.3.mlp.c_proj.weight
Freezed:  module.transformer.h.3.mlp.c_proj.bias
Freezed:  module.transformer.h.4.ln_1.weight
Freezed:  module.transformer.h.4.ln_1.bias
Freezed:  module.transformer.h.4.attn.c_attn.weight
Freezed:  module.transformer.h.4.attn.c_attn.bias
Freezed:  module.transformer.h.4.attn.c_proj.weight
Freezed:  module.transformer.h.4.attn.c_proj.bias
Freezed:  module.transformer.h.4.ln_2.weight
Freezed:  module.transformer.h.4.ln_2.bias
Freezed:  module.transformer.h.4.mlp.c_fc.weight
Freezed:  module.transformer.h.4.mlp.c_fc.bias
Freezed:  module.transformer.h.4.mlp.c_proj.weight
Freezed:  module.transformer.h.4.mlp.c_proj.bias
Freezed:  module.transformer.h.5.ln_1.weight
Freezed:  module.transformer.h.5.ln_1.bias
Freezed:  module.transformer.h.5.attn.c_attn.weight
Freezed:  module.transformer.h.5.attn.c_attn.bias
Freezed:  module.transformer.h.5.attn.c_proj.weight
Freezed:  module.transformer.h.5.attn.c_proj.bias
Freezed:  module.transformer.h.5.ln_2.weight
Freezed:  module.transformer.h.5.ln_2.bias
Freezed:  module.transformer.h.5.mlp.c_fc.weight
Freezed:  module.transformer.h.5.mlp.c_fc.bias
Freezed:  module.transformer.h.5.mlp.c_proj.weight
Freezed:  module.transformer.h.5.mlp.c_proj.bias
EPOCH 4
--------------
Labels:  tensor([0, 4, 0, 3, 0, 1, 2, 1, 4, 2, 1, 1, 4, 3, 1, 3], device='cuda:1')
Preds:  tensor([0, 4, 0, 3, 0, 0, 2, 2, 3, 3, 1, 2, 4, 3, 1, 2], device='cuda:1')
Outputs:  tensor([[    0.5339,     0.4471,     0.0168,     0.0005,     0.0017],
        [    0.0007,     0.0014,     0.0085,     0.1036,     0.8858],
        [    0.8690,     0.1163,     0.0130,     0.0014,     0.0002],
        [    0.0000,     0.0004,     0.0439,     0.7526,     0.2031],
        [    0.8435,     0.1547,     0.0018,     0.0000,     0.0000],
        [    0.6450,     0.3105,     0.0430,     0.0015,     0.0001],
        [    0.1392,     0.3631,     0.4062,     0.0696,     0.0217],
        [    0.0258,     0.4016,     0.5570,     0.0150,     0.0006],
        [    0.0390,     0.0796,     0.3871,     0.4298,     0.0644],
        [    0.0003,     0.0053,     0.3184,     0.5996,     0.0765],
        [    0.0273,     0.5774,     0.3826,     0.0121,     0.0006],
        [    0.0105,     0.1496,     0.7514,     0.0860,     0.0025],
        [    0.0002,     0.0001,     0.0016,     0.2146,     0.7834],
        [    0.0000,     0.0001,     0.0435,     0.8942,     0.0622],
        [    0.0826,     0.4626,     0.4393,     0.0145,     0.0009],
        [    0.0053,     0.2746,     0.3823,     0.2985,     0.0393]],
       device='cuda:1')
Metric:  tensor(0.6250, device='cuda:1')
------------------------
Mean loss[0.9261952450270767] | Mean metric[0.6032210834553441]
Stupid loss[0.0] | Naive soulution metric[0.2]
Freezed:  module.transformer.wte.weight
Freezed:  module.transformer.wpe.weight
Freezed:  module.transformer.h.0.ln_1.weight
Freezed:  module.transformer.h.0.ln_1.bias
Freezed:  module.transformer.h.0.attn.c_attn.weight
Freezed:  module.transformer.h.0.attn.c_attn.bias
Freezed:  module.transformer.h.0.attn.c_proj.weight
Freezed:  module.transformer.h.0.attn.c_proj.bias
Freezed:  module.transformer.h.0.ln_2.weight
Freezed:  module.transformer.h.0.ln_2.bias
Freezed:  module.transformer.h.0.mlp.c_fc.weight
Freezed:  module.transformer.h.0.mlp.c_fc.bias
Freezed:  module.transformer.h.0.mlp.c_proj.weight
Freezed:  module.transformer.h.0.mlp.c_proj.bias
Freezed:  module.transformer.h.1.ln_1.weight
Freezed:  module.transformer.h.1.ln_1.bias
Freezed:  module.transformer.h.1.attn.c_attn.weight
Freezed:  module.transformer.h.1.attn.c_attn.bias
Freezed:  module.transformer.h.1.attn.c_proj.weight
Freezed:  module.transformer.h.1.attn.c_proj.bias
Freezed:  module.transformer.h.1.ln_2.weight
Freezed:  module.transformer.h.1.ln_2.bias
Freezed:  module.transformer.h.1.mlp.c_fc.weight
Freezed:  module.transformer.h.1.mlp.c_fc.bias
Freezed:  module.transformer.h.1.mlp.c_proj.weight
Freezed:  module.transformer.h.1.mlp.c_proj.bias
Freezed:  module.transformer.h.2.ln_1.weight
Freezed:  module.transformer.h.2.ln_1.bias
Freezed:  module.transformer.h.2.attn.c_attn.weight
Freezed:  module.transformer.h.2.attn.c_attn.bias
Freezed:  module.transformer.h.2.attn.c_proj.weight
Freezed:  module.transformer.h.2.attn.c_proj.bias
Freezed:  module.transformer.h.2.ln_2.weight
Freezed:  module.transformer.h.2.ln_2.bias
Freezed:  module.transformer.h.2.mlp.c_fc.weight
Freezed:  module.transformer.h.2.mlp.c_fc.bias
Freezed:  module.transformer.h.2.mlp.c_proj.weight
Freezed:  module.transformer.h.2.mlp.c_proj.bias
Freezed:  module.transformer.h.3.ln_1.weight
Freezed:  module.transformer.h.3.ln_1.bias
Freezed:  module.transformer.h.3.attn.c_attn.weight
Freezed:  module.transformer.h.3.attn.c_attn.bias
Freezed:  module.transformer.h.3.attn.c_proj.weight
Freezed:  module.transformer.h.3.attn.c_proj.bias
Freezed:  module.transformer.h.3.ln_2.weight
Freezed:  module.transformer.h.3.ln_2.bias
Freezed:  module.transformer.h.3.mlp.c_fc.weight
Freezed:  module.transformer.h.3.mlp.c_fc.bias
Freezed:  module.transformer.h.3.mlp.c_proj.weight
Freezed:  module.transformer.h.3.mlp.c_proj.bias
Freezed:  module.transformer.h.4.ln_1.weight
Freezed:  module.transformer.h.4.ln_1.bias
Freezed:  module.transformer.h.4.attn.c_attn.weight
Freezed:  module.transformer.h.4.attn.c_attn.bias
Freezed:  module.transformer.h.4.attn.c_proj.weight
Freezed:  module.transformer.h.4.attn.c_proj.bias
Freezed:  module.transformer.h.4.ln_2.weight
Freezed:  module.transformer.h.4.ln_2.bias
Freezed:  module.transformer.h.4.mlp.c_fc.weight
Freezed:  module.transformer.h.4.mlp.c_fc.bias
Freezed:  module.transformer.h.4.mlp.c_proj.weight
Freezed:  module.transformer.h.4.mlp.c_proj.bias
Freezed:  module.transformer.h.5.ln_1.weight
Freezed:  module.transformer.h.5.ln_1.bias
Freezed:  module.transformer.h.5.attn.c_attn.weight
Freezed:  module.transformer.h.5.attn.c_attn.bias
Freezed:  module.transformer.h.5.attn.c_proj.weight
Freezed:  module.transformer.h.5.attn.c_proj.bias
Freezed:  module.transformer.h.5.ln_2.weight
Freezed:  module.transformer.h.5.ln_2.bias
Freezed:  module.transformer.h.5.mlp.c_fc.weight
Freezed:  module.transformer.h.5.mlp.c_fc.bias
Freezed:  module.transformer.h.5.mlp.c_proj.weight
Freezed:  module.transformer.h.5.mlp.c_proj.bias
EPOCH 4
--------------
Labels:  tensor([4, 2, 2, 0, 0, 3, 3, 0, 0, 0, 0, 1, 4, 2, 0, 4], device='cuda:0')
Preds:  tensor([4, 4, 2, 0, 0, 3, 3, 1, 0, 0, 4, 0, 3, 2, 0, 4], device='cuda:0')
Outputs:  tensor([[    0.0000,     0.0002,     0.0007,     0.1021,     0.8969],
        [    0.0007,     0.0014,     0.0206,     0.2539,     0.7234],
        [    0.0777,     0.3354,     0.4856,     0.0983,     0.0030],
        [    0.9704,     0.0290,     0.0006,     0.0000,     0.0000],
        [    0.6385,     0.3452,     0.0158,     0.0003,     0.0002],
        [    0.0001,     0.0000,     0.0008,     0.9969,     0.0023],
        [    0.0000,     0.0010,     0.1661,     0.8051,     0.0278],
        [    0.2419,     0.6679,     0.0747,     0.0073,     0.0081],
        [    0.8543,     0.1453,     0.0004,     0.0000,     0.0000],
        [    0.8338,     0.1561,     0.0096,     0.0002,     0.0003],
        [    0.0748,     0.0924,     0.0208,     0.1213,     0.6907],
        [    0.7219,     0.2674,     0.0103,     0.0003,     0.0001],
        [    0.0008,     0.0021,     0.0203,     0.8158,     0.1609],
        [    0.2169,     0.2833,     0.3465,     0.0892,     0.0641],
        [    0.7527,     0.2148,     0.0293,     0.0022,     0.0010],
        [    0.0000,     0.0001,     0.0007,     0.0985,     0.9007]],
       device='cuda:0')
Metric:  tensor(0.6875, device='cuda:0')
------------------------
Mean loss[0.9338012269614905] | Mean metric[0.602214494875549]
Stupid loss[0.0] | Naive soulution metric[0.2]
Freezed:  module.transformer.wte.weight
Freezed:  module.transformer.wpe.weight
Freezed:  module.transformer.h.0.ln_1.weight
Freezed:  module.transformer.h.0.ln_1.bias
Freezed:  module.transformer.h.0.attn.c_attn.weight
Freezed:  module.transformer.h.0.attn.c_attn.bias
Freezed:  module.transformer.h.0.attn.c_proj.weight
Freezed:  module.transformer.h.0.attn.c_proj.bias
Freezed:  module.transformer.h.0.ln_2.weight
Freezed:  module.transformer.h.0.ln_2.bias
Freezed:  module.transformer.h.0.mlp.c_fc.weight
Freezed:  module.transformer.h.0.mlp.c_fc.bias
Freezed:  module.transformer.h.0.mlp.c_proj.weight
Freezed:  module.transformer.h.0.mlp.c_proj.bias
Freezed:  module.transformer.h.1.ln_1.weight
Freezed:  module.transformer.h.1.ln_1.bias
Freezed:  module.transformer.h.1.attn.c_attn.weight
Freezed:  module.transformer.h.1.attn.c_attn.bias
Freezed:  module.transformer.h.1.attn.c_proj.weight
Freezed:  module.transformer.h.1.attn.c_proj.bias
Freezed:  module.transformer.h.1.ln_2.weight
Freezed:  module.transformer.h.1.ln_2.bias
Freezed:  module.transformer.h.1.mlp.c_fc.weight
Freezed:  module.transformer.h.1.mlp.c_fc.bias
Freezed:  module.transformer.h.1.mlp.c_proj.weight
Freezed:  module.transformer.h.1.mlp.c_proj.bias
Freezed:  module.transformer.h.2.ln_1.weight
Freezed:  module.transformer.h.2.ln_1.bias
Freezed:  module.transformer.h.2.attn.c_attn.weight
Freezed:  module.transformer.h.2.attn.c_attn.bias
Freezed:  module.transformer.h.2.attn.c_proj.weight
Freezed:  module.transformer.h.2.attn.c_proj.bias
Freezed:  module.transformer.h.2.ln_2.weight
Freezed:  module.transformer.h.2.ln_2.bias
Freezed:  module.transformer.h.2.mlp.c_fc.weight
Freezed:  module.transformer.h.2.mlp.c_fc.bias
Freezed:  module.transformer.h.2.mlp.c_proj.weight
Freezed:  module.transformer.h.2.mlp.c_proj.bias
Freezed:  module.transformer.h.3.ln_1.weight
Freezed:  module.transformer.h.3.ln_1.bias
Freezed:  module.transformer.h.3.attn.c_attn.weight
Freezed:  module.transformer.h.3.attn.c_attn.bias
Freezed:  module.transformer.h.3.attn.c_proj.weight
Freezed:  module.transformer.h.3.attn.c_proj.bias
Freezed:  module.transformer.h.3.ln_2.weight
Freezed:  module.transformer.h.3.ln_2.bias
Freezed:  module.transformer.h.3.mlp.c_fc.weight
Freezed:  module.transformer.h.3.mlp.c_fc.bias
Freezed:  module.transformer.h.3.mlp.c_proj.weight
Freezed:  module.transformer.h.3.mlp.c_proj.bias
Freezed:  module.transformer.h.4.ln_1.weight
Freezed:  module.transformer.h.4.ln_1.bias
Freezed:  module.transformer.h.4.attn.c_attn.weight
Freezed:  module.transformer.h.4.attn.c_attn.bias
Freezed:  module.transformer.h.4.attn.c_proj.weight
Freezed:  module.transformer.h.4.attn.c_proj.bias
Freezed:  module.transformer.h.4.ln_2.weight
Freezed:  module.transformer.h.4.ln_2.bias
Freezed:  module.transformer.h.4.mlp.c_fc.weight
Freezed:  module.transformer.h.4.mlp.c_fc.bias
Freezed:  module.transformer.h.4.mlp.c_proj.weight
Freezed:  module.transformer.h.4.mlp.c_proj.bias
Freezed:  module.transformer.h.5.ln_1.weight
Freezed:  module.transformer.h.5.ln_1.bias
Freezed:  module.transformer.h.5.attn.c_attn.weight
Freezed:  module.transformer.h.5.attn.c_attn.bias
Freezed:  module.transformer.h.5.attn.c_proj.weight
Freezed:  module.transformer.h.5.attn.c_proj.bias
Freezed:  module.transformer.h.5.ln_2.weight
Freezed:  module.transformer.h.5.ln_2.bias
Freezed:  module.transformer.h.5.mlp.c_fc.weight
Freezed:  module.transformer.h.5.mlp.c_fc.bias
Freezed:  module.transformer.h.5.mlp.c_proj.weight
Freezed:  module.transformer.h.5.mlp.c_proj.bias
EPOCH 4
--------------
Step[500] | Loss[0.640572190284729] | Lr[8.000000000000003e-08]Step[500] | Loss[0.6709146499633789] | Lr[8.000000000000003e-08]

Step[500] | Loss[0.4747394323348999] | Lr[8.000000000000003e-08]
Step[500] | Loss[0.7365092635154724] | Lr[8.000000000000003e-08]
Step[1000] | Loss[0.640936017036438] | Lr[8.000000000000003e-08]
Step[1000] | Loss[0.7414892911911011] | Lr[8.000000000000003e-08]
Step[1000] | Loss[0.7565967440605164] | Lr[8.000000000000003e-08]
Step[1000] | Loss[0.8163073658943176] | Lr[8.000000000000003e-08]
Step[1500] | Loss[0.6249296069145203] | Lr[8.000000000000003e-08]Step[1500] | Loss[0.6935697793960571] | Lr[8.000000000000003e-08]

Step[1500] | Loss[0.5859066247940063] | Lr[8.000000000000003e-08]
Step[1500] | Loss[0.861240565776825] | Lr[8.000000000000003e-08]
Step[2000] | Loss[1.0844920873641968] | Lr[8.000000000000003e-08]
Step[2000] | Loss[0.6434078216552734] | Lr[8.000000000000003e-08]
Step[2000] | Loss[0.6698441505432129] | Lr[8.000000000000003e-08]
Step[2000] | Loss[0.4992302656173706] | Lr[8.000000000000003e-08]
Step[2500] | Loss[0.8335060477256775] | Lr[8.000000000000003e-08]
Step[2500] | Loss[0.5578032732009888] | Lr[8.000000000000003e-08]
Step[2500] | Loss[0.717386782169342] | Lr[8.000000000000003e-08]Step[2500] | Loss[0.6267077922821045] | Lr[8.000000000000003e-08]

Step[3000] | Loss[0.7986853718757629] | Lr[8.000000000000003e-08]
Step[3000] | Loss[0.7553583979606628] | Lr[8.000000000000003e-08]
Step[3000] | Loss[0.8664713501930237] | Lr[8.000000000000003e-08]
Step[3000] | Loss[0.6616714596748352] | Lr[8.000000000000003e-08]
Step[3500] | Loss[0.8212478160858154] | Lr[8.000000000000003e-08]Step[3500] | Loss[0.6371975541114807] | Lr[8.000000000000003e-08]

Step[3500] | Loss[0.3404019773006439] | Lr[8.000000000000003e-08]
Step[3500] | Loss[0.48853111267089844] | Lr[8.000000000000003e-08]
Step[4000] | Loss[0.8783808946609497] | Lr[8.000000000000003e-08]
Step[4000] | Loss[0.4994671940803528] | Lr[8.000000000000003e-08]
Step[4000] | Loss[0.843107283115387] | Lr[8.000000000000003e-08]
Step[4000] | Loss[0.4695528447628021] | Lr[8.000000000000003e-08]
Step[4500] | Loss[0.4950792193412781] | Lr[8.000000000000003e-08]Step[4500] | Loss[0.8582165241241455] | Lr[8.000000000000003e-08]

Step[4500] | Loss[0.7114894986152649] | Lr[8.000000000000003e-08]
Step[4500] | Loss[0.39371079206466675] | Lr[8.000000000000003e-08]
Step[5000] | Loss[0.7345274686813354] | Lr[8.000000000000003e-08]
Step[5000] | Loss[0.6755523085594177] | Lr[8.000000000000003e-08]
Step[5000] | Loss[0.9664514064788818] | Lr[8.000000000000003e-08]Step[5000] | Loss[0.6467138528823853] | Lr[8.000000000000003e-08]

Step[5500] | Loss[0.7670489549636841] | Lr[8.000000000000003e-08]
Step[5500] | Loss[0.4980127811431885] | Lr[8.000000000000003e-08]
Step[5500] | Loss[0.4920738935470581] | Lr[8.000000000000003e-08]
Step[5500] | Loss[0.6910622119903564] | Lr[8.000000000000003e-08]
Step[6000] | Loss[0.6586337089538574] | Lr[8.000000000000003e-08]
Step[6000] | Loss[0.8518850207328796] | Lr[8.000000000000003e-08]
Step[6000] | Loss[0.49352285265922546] | Lr[8.000000000000003e-08]
Step[6000] | Loss[0.805679976940155] | Lr[8.000000000000003e-08]
Step[6500] | Loss[0.36771318316459656] | Lr[8.000000000000003e-08]Step[6500] | Loss[0.8355263471603394] | Lr[8.000000000000003e-08]

Step[6500] | Loss[0.7747862339019775] | Lr[8.000000000000003e-08]
Step[6500] | Loss[0.5579058527946472] | Lr[8.000000000000003e-08]
Step[7000] | Loss[0.6165162920951843] | Lr[8.000000000000003e-08]
Step[7000] | Loss[0.7431652545928955] | Lr[8.000000000000003e-08]
Step[7000] | Loss[0.7837949991226196] | Lr[8.000000000000003e-08]
Step[7000] | Loss[0.7461361885070801] | Lr[8.000000000000003e-08]
Step[7500] | Loss[1.1619077920913696] | Lr[8.000000000000003e-08]
Step[7500] | Loss[0.40231257677078247] | Lr[8.000000000000003e-08]
Step[7500] | Loss[0.6302691102027893] | Lr[8.000000000000003e-08]
Step[7500] | Loss[0.6278570890426636] | Lr[8.000000000000003e-08]
Step[8000] | Loss[0.47203728556632996] | Lr[8.000000000000003e-08]
Step[8000] | Loss[0.7530122399330139] | Lr[8.000000000000003e-08]
Step[8000] | Loss[0.6132108569145203] | Lr[8.000000000000003e-08]
Step[8000] | Loss[0.3019880950450897] | Lr[8.000000000000003e-08]
Step[8500] | Loss[0.671153724193573] | Lr[8.000000000000003e-08]Step[8500] | Loss[0.6798072457313538] | Lr[8.000000000000003e-08]

Step[8500] | Loss[0.47875410318374634] | Lr[8.000000000000003e-08]
Step[8500] | Loss[0.363675594329834] | Lr[8.000000000000003e-08]
Step[9000] | Loss[0.5400996804237366] | Lr[8.000000000000003e-08]
Step[9000] | Loss[0.6541305780410767] | Lr[8.000000000000003e-08]
Step[9000] | Loss[0.5317345857620239] | Lr[8.000000000000003e-08]
Step[9000] | Loss[0.6934784650802612] | Lr[8.000000000000003e-08]
Step[9500] | Loss[0.8197904825210571] | Lr[8.000000000000003e-08]
Step[9500] | Loss[0.5338889360427856] | Lr[8.000000000000003e-08]
Step[9500] | Loss[0.6312153935432434] | Lr[8.000000000000003e-08]Step[9500] | Loss[0.778015673160553] | Lr[8.000000000000003e-08]

Step[10000] | Loss[0.8995271325111389] | Lr[8.000000000000003e-08]
Step[10000] | Loss[0.7298294305801392] | Lr[8.000000000000003e-08]
Step[10000] | Loss[0.6144231557846069] | Lr[8.000000000000003e-08]
Step[10000] | Loss[0.6222574710845947] | Lr[8.000000000000003e-08]
Step[10500] | Loss[1.0080459117889404] | Lr[8.000000000000003e-08]
Step[10500] | Loss[0.3438551425933838] | Lr[8.000000000000003e-08]
Step[10500] | Loss[0.9536935091018677] | Lr[8.000000000000003e-08]
Step[10500] | Loss[0.615700900554657] | Lr[8.000000000000003e-08]
Step[11000] | Loss[0.8340150713920593] | Lr[8.000000000000003e-08]Step[11000] | Loss[0.7085244059562683] | Lr[8.000000000000003e-08]

Step[11000] | Loss[0.6114773154258728] | Lr[8.000000000000003e-08]
Step[11000] | Loss[0.7763057351112366] | Lr[8.000000000000003e-08]
Step[11500] | Loss[0.5569319725036621] | Lr[8.000000000000003e-08]
Step[11500] | Loss[0.8253621459007263] | Lr[8.000000000000003e-08]
Step[11500] | Loss[0.9782934784889221] | Lr[8.000000000000003e-08]
Step[11500] | Loss[0.6627202033996582] | Lr[8.000000000000003e-08]
Step[12000] | Loss[0.608150064945221] | Lr[8.000000000000003e-08]
Step[12000] | Loss[0.5682020783424377] | Lr[8.000000000000003e-08]
Step[12000] | Loss[0.7176409363746643] | Lr[8.000000000000003e-08]
Step[12000] | Loss[0.946519672870636] | Lr[8.000000000000003e-08]
Step[12500] | Loss[0.8886483311653137] | Lr[8.000000000000003e-08]
Step[12500] | Loss[0.7520958781242371] | Lr[8.000000000000003e-08]
Step[12500] | Loss[0.9785168766975403] | Lr[8.000000000000003e-08]
Step[12500] | Loss[0.6180950999259949] | Lr[8.000000000000003e-08]
Step[13000] | Loss[0.904940128326416] | Lr[8.000000000000003e-08]Step[13000] | Loss[0.5230683088302612] | Lr[8.000000000000003e-08]

Step[13000] | Loss[0.6455020904541016] | Lr[8.000000000000003e-08]
Step[13000] | Loss[0.5338907837867737] | Lr[8.000000000000003e-08]
Step[13500] | Loss[0.5274743437767029] | Lr[8.000000000000003e-08]
Step[13500] | Loss[0.4889377951622009] | Lr[8.000000000000003e-08]
Step[13500] | Loss[0.8422583937644958] | Lr[8.000000000000003e-08]
Step[13500] | Loss[0.6900098919868469] | Lr[8.000000000000003e-08]
Step[14000] | Loss[0.6075186133384705] | Lr[8.000000000000003e-08]
Step[14000] | Loss[0.5203016400337219] | Lr[8.000000000000003e-08]
Step[14000] | Loss[0.5891080498695374] | Lr[8.000000000000003e-08]
Step[14000] | Loss[0.9984692335128784] | Lr[8.000000000000003e-08]
Step[14500] | Loss[0.9963124990463257] | Lr[8.000000000000003e-08]
Step[14500] | Loss[0.47299498319625854] | Lr[8.000000000000003e-08]
Step[14500] | Loss[0.640734076499939] | Lr[8.000000000000003e-08]
Step[14500] | Loss[0.7679452300071716] | Lr[8.000000000000003e-08]
Step[15000] | Loss[0.4776926636695862] | Lr[8.000000000000003e-08]
Step[15000] | Loss[0.9509825110435486] | Lr[8.000000000000003e-08]
Step[15000] | Loss[0.7549551725387573] | Lr[8.000000000000003e-08]
Step[15000] | Loss[0.9969797730445862] | Lr[8.000000000000003e-08]
Step[15500] | Loss[0.3881266415119171] | Lr[8.000000000000003e-08]
Step[15500] | Loss[0.6191695332527161] | Lr[8.000000000000003e-08]
Step[15500] | Loss[0.9334568977355957] | Lr[8.000000000000003e-08]
Step[15500] | Loss[1.183465838432312] | Lr[8.000000000000003e-08]
Step[16000] | Loss[0.40686845779418945] | Lr[8.000000000000003e-08]Step[16000] | Loss[0.6820746660232544] | Lr[8.000000000000003e-08]

Step[16000] | Loss[0.53266441822052] | Lr[8.000000000000003e-08]
Step[16000] | Loss[0.5303980708122253] | Lr[8.000000000000003e-08]
Step[16500] | Loss[0.8501031994819641] | Lr[8.000000000000003e-08]
Step[16500] | Loss[0.7063732147216797] | Lr[8.000000000000003e-08]
Step[16500] | Loss[0.5779147744178772] | Lr[8.000000000000003e-08]Step[16500] | Loss[0.5693520903587341] | Lr[8.000000000000003e-08]

Step[17000] | Loss[0.40183842182159424] | Lr[8.000000000000003e-08]Step[17000] | Loss[0.6141912937164307] | Lr[8.000000000000003e-08]

Step[17000] | Loss[0.9315164089202881] | Lr[8.000000000000003e-08]
Step[17000] | Loss[0.767784833908081] | Lr[8.000000000000003e-08]
Step[17500] | Loss[0.613170862197876] | Lr[8.000000000000003e-08]
Step[17500] | Loss[0.608592689037323] | Lr[8.000000000000003e-08]
Step[17500] | Loss[0.979834794998169] | Lr[8.000000000000003e-08]
Step[17500] | Loss[0.586956799030304] | Lr[8.000000000000003e-08]
Step[18000] | Loss[0.3623025715351105] | Lr[8.000000000000003e-08]
Step[18000] | Loss[0.6135292649269104] | Lr[8.000000000000003e-08]
Step[18000] | Loss[0.8625072240829468] | Lr[8.000000000000003e-08]
Step[18000] | Loss[0.7329403162002563] | Lr[8.000000000000003e-08]
Step[18500] | Loss[0.6459069848060608] | Lr[8.000000000000003e-08]Step[18500] | Loss[0.4528433084487915] | Lr[8.000000000000003e-08]

Step[18500] | Loss[0.7380532622337341] | Lr[8.000000000000003e-08]
Step[18500] | Loss[0.7416669726371765] | Lr[8.000000000000003e-08]
Step[19000] | Loss[0.5079561471939087] | Lr[8.000000000000003e-08]Step[19000] | Loss[0.7840598821640015] | Lr[8.000000000000003e-08]

Step[19000] | Loss[0.8327795267105103] | Lr[8.000000000000003e-08]
Step[19000] | Loss[0.7612072229385376] | Lr[8.000000000000003e-08]
Step[19500] | Loss[0.8802946209907532] | Lr[8.000000000000003e-08]
Step[19500] | Loss[0.816000759601593] | Lr[8.000000000000003e-08]
Step[19500] | Loss[0.5756505131721497] | Lr[8.000000000000003e-08]
Step[19500] | Loss[0.7802198529243469] | Lr[8.000000000000003e-08]
Step[20000] | Loss[0.6550671458244324] | Lr[8.000000000000003e-08]
Step[20000] | Loss[0.4510936141014099] | Lr[8.000000000000003e-08]
Step[20000] | Loss[0.8351765275001526] | Lr[8.000000000000003e-08]
Step[20000] | Loss[0.7625473141670227] | Lr[8.000000000000003e-08]
Step[20500] | Loss[0.7827996611595154] | Lr[8.000000000000003e-08]
Step[20500] | Loss[0.9371398687362671] | Lr[8.000000000000003e-08]
Step[20500] | Loss[0.44193679094314575] | Lr[8.000000000000003e-08]
Step[20500] | Loss[0.45735374093055725] | Lr[8.000000000000003e-08]
Step[21000] | Loss[0.9007576107978821] | Lr[8.000000000000003e-08]
Step[21000] | Loss[0.4675382673740387] | Lr[8.000000000000003e-08]
Step[21000] | Loss[0.5757885575294495] | Lr[8.000000000000003e-08]
Step[21000] | Loss[0.7016712427139282] | Lr[8.000000000000003e-08]
Step[21500] | Loss[0.5785378813743591] | Lr[8.000000000000003e-08]
Step[21500] | Loss[0.48372241854667664] | Lr[8.000000000000003e-08]
Step[21500] | Loss[0.9392678141593933] | Lr[8.000000000000003e-08]
Step[21500] | Loss[0.7131931185722351] | Lr[8.000000000000003e-08]
Step[22000] | Loss[0.6611629724502563] | Lr[8.000000000000003e-08]
Step[22000] | Loss[0.5261478424072266] | Lr[8.000000000000003e-08]
Step[22000] | Loss[0.5905613303184509] | Lr[8.000000000000003e-08]
Step[22000] | Loss[0.5449514985084534] | Lr[8.000000000000003e-08]
Step[22500] | Loss[0.9150466322898865] | Lr[8.000000000000003e-08]
Step[22500] | Loss[0.49302732944488525] | Lr[8.000000000000003e-08]
Step[22500] | Loss[0.5785934329032898] | Lr[8.000000000000003e-08]
Step[22500] | Loss[0.9962745308876038] | Lr[8.000000000000003e-08]
Step[23000] | Loss[0.5597283244132996] | Lr[8.000000000000003e-08]
Step[23000] | Loss[0.9087203741073608] | Lr[8.000000000000003e-08]
Step[23000] | Loss[0.5382168292999268] | Lr[8.000000000000003e-08]
Step[23000] | Loss[0.5486041307449341] | Lr[8.000000000000003e-08]
Step[23500] | Loss[0.749474287033081] | Lr[8.000000000000003e-08]
Step[23500] | Loss[0.49808961153030396] | Lr[8.000000000000003e-08]
Step[23500] | Loss[1.039406180381775] | Lr[8.000000000000003e-08]
Step[23500] | Loss[0.5963035225868225] | Lr[8.000000000000003e-08]
Step[24000] | Loss[0.46745315194129944] | Lr[8.000000000000003e-08]
Step[24000] | Loss[0.47690102458000183] | Lr[8.000000000000003e-08]
Step[24000] | Loss[0.8553982377052307] | Lr[8.000000000000003e-08]
Step[24000] | Loss[0.6419746279716492] | Lr[8.000000000000003e-08]
Step[24500] | Loss[0.6964245438575745] | Lr[8.000000000000003e-08]
Step[24500] | Loss[0.8036147356033325] | Lr[8.000000000000003e-08]
Step[24500] | Loss[0.633771538734436] | Lr[8.000000000000003e-08]
Step[24500] | Loss[0.7687206268310547] | Lr[8.000000000000003e-08]
Step[25000] | Loss[0.5640827417373657] | Lr[8.000000000000003e-08]
Step[25000] | Loss[0.6543915271759033] | Lr[8.000000000000003e-08]
Step[25000] | Loss[0.9083988070487976] | Lr[8.000000000000003e-08]
Step[25000] | Loss[1.1885075569152832] | Lr[8.000000000000003e-08]
Step[25500] | Loss[0.441778302192688] | Lr[8.000000000000003e-08]
Step[25500] | Loss[0.6626760959625244] | Lr[8.000000000000003e-08]
Step[25500] | Loss[0.6111217141151428] | Lr[8.000000000000003e-08]
Step[25500] | Loss[0.4132564961910248] | Lr[8.000000000000003e-08]
Step[26000] | Loss[0.35880783200263977] | Lr[8.000000000000003e-08]
Step[26000] | Loss[0.519032895565033] | Lr[8.000000000000003e-08]
Step[26000] | Loss[0.5337937474250793] | Lr[8.000000000000003e-08]
Step[26000] | Loss[0.5854334831237793] | Lr[8.000000000000003e-08]
Step[26500] | Loss[0.6798572540283203] | Lr[8.000000000000003e-08]
Step[26500] | Loss[1.3394660949707031] | Lr[8.000000000000003e-08]
Step[26500] | Loss[0.9684985876083374] | Lr[8.000000000000003e-08]
Step[26500] | Loss[0.7646574378013611] | Lr[8.000000000000003e-08]
Step[27000] | Loss[0.7499326467514038] | Lr[8.000000000000003e-08]
Step[27000] | Loss[0.43313273787498474] | Lr[8.000000000000003e-08]
Step[27000] | Loss[0.5149993896484375] | Lr[8.000000000000003e-08]
Step[27000] | Loss[0.4763205349445343] | Lr[8.000000000000003e-08]
Step[27500] | Loss[0.3446040749549866] | Lr[8.000000000000003e-08]
Step[27500] | Loss[0.5256986021995544] | Lr[8.000000000000003e-08]
Step[27500] | Loss[0.7507898211479187] | Lr[8.000000000000003e-08]
Step[27500] | Loss[0.8644272089004517] | Lr[8.000000000000003e-08]
Step[28000] | Loss[0.513679563999176] | Lr[8.000000000000003e-08]
Step[28000] | Loss[0.5964109897613525] | Lr[8.000000000000003e-08]
Step[28000] | Loss[0.4477039575576782] | Lr[8.000000000000003e-08]
Step[28000] | Loss[0.6668180823326111] | Lr[8.000000000000003e-08]
Step[28500] | Loss[0.5111516714096069] | Lr[8.000000000000003e-08]
Step[28500] | Loss[0.5149335861206055] | Lr[8.000000000000003e-08]
Step[28500] | Loss[0.7519737482070923] | Lr[8.000000000000003e-08]
Step[28500] | Loss[0.9585504531860352] | Lr[8.000000000000003e-08]
Step[29000] | Loss[0.765298068523407] | Lr[8.000000000000003e-08]
Step[29000] | Loss[0.6315248608589172] | Lr[8.000000000000003e-08]
Step[29000] | Loss[0.6259801387786865] | Lr[8.000000000000003e-08]
Step[29000] | Loss[0.736081600189209] | Lr[8.000000000000003e-08]
Step[29500] | Loss[0.49726808071136475] | Lr[8.000000000000003e-08]
Step[29500] | Loss[0.7417462468147278] | Lr[8.000000000000003e-08]
Step[29500] | Loss[0.5841919779777527] | Lr[8.000000000000003e-08]
Step[29500] | Loss[0.7584050893783569] | Lr[8.000000000000003e-08]
Step[30000] | Loss[0.5626000165939331] | Lr[8.000000000000003e-08]
Step[30000] | Loss[0.9885836839675903] | Lr[8.000000000000003e-08]
Step[30000] | Loss[0.5260480642318726] | Lr[8.000000000000003e-08]
Step[30000] | Loss[0.6613370180130005] | Lr[8.000000000000003e-08]
Step[30500] | Loss[0.8145694732666016] | Lr[8.000000000000003e-08]
Step[30500] | Loss[0.6070399880409241] | Lr[8.000000000000003e-08]
Step[30500] | Loss[0.5817490816116333] | Lr[8.000000000000003e-08]
Step[30500] | Loss[0.5965766310691833] | Lr[8.000000000000003e-08]
Step[31000] | Loss[0.5519605278968811] | Lr[8.000000000000003e-08]
Step[31000] | Loss[0.8618370890617371] | Lr[8.000000000000003e-08]
Step[31000] | Loss[0.4281359612941742] | Lr[8.000000000000003e-08]
Step[31000] | Loss[0.6472049355506897] | Lr[8.000000000000003e-08]
Step[31500] | Loss[0.5587387084960938] | Lr[8.000000000000003e-08]Step[31500] | Loss[0.5861079692840576] | Lr[8.000000000000003e-08]

Step[31500] | Loss[0.8368023037910461] | Lr[8.000000000000003e-08]
Step[31500] | Loss[1.1366616487503052] | Lr[8.000000000000003e-08]
Step[32000] | Loss[0.4812450110912323] | Lr[8.000000000000003e-08]
Step[32000] | Loss[0.6167770028114319] | Lr[8.000000000000003e-08]
Step[32000] | Loss[0.4252639710903168] | Lr[8.000000000000003e-08]
Step[32000] | Loss[0.5009087324142456] | Lr[8.000000000000003e-08]
Step[32500] | Loss[0.6708437204360962] | Lr[8.000000000000003e-08]
Step[32500] | Loss[0.7329609990119934] | Lr[8.000000000000003e-08]
Step[32500] | Loss[0.7976295351982117] | Lr[8.000000000000003e-08]
Step[32500] | Loss[0.7119535207748413] | Lr[8.000000000000003e-08]
Step[33000] | Loss[0.8915196061134338] | Lr[8.000000000000003e-08]
Step[33000] | Loss[0.37550297379493713] | Lr[8.000000000000003e-08]
Step[33000] | Loss[1.081714153289795] | Lr[8.000000000000003e-08]
Step[33000] | Loss[0.697494387626648] | Lr[8.000000000000003e-08]
Step[33500] | Loss[0.3158138692378998] | Lr[8.000000000000003e-08]
Step[33500] | Loss[0.5373095273971558] | Lr[8.000000000000003e-08]
Step[33500] | Loss[1.0047245025634766] | Lr[8.000000000000003e-08]Step[33500] | Loss[0.723046600818634] | Lr[8.000000000000003e-08]

Step[34000] | Loss[0.4570407271385193] | Lr[8.000000000000003e-08]
Step[34000] | Loss[0.4500986635684967] | Lr[8.000000000000003e-08]
Step[34000] | Loss[0.6855712532997131] | Lr[8.000000000000003e-08]
Step[34000] | Loss[0.5513729453086853] | Lr[8.000000000000003e-08]
Step[34500] | Loss[0.668511688709259] | Lr[8.000000000000003e-08]
Step[34500] | Loss[0.7516797780990601] | Lr[8.000000000000003e-08]
Step[34500] | Loss[0.38631147146224976] | Lr[8.000000000000003e-08]
Step[34500] | Loss[0.6200920939445496] | Lr[8.000000000000003e-08]
Step[35000] | Loss[0.679201602935791] | Lr[8.000000000000003e-08]
Step[35000] | Loss[0.6915337443351746] | Lr[8.000000000000003e-08]
Step[35000] | Loss[0.4053730368614197] | Lr[8.000000000000003e-08]
Step[35000] | Loss[0.6637650728225708] | Lr[8.000000000000003e-08]
Step[35500] | Loss[0.6913633942604065] | Lr[8.000000000000003e-08]
Step[35500] | Loss[0.9159351587295532] | Lr[8.000000000000003e-08]
Step[35500] | Loss[0.486205130815506] | Lr[8.000000000000003e-08]
Step[35500] | Loss[0.7296855449676514] | Lr[8.000000000000003e-08]
Step[36000] | Loss[0.7708000540733337] | Lr[8.000000000000003e-08]
Step[36000] | Loss[0.6210123300552368] | Lr[8.000000000000003e-08]
Step[36000] | Loss[0.7540943622589111] | Lr[8.000000000000003e-08]
Step[36000] | Loss[0.8367049694061279] | Lr[8.000000000000003e-08]
Step[36500] | Loss[0.6136281490325928] | Lr[8.000000000000003e-08]
Step[36500] | Loss[0.5654997229576111] | Lr[8.000000000000003e-08]
Step[36500] | Loss[0.3773571252822876] | Lr[8.000000000000003e-08]
Step[36500] | Loss[0.6026394367218018] | Lr[8.000000000000003e-08]
Step[37000] | Loss[0.6683297753334045] | Lr[8.000000000000003e-08]
Step[37000] | Loss[0.5861430168151855] | Lr[8.000000000000003e-08]
Step[37000] | Loss[0.5349155068397522] | Lr[8.000000000000003e-08]
Step[37000] | Loss[0.3512948751449585] | Lr[8.000000000000003e-08]
Step[37500] | Loss[0.6025001406669617] | Lr[8.000000000000003e-08]
Step[37500] | Loss[0.7203034162521362] | Lr[8.000000000000003e-08]
Step[37500] | Loss[0.7515066862106323] | Lr[8.000000000000003e-08]Step[37500] | Loss[0.9725025296211243] | Lr[8.000000000000003e-08]

Step[38000] | Loss[0.5163329243659973] | Lr[8.000000000000003e-08]
Step[38000] | Loss[0.7443221807479858] | Lr[8.000000000000003e-08]
Step[38000] | Loss[0.8665852546691895] | Lr[8.000000000000003e-08]
Step[38000] | Loss[0.7696186304092407] | Lr[8.000000000000003e-08]
Step[38500] | Loss[0.52138352394104] | Lr[8.000000000000003e-08]
Step[38500] | Loss[1.1113427877426147] | Lr[8.000000000000003e-08]
Step[38500] | Loss[0.7313545346260071] | Lr[8.000000000000003e-08]
Step[38500] | Loss[0.6121212244033813] | Lr[8.000000000000003e-08]
Step[39000] | Loss[0.9088917374610901] | Lr[8.000000000000003e-08]
Step[39000] | Loss[0.6736303567886353] | Lr[8.000000000000003e-08]
Step[39000] | Loss[0.5778526067733765] | Lr[8.000000000000003e-08]
Step[39000] | Loss[0.5860188007354736] | Lr[8.000000000000003e-08]
Step[39500] | Loss[0.7892767190933228] | Lr[8.000000000000003e-08]Step[39500] | Loss[0.6333069801330566] | Lr[8.000000000000003e-08]

Step[39500] | Loss[0.42297446727752686] | Lr[8.000000000000003e-08]
Step[39500] | Loss[0.3991451561450958] | Lr[8.000000000000003e-08]
Step[40000] | Loss[1.0472455024719238] | Lr[8.000000000000003e-08]
Step[40000] | Loss[0.7077170014381409] | Lr[8.000000000000003e-08]
Step[40000] | Loss[0.5302811861038208] | Lr[8.000000000000003e-08]
Step[40000] | Loss[0.36295658349990845] | Lr[8.000000000000003e-08]
Step[40500] | Loss[0.47204503417015076] | Lr[8.000000000000003e-08]
Step[40500] | Loss[0.40713319182395935] | Lr[8.000000000000003e-08]
Step[40500] | Loss[0.8049808740615845] | Lr[8.000000000000003e-08]
Step[40500] | Loss[0.5588003396987915] | Lr[8.000000000000003e-08]
Step[41000] | Loss[0.9862837791442871] | Lr[8.000000000000003e-08]
Step[41000] | Loss[0.5357762575149536] | Lr[8.000000000000003e-08]
Step[41000] | Loss[0.4392984211444855] | Lr[8.000000000000003e-08]
Step[41000] | Loss[0.7087424993515015] | Lr[8.000000000000003e-08]
Step[41500] | Loss[0.7075182199478149] | Lr[8.000000000000003e-08]Step[41500] | Loss[0.9370381832122803] | Lr[8.000000000000003e-08]

Step[41500] | Loss[0.6893131732940674] | Lr[8.000000000000003e-08]
Step[41500] | Loss[0.7639803290367126] | Lr[8.000000000000003e-08]
Step[42000] | Loss[0.4657460153102875] | Lr[8.000000000000003e-08]
Step[42000] | Loss[0.7711203098297119] | Lr[8.000000000000003e-08]
Step[42000] | Loss[0.8652867078781128] | Lr[8.000000000000003e-08]
Step[42000] | Loss[0.44134920835494995] | Lr[8.000000000000003e-08]
Step[42500] | Loss[0.6627750396728516] | Lr[8.000000000000003e-08]
Step[42500] | Loss[0.7383605241775513] | Lr[8.000000000000003e-08]
Step[42500] | Loss[0.8368467688560486] | Lr[8.000000000000003e-08]
Step[42500] | Loss[0.575616717338562] | Lr[8.000000000000003e-08]
Step[43000] | Loss[0.5241262912750244] | Lr[8.000000000000003e-08]
Step[43000] | Loss[0.6581799387931824] | Lr[8.000000000000003e-08]
Step[43000] | Loss[0.7657872438430786] | Lr[8.000000000000003e-08]Step[43000] | Loss[0.5188876986503601] | Lr[8.000000000000003e-08]

Step[43500] | Loss[0.49324971437454224] | Lr[8.000000000000003e-08]
Step[43500] | Loss[0.8935319185256958] | Lr[8.000000000000003e-08]
Step[43500] | Loss[0.7889328598976135] | Lr[8.000000000000003e-08]
Step[43500] | Loss[0.784199595451355] | Lr[8.000000000000003e-08]
Step[44000] | Loss[0.6855055093765259] | Lr[8.000000000000003e-08]
Step[44000] | Loss[0.991654634475708] | Lr[8.000000000000003e-08]
Step[44000] | Loss[0.8631454706192017] | Lr[8.000000000000003e-08]
Step[44000] | Loss[0.700771152973175] | Lr[8.000000000000003e-08]
Step[44500] | Loss[0.6381348371505737] | Lr[8.000000000000003e-08]
Step[44500] | Loss[1.1116111278533936] | Lr[8.000000000000003e-08]
Step[44500] | Loss[0.8066455125808716] | Lr[8.000000000000003e-08]
Step[44500] | Loss[0.5661764144897461] | Lr[8.000000000000003e-08]
Step[45000] | Loss[0.3902926445007324] | Lr[8.000000000000003e-08]Step[45000] | Loss[0.7835533618927002] | Lr[8.000000000000003e-08]

Step[45000] | Loss[0.9480305910110474] | Lr[8.000000000000003e-08]
Step[45000] | Loss[1.403795838356018] | Lr[8.000000000000003e-08]
Step[45500] | Loss[0.3978400230407715] | Lr[8.000000000000003e-08]Step[45500] | Loss[0.7189368009567261] | Lr[8.000000000000003e-08]

Step[45500] | Loss[0.6441819071769714] | Lr[8.000000000000003e-08]
Step[45500] | Loss[0.9111372828483582] | Lr[8.000000000000003e-08]
Step[46000] | Loss[0.7101793885231018] | Lr[8.000000000000003e-08]
Step[46000] | Loss[0.5577061772346497] | Lr[8.000000000000003e-08]
Step[46000] | Loss[0.6248728036880493] | Lr[8.000000000000003e-08]
Step[46000] | Loss[0.8458980321884155] | Lr[8.000000000000003e-08]
Step[46500] | Loss[0.7575267553329468] | Lr[8.000000000000003e-08]
Step[46500] | Loss[0.5281552076339722] | Lr[8.000000000000003e-08]
Step[46500] | Loss[0.6372458338737488] | Lr[8.000000000000003e-08]
Step[46500] | Loss[0.3405535817146301] | Lr[8.000000000000003e-08]
Step[47000] | Loss[0.5486729741096497] | Lr[8.000000000000003e-08]Step[47000] | Loss[0.5495940446853638] | Lr[8.000000000000003e-08]

Step[47000] | Loss[0.4146133065223694] | Lr[8.000000000000003e-08]
Step[47000] | Loss[0.6241824626922607] | Lr[8.000000000000003e-08]
Step[47500] | Loss[0.5091577172279358] | Lr[8.000000000000003e-08]
Step[47500] | Loss[0.7400075793266296] | Lr[8.000000000000003e-08]
Step[47500] | Loss[0.4484386742115021] | Lr[8.000000000000003e-08]
Step[47500] | Loss[0.43732479214668274] | Lr[8.000000000000003e-08]
Step[48000] | Loss[0.27020564675331116] | Lr[8.000000000000003e-08]
Step[48000] | Loss[0.786309540271759] | Lr[8.000000000000003e-08]
Step[48000] | Loss[0.5350192189216614] | Lr[8.000000000000003e-08]
Step[48000] | Loss[0.7434354424476624] | Lr[8.000000000000003e-08]
Step[48500] | Loss[0.4489428400993347] | Lr[8.000000000000003e-08]
Step[48500] | Loss[0.39086228609085083] | Lr[8.000000000000003e-08]
Step[48500] | Loss[0.5618664026260376] | Lr[8.000000000000003e-08]
Step[48500] | Loss[0.4812307357788086] | Lr[8.000000000000003e-08]
Step[49000] | Loss[0.9995444416999817] | Lr[8.000000000000003e-08]
Step[49000] | Loss[0.7373498678207397] | Lr[8.000000000000003e-08]
Step[49000] | Loss[0.693408191204071] | Lr[8.000000000000003e-08]Step[49000] | Loss[0.6231159567832947] | Lr[8.000000000000003e-08]

Step[49500] | Loss[0.7323642373085022] | Lr[8.000000000000003e-08]Step[49500] | Loss[0.4538571238517761] | Lr[8.000000000000003e-08]

Step[49500] | Loss[0.4603464603424072] | Lr[8.000000000000003e-08]
Step[49500] | Loss[0.7238599061965942] | Lr[8.000000000000003e-08]
Step[50000] | Loss[0.8218539953231812] | Lr[8.000000000000003e-08]
Step[50000] | Loss[0.29942286014556885] | Lr[8.000000000000003e-08]
Step[50000] | Loss[0.7947056889533997] | Lr[8.000000000000003e-08]
Step[50000] | Loss[0.6531301736831665] | Lr[8.000000000000003e-08]
Step[50500] | Loss[0.5319567322731018] | Lr[8.000000000000003e-08]
Step[50500] | Loss[1.1311603784561157] | Lr[8.000000000000003e-08]
Step[50500] | Loss[0.5055435299873352] | Lr[8.000000000000003e-08]
Step[50500] | Loss[0.5984475612640381] | Lr[8.000000000000003e-08]
Step[51000] | Loss[0.6027368307113647] | Lr[8.000000000000003e-08]
Step[51000] | Loss[0.6293026804924011] | Lr[8.000000000000003e-08]
Step[51000] | Loss[0.9259698390960693] | Lr[8.000000000000003e-08]
Step[51000] | Loss[1.144779086112976] | Lr[8.000000000000003e-08]
Step[51500] | Loss[0.7426895499229431] | Lr[8.000000000000003e-08]
Step[51500] | Loss[0.6298836469650269] | Lr[8.000000000000003e-08]
Step[51500] | Loss[0.6611260771751404] | Lr[8.000000000000003e-08]
Step[51500] | Loss[0.9208664298057556] | Lr[8.000000000000003e-08]
Step[52000] | Loss[0.7994574904441833] | Lr[8.000000000000003e-08]
Step[52000] | Loss[0.6496831774711609] | Lr[8.000000000000003e-08]
Step[52000] | Loss[1.164541244506836] | Lr[8.000000000000003e-08]
Step[52000] | Loss[0.6906173229217529] | Lr[8.000000000000003e-08]
Step[52500] | Loss[0.7261524796485901] | Lr[8.000000000000003e-08]
Step[52500] | Loss[0.7112526297569275] | Lr[8.000000000000003e-08]
Step[52500] | Loss[0.781519889831543] | Lr[8.000000000000003e-08]
Step[52500] | Loss[0.558810293674469] | Lr[8.000000000000003e-08]
Step[53000] | Loss[0.7246611714363098] | Lr[8.000000000000003e-08]
Step[53000] | Loss[0.7143184542655945] | Lr[8.000000000000003e-08]
Step[53000] | Loss[0.5980983972549438] | Lr[8.000000000000003e-08]
Step[53000] | Loss[0.42519867420196533] | Lr[8.000000000000003e-08]
Step[53500] | Loss[0.8336976170539856] | Lr[8.000000000000003e-08]
Step[53500] | Loss[0.6366872191429138] | Lr[8.000000000000003e-08]
Step[53500] | Loss[0.5623301267623901] | Lr[8.000000000000003e-08]
Step[53500] | Loss[0.522441029548645] | Lr[8.000000000000003e-08]
Step[54000] | Loss[0.5835165977478027] | Lr[8.000000000000003e-08]
Step[54000] | Loss[0.4794173836708069] | Lr[8.000000000000003e-08]
Step[54000] | Loss[1.0276634693145752] | Lr[8.000000000000003e-08]
Step[54000] | Loss[0.49868789315223694] | Lr[8.000000000000003e-08]
Step[54500] | Loss[0.5414997339248657] | Lr[8.000000000000003e-08]
Step[54500] | Loss[0.7481481432914734] | Lr[8.000000000000003e-08]
Step[54500] | Loss[0.861957311630249] | Lr[8.000000000000003e-08]
Step[54500] | Loss[0.6354079246520996] | Lr[8.000000000000003e-08]
Step[55000] | Loss[0.47635897994041443] | Lr[8.000000000000003e-08]
Step[55000] | Loss[0.8148618936538696] | Lr[8.000000000000003e-08]
Step[55000] | Loss[0.7274876832962036] | Lr[8.000000000000003e-08]
Step[55000] | Loss[0.5935568809509277] | Lr[8.000000000000003e-08]
Step[55500] | Loss[0.5266474485397339] | Lr[8.000000000000003e-08]
Step[55500] | Loss[0.4887438714504242] | Lr[8.000000000000003e-08]
Step[55500] | Loss[0.7730075120925903] | Lr[8.000000000000003e-08]
Step[55500] | Loss[0.7436729669570923] | Lr[8.000000000000003e-08]
Step[56000] | Loss[0.33221757411956787] | Lr[8.000000000000003e-08]
Step[56000] | Loss[0.5755826830863953] | Lr[8.000000000000003e-08]
Step[56000] | Loss[0.6088700890541077] | Lr[8.000000000000003e-08]
Step[56000] | Loss[1.016800880432129] | Lr[8.000000000000003e-08]
Step[56500] | Loss[0.5331392884254456] | Lr[8.000000000000003e-08]
Step[56500] | Loss[0.5602816343307495] | Lr[8.000000000000003e-08]
Step[56500] | Loss[0.6708890199661255] | Lr[8.000000000000003e-08]Step[56500] | Loss[0.8370282649993896] | Lr[8.000000000000003e-08]

Step[57000] | Loss[0.8858647346496582] | Lr[8.000000000000003e-08]
Step[57000] | Loss[0.5671514272689819] | Lr[8.000000000000003e-08]
Step[57000] | Loss[0.30082619190216064] | Lr[8.000000000000003e-08]
Step[57000] | Loss[0.7654715180397034] | Lr[8.000000000000003e-08]
Step[57500] | Loss[0.8356772661209106] | Lr[8.000000000000003e-08]
Step[57500] | Loss[0.38426560163497925] | Lr[8.000000000000003e-08]
Step[57500] | Loss[0.7199139595031738] | Lr[8.000000000000003e-08]
Step[57500] | Loss[0.552563488483429] | Lr[8.000000000000003e-08]
Step[58000] | Loss[0.7689621448516846] | Lr[8.000000000000003e-08]
Step[58000] | Loss[1.2998992204666138] | Lr[8.000000000000003e-08]
Step[58000] | Loss[0.5338898301124573] | Lr[8.000000000000003e-08]
Step[58000] | Loss[0.7028462886810303] | Lr[8.000000000000003e-08]
Step[58500] | Loss[0.6656646728515625] | Lr[8.000000000000003e-08]
Step[58500] | Loss[0.5012049674987793] | Lr[8.000000000000003e-08]
Step[58500] | Loss[0.5266737937927246] | Lr[8.000000000000003e-08]Step[58500] | Loss[0.5640436410903931] | Lr[8.000000000000003e-08]

Step[59000] | Loss[0.6135373115539551] | Lr[8.000000000000003e-08]
Step[59000] | Loss[0.44567635655403137] | Lr[8.000000000000003e-08]
Step[59000] | Loss[0.4742962419986725] | Lr[8.000000000000003e-08]
Step[59000] | Loss[0.7566946148872375] | Lr[8.000000000000003e-08]
Step[59500] | Loss[1.00047767162323] | Lr[8.000000000000003e-08]
Step[59500] | Loss[0.7255595922470093] | Lr[8.000000000000003e-08]
Step[59500] | Loss[0.5766721367835999] | Lr[8.000000000000003e-08]
Step[59500] | Loss[0.798838198184967] | Lr[8.000000000000003e-08]
Step[60000] | Loss[0.6462432742118835] | Lr[8.000000000000003e-08]
Step[60000] | Loss[0.9262745380401611] | Lr[8.000000000000003e-08]
Step[60000] | Loss[0.4204074740409851] | Lr[8.000000000000003e-08]
Step[60000] | Loss[0.7452380061149597] | Lr[8.000000000000003e-08]
Step[60500] | Loss[0.6646894216537476] | Lr[8.000000000000003e-08]
Step[60500] | Loss[0.32913342118263245] | Lr[8.000000000000003e-08]
Step[60500] | Loss[0.8784281015396118] | Lr[8.000000000000003e-08]
Step[60500] | Loss[0.8176014423370361] | Lr[8.000000000000003e-08]
Step[61000] | Loss[0.7868857979774475] | Lr[8.000000000000003e-08]
Step[61000] | Loss[1.0143924951553345] | Lr[8.000000000000003e-08]
Step[61000] | Loss[0.5842524766921997] | Lr[8.000000000000003e-08]
Step[61000] | Loss[0.46393486857414246] | Lr[8.000000000000003e-08]
Step[61500] | Loss[0.5279278755187988] | Lr[8.000000000000003e-08]
Step[61500] | Loss[0.8383119106292725] | Lr[8.000000000000003e-08]
Step[61500] | Loss[1.0986921787261963] | Lr[8.000000000000003e-08]
Step[61500] | Loss[0.9711229801177979] | Lr[8.000000000000003e-08]
Step[62000] | Loss[0.37067049741744995] | Lr[8.000000000000003e-08]
Step[62000] | Loss[0.47016507387161255] | Lr[8.000000000000003e-08]
Step[62000] | Loss[0.6922057867050171] | Lr[8.000000000000003e-08]Step[62000] | Loss[0.5980555415153503] | Lr[8.000000000000003e-08]

Step[62500] | Loss[0.563978374004364] | Lr[8.000000000000003e-08]
Step[62500] | Loss[1.3148245811462402] | Lr[8.000000000000003e-08]
Step[62500] | Loss[0.3826133608818054] | Lr[8.000000000000003e-08]
Step[62500] | Loss[0.7129600048065186] | Lr[8.000000000000003e-08]
Step[63000] | Loss[0.8886688351631165] | Lr[8.000000000000003e-08]Step[63000] | Loss[0.5854269862174988] | Lr[8.000000000000003e-08]

Step[63000] | Loss[0.9647611975669861] | Lr[8.000000000000003e-08]
Step[63000] | Loss[0.5394813418388367] | Lr[8.000000000000003e-08]
Step[63500] | Loss[0.7152793407440186] | Lr[8.000000000000003e-08]
Step[63500] | Loss[0.8300104141235352] | Lr[8.000000000000003e-08]
Step[63500] | Loss[0.49722665548324585] | Lr[8.000000000000003e-08]
Step[63500] | Loss[0.4137062430381775] | Lr[8.000000000000003e-08]
Step[64000] | Loss[0.4429996907711029] | Lr[8.000000000000003e-08]
Step[64000] | Loss[0.33396634459495544] | Lr[8.000000000000003e-08]
Step[64000] | Loss[0.5720487833023071] | Lr[8.000000000000003e-08]
Step[64000] | Loss[0.4202183783054352] | Lr[8.000000000000003e-08]
Step[64500] | Loss[0.9707856178283691] | Lr[8.000000000000003e-08]
Step[64500] | Loss[0.7102445960044861] | Lr[8.000000000000003e-08]
Step[64500] | Loss[0.41783756017684937] | Lr[8.000000000000003e-08]Step[64500] | Loss[0.8102753162384033] | Lr[8.000000000000003e-08]

Step[65000] | Loss[0.570989191532135] | Lr[8.000000000000003e-08]
Step[65000] | Loss[0.49586811661720276] | Lr[8.000000000000003e-08]
Step[65000] | Loss[0.9917342066764832] | Lr[8.000000000000003e-08]
Step[65000] | Loss[0.5722894668579102] | Lr[8.000000000000003e-08]
Step[65500] | Loss[0.6172910332679749] | Lr[8.000000000000003e-08]
Step[65500] | Loss[0.6599228978157043] | Lr[8.000000000000003e-08]
Step[65500] | Loss[0.7678959965705872] | Lr[8.000000000000003e-08]
Step[65500] | Loss[0.967781126499176] | Lr[8.000000000000003e-08]
Step[66000] | Loss[0.9352571368217468] | Lr[8.000000000000003e-08]
Step[66000] | Loss[0.9038273692131042] | Lr[8.000000000000003e-08]
Step[66000] | Loss[0.4487215280532837] | Lr[8.000000000000003e-08]
Step[66000] | Loss[0.40848907828330994] | Lr[8.000000000000003e-08]
Step[66500] | Loss[0.6645107865333557] | Lr[8.000000000000003e-08]
Step[66500] | Loss[0.839331328868866] | Lr[8.000000000000003e-08]
Step[66500] | Loss[0.6359925270080566] | Lr[8.000000000000003e-08]
Step[66500] | Loss[0.3543165624141693] | Lr[8.000000000000003e-08]
Step[67000] | Loss[0.5042030215263367] | Lr[8.000000000000003e-08]
Step[67000] | Loss[0.6398640871047974] | Lr[8.000000000000003e-08]
Step[67000] | Loss[0.5970942378044128] | Lr[8.000000000000003e-08]
Step[67000] | Loss[0.9637013673782349] | Lr[8.000000000000003e-08]
Step[67500] | Loss[0.679999828338623] | Lr[8.000000000000003e-08]
Step[67500] | Loss[0.5418870449066162] | Lr[8.000000000000003e-08]
Step[67500] | Loss[0.7468633055686951] | Lr[8.000000000000003e-08]
Step[67500] | Loss[0.5847675800323486] | Lr[8.000000000000003e-08]
Step[68000] | Loss[0.43138939142227173] | Lr[8.000000000000003e-08]Step[68000] | Loss[0.8090872168540955] | Lr[8.000000000000003e-08]

Step[68000] | Loss[0.48455142974853516] | Lr[8.000000000000003e-08]
Step[68000] | Loss[0.7846333980560303] | Lr[8.000000000000003e-08]
Step[68500] | Loss[0.7042204737663269] | Lr[8.000000000000003e-08]Step[68500] | Loss[0.7054520845413208] | Lr[8.000000000000003e-08]

Step[68500] | Loss[0.5970442891120911] | Lr[8.000000000000003e-08]
Step[68500] | Loss[0.532838761806488] | Lr[8.000000000000003e-08]
Step[69000] | Loss[0.7111335396766663] | Lr[8.000000000000003e-08]
Step[69000] | Loss[0.3862285614013672] | Lr[8.000000000000003e-08]
Step[69000] | Loss[0.2272811383008957] | Lr[8.000000000000003e-08]
Step[69000] | Loss[0.4570971131324768] | Lr[8.000000000000003e-08]
Step[69500] | Loss[0.41377827525138855] | Lr[8.000000000000003e-08]
Step[69500] | Loss[0.24887007474899292] | Lr[8.000000000000003e-08]
Step[69500] | Loss[0.8958080410957336] | Lr[8.000000000000003e-08]
Step[69500] | Loss[0.4886344373226166] | Lr[8.000000000000003e-08]
Step[70000] | Loss[0.5335946083068848] | Lr[8.000000000000003e-08]
Step[70000] | Loss[0.521812915802002] | Lr[8.000000000000003e-08]
Step[70000] | Loss[0.5866261124610901] | Lr[8.000000000000003e-08]
Step[70000] | Loss[0.2585107088088989] | Lr[8.000000000000003e-08]
Step[70500] | Loss[0.5161435604095459] | Lr[8.000000000000003e-08]
Step[70500] | Loss[0.5164090394973755] | Lr[8.000000000000003e-08]
Step[70500] | Loss[0.6560847163200378] | Lr[8.000000000000003e-08]
Step[70500] | Loss[0.7329360842704773] | Lr[8.000000000000003e-08]
Step[71000] | Loss[0.4768640398979187] | Lr[8.000000000000003e-08]
Step[71000] | Loss[0.4121709167957306] | Lr[8.000000000000003e-08]
Step[71000] | Loss[0.21006229519844055] | Lr[8.000000000000003e-08]
Step[71000] | Loss[0.5889995098114014] | Lr[8.000000000000003e-08]
Step[71500] | Loss[0.5176470875740051] | Lr[8.000000000000003e-08]
Step[71500] | Loss[1.087470293045044] | Lr[8.000000000000003e-08]
Step[71500] | Loss[0.908650279045105] | Lr[8.000000000000003e-08]
Step[71500] | Loss[0.5957204103469849] | Lr[8.000000000000003e-08]
Step[72000] | Loss[0.8654701709747314] | Lr[8.000000000000003e-08]Step[72000] | Loss[0.7831888198852539] | Lr[8.000000000000003e-08]

Step[72000] | Loss[0.5091519951820374] | Lr[8.000000000000003e-08]
Step[72000] | Loss[0.41897618770599365] | Lr[8.000000000000003e-08]
Step[72500] | Loss[0.7458249926567078] | Lr[8.000000000000003e-08]
Step[72500] | Loss[0.4863833487033844] | Lr[8.000000000000003e-08]
Step[72500] | Loss[0.6967669129371643] | Lr[8.000000000000003e-08]
Step[72500] | Loss[0.6180723309516907] | Lr[8.000000000000003e-08]
Step[73000] | Loss[0.7530521154403687] | Lr[8.000000000000003e-08]
Step[73000] | Loss[0.6976973414421082] | Lr[8.000000000000003e-08]
Step[73000] | Loss[0.6122540235519409] | Lr[8.000000000000003e-08]
Step[73000] | Loss[0.9635690450668335] | Lr[8.000000000000003e-08]
Step[73500] | Loss[0.5031588673591614] | Lr[8.000000000000003e-08]
Step[73500] | Loss[0.8606199026107788] | Lr[8.000000000000003e-08]
Step[73500] | Loss[0.539527952671051] | Lr[8.000000000000003e-08]
Step[73500] | Loss[0.7774167656898499] | Lr[8.000000000000003e-08]
Step[74000] | Loss[0.870814859867096] | Lr[8.000000000000003e-08]
Step[74000] | Loss[0.8000921607017517] | Lr[8.000000000000003e-08]
Step[74000] | Loss[0.8431988954544067] | Lr[8.000000000000003e-08]
Step[74000] | Loss[0.7439843416213989] | Lr[8.000000000000003e-08]
Step[74500] | Loss[0.6978473663330078] | Lr[8.000000000000003e-08]Step[74500] | Loss[0.6103427410125732] | Lr[8.000000000000003e-08]

Step[74500] | Loss[0.5060244798660278] | Lr[8.000000000000003e-08]
Step[74500] | Loss[0.8495388031005859] | Lr[8.000000000000003e-08]
Step[75000] | Loss[0.5190997123718262] | Lr[8.000000000000003e-08]
Step[75000] | Loss[0.6618122458457947] | Lr[8.000000000000003e-08]
Step[75000] | Loss[0.5361759066581726] | Lr[8.000000000000003e-08]Step[75000] | Loss[0.7491468787193298] | Lr[8.000000000000003e-08]

Step[75500] | Loss[0.4572784900665283] | Lr[8.000000000000003e-08]
Step[75500] | Loss[0.5279437303543091] | Lr[8.000000000000003e-08]
Step[75500] | Loss[0.8232442736625671] | Lr[8.000000000000003e-08]
Step[75500] | Loss[0.6688660383224487] | Lr[8.000000000000003e-08]
Step[76000] | Loss[0.5045457482337952] | Lr[8.000000000000003e-08]
Step[76000] | Loss[0.9885653257369995] | Lr[8.000000000000003e-08]
Step[76000] | Loss[0.6479891538619995] | Lr[8.000000000000003e-08]
Step[76000] | Loss[0.4355943500995636] | Lr[8.000000000000003e-08]
Step[76500] | Loss[0.5580384731292725] | Lr[8.000000000000003e-08]
Step[76500] | Loss[0.25114956498146057] | Lr[8.000000000000003e-08]
Step[76500] | Loss[0.7901208400726318] | Lr[8.000000000000003e-08]
Step[76500] | Loss[0.42224419116973877] | Lr[8.000000000000003e-08]
Step[77000] | Loss[0.6303081512451172] | Lr[8.000000000000003e-08]
Step[77000] | Loss[0.9915376901626587] | Lr[8.000000000000003e-08]
Step[77000] | Loss[0.5712742209434509] | Lr[8.000000000000003e-08]
Step[77000] | Loss[1.1964408159255981] | Lr[8.000000000000003e-08]
Step[77500] | Loss[0.9199035167694092] | Lr[8.000000000000003e-08]
Step[77500] | Loss[0.6532450914382935] | Lr[8.000000000000003e-08]
Step[77500] | Loss[0.6034101247787476] | Lr[8.000000000000003e-08]
Step[77500] | Loss[0.3958944082260132] | Lr[8.000000000000003e-08]
Step[78000] | Loss[0.4090922772884369] | Lr[8.000000000000003e-08]
Step[78000] | Loss[0.4774898886680603] | Lr[8.000000000000003e-08]
Step[78000] | Loss[0.5039199590682983] | Lr[8.000000000000003e-08]
Step[78000] | Loss[0.7484162449836731] | Lr[8.000000000000003e-08]
Labels:  tensor([0, 4, 2, 3, 0, 1, 2, 2, 3, 2, 2, 4, 4, 1, 1, 2], device='cuda:1')
Labels:  tensor([3, 1, 1, 4, 0, 2, 4, 1, 3, 0, 2, 3, 2, 2, 4, 4], device='cuda:0')
Preds:  Labels:  tensor([0, 4, 1, 4, 0, 2, 4, 2, 1, 2, 0, 4, 4, 1, 1, 4], device='cuda:1')
Preds:  tensor([3, 0, 0, 4, 0, 2, 4, 1, 3, 0, 1, 4, 1, 2, 4, 4], device='cuda:0')
Outputs:  tensor([2, 2, 1, 1, 1, 4, 4, 4, 3, 2, 0, 3, 3, 4, 0, 3], device='cuda:0')
Preds:  tensor([3, 3, 2, 1, 0, 4, 4, 4, 2, 2, 1, 2, 4, 4, 0, 3], device='cuda:0')
Outputs:  Labels:  tensor([3, 0, 0, 1, 0, 3, 0, 0, 3, 1, 4, 4, 4, 1, 2, 0], device='cuda:1')
Preds:  tensor([4, 0, 2, 1, 0, 2, 0, 1, 3, 1, 2, 3, 4, 1, 2, 0], device='cuda:1')
Outputs:  tensor([[    0.7804,     0.2088,     0.0107,     0.0001,     0.0000],
        [    0.0002,     0.0001,     0.0008,     0.0558,     0.9432],
        [    0.0327,     0.7959,     0.1399,     0.0274,     0.0041],
        [    0.0001,     0.0000,     0.0002,     0.0186,     0.9810],
        [    0.9930,     0.0053,     0.0005,     0.0002,     0.0009],
        [    0.0731,     0.3417,     0.4737,     0.1093,     0.0022],
        [    0.0009,     0.0055,     0.0803,     0.4470,     0.4663],
        [    0.0005,     0.0145,     0.5519,     0.4259,     0.0072],
        [    0.1011,     0.4320,     0.4310,     0.0354,     0.0005],
        [    0.0020,     0.0362,     0.5864,     0.3557,     0.0198],
        [    0.6497,     0.3024,     0.0465,     0.0009,     0.0004],
        [    0.0000,     0.0000,     0.0008,     0.0681,     0.9309],
        [    0.0003,     0.0000,     0.0001,     0.0007,     0.9989],
        [    0.0123,     0.5089,     0.4086,     0.0615,     0.0088],
        [    0.0021,     0.9956,     0.0016,     0.0005,     0.0001],
        [    0.0034,     0.0021,     0.0233,     0.3156,     0.6556]],
       device='cuda:1')
Metric:  tensor(0.5625, device='cuda:1')
------------------------
tensor([[    0.0001,     0.0004,     0.0345,     0.5580,     0.4071],
        [    0.0001,     0.0006,     0.0223,     0.6795,     0.2974],
        [    0.0075,     0.0579,     0.5426,     0.3387,     0.0533],
        [    0.1036,     0.6123,     0.2775,     0.0066,     0.0001],
        [    0.6879,     0.2863,     0.0247,     0.0008,     0.0003],
        [    0.0000,     0.0000,     0.0013,     0.0634,     0.9352],
        [    0.0003,     0.0001,     0.0015,     0.0330,     0.9651],
        [    0.0013,     0.0020,     0.0180,     0.1316,     0.8471],
        [    0.0054,     0.0334,     0.6418,     0.2737,     0.0456],
        [    0.0038,     0.0487,     0.5443,     0.3957,     0.0075],
        [    0.0488,     0.6293,     0.3002,     0.0189,     0.0027],
        [    0.0027,     0.0671,     0.7287,     0.1742,     0.0274],
        [    0.0001,     0.0003,     0.0065,     0.3322,     0.6609],
        [    0.0001,     0.0006,     0.0018,     0.0968,     0.9006],
        [    0.9476,     0.0517,     0.0007,     0.0000,     0.0000],
        [    0.0000,     0.0001,     0.0156,     0.8799,     0.1044]],
       device='cuda:0')
Metric:  tensor(0.5000, device='cuda:0')
------------------------
Outputs:  tensor([[    0.0004,     0.0006,     0.0145,     0.3831,     0.6014],
        [    0.6811,     0.2940,     0.0234,     0.0008,     0.0007],
        [    0.1756,     0.3532,     0.4433,     0.0267,     0.0011],
        [    0.3228,     0.5477,     0.1276,     0.0017,     0.0002],
        [    0.8270,     0.1525,     0.0204,     0.0001,     0.0000],
        [    0.0198,     0.1261,     0.6401,     0.2067,     0.0073],
        [    0.8980,     0.0962,     0.0057,     0.0000,     0.0000],
        [    0.2751,     0.6936,     0.0303,     0.0009,     0.0001],
        [    0.0000,     0.0016,     0.3533,     0.5938,     0.0513],
        [    0.2264,     0.4940,     0.2703,     0.0086,     0.0007],
        [    0.2670,     0.1531,     0.2883,     0.1318,     0.1599],
        [    0.0472,     0.0578,     0.4079,     0.4123,     0.0748],
        [    0.0003,     0.0002,     0.0041,     0.1743,     0.8210],
        [    0.2059,     0.6348,     0.1174,     0.0331,     0.0088],
        [    0.0016,     0.0893,     0.8842,     0.0247,     0.0002],
        [    0.9887,     0.0112,     0.0001,     0.0000,     0.0000]],
       device='cuda:1')
Metric:  tensor(0.6250, device='cuda:1')
------------------------
tensor([[    0.0000,     0.0012,     0.0370,     0.9616,     0.0001],
        [    0.4735,     0.4591,     0.0665,     0.0008,     0.0001],
        [    0.4460,     0.4330,     0.1168,     0.0040,     0.0003],
        [    0.0007,     0.0002,     0.0016,     0.0373,     0.9602],
        [    0.7481,     0.0964,     0.0803,     0.0407,     0.0345],
        [    0.0017,     0.1001,     0.8095,     0.0883,     0.0004],
        [    0.0020,     0.0009,     0.0069,     0.1722,     0.8180],
        [    0.4604,     0.5025,     0.0370,     0.0000,     0.0000],
        [    0.0001,     0.0010,     0.3034,     0.6737,     0.0218],
        [    0.5220,     0.2264,     0.2317,     0.0198,     0.0001],
        [    0.1953,     0.5596,     0.2414,     0.0034,     0.0003],
        [    0.0002,     0.0002,     0.0043,     0.3009,     0.6945],
        [    0.0693,     0.6618,     0.2675,     0.0015,     0.0000],
        [    0.0123,     0.0972,     0.5251,     0.3003,     0.0652],
        [    0.0001,     0.0002,     0.0110,     0.3562,     0.6324],
        [    0.0004,     0.0002,     0.0035,     0.1184,     0.8776]],
       device='cuda:0')
Metric:  tensor(0.6875, device='cuda:0')
------------------------
Labels:  tensor([2, 0, 4, 4, 4, 0, 0, 2, 4, 0, 4, 0, 0, 0, 1, 2], device='cuda:1')
Preds:  tensor([2, 0, 4, 4, 4, 0, 0, 2, 4, 1, 4, 4, 0, 0, 2, 4], device='cuda:1')
Outputs:  tensor([[    0.0107,     0.0253,     0.5023,     0.3934,     0.0684],
        [    0.5159,     0.4354,     0.0464,     0.0017,     0.0006],
        [    0.0002,     0.0008,     0.0002,     0.0139,     0.9849],
        [    0.0001,     0.0000,     0.0003,     0.0425,     0.9570],
        [    0.0005,     0.0007,     0.0115,     0.2262,     0.7610],
        [    0.5997,     0.3238,     0.0719,     0.0037,     0.0009],
        [    0.7511,     0.2142,     0.0326,     0.0020,     0.0001],
        [    0.0355,     0.2640,     0.6829,     0.0175,     0.0002],
        [    0.0002,     0.0007,     0.0226,     0.2955,     0.6810],
        [    0.0811,     0.5093,     0.4021,     0.0072,     0.0002],
        [    0.0006,     0.0005,     0.0088,     0.2163,     0.7737],
        [    0.0897,     0.0640,     0.0778,     0.1249,     0.6437],
        [    0.6057,     0.3698,     0.0225,     0.0006,     0.0015],
        [    0.9117,     0.0871,     0.0012,     0.0000,     0.0000],
        [    0.0127,     0.2890,     0.6779,     0.0203,     0.0000],
        [    0.1084,     0.1682,     0.2599,     0.1155,     0.3480]],
       device='cuda:1')
Metric:  tensor(0.7500, device='cuda:1')
------------------------
Labels:  tensor([0, 1, 4, 2, 3, 2, 1, 0, 2, 2, 2, 0, 2, 4, 3, 4], device='cuda:0')
Preds:  tensor([0, 1, 4, 1, 0, 2, 1, 0, 1, 3, 3, 0, 2, 4, 0, 4], device='cuda:0')
Outputs:  tensor([[    0.5236,     0.4523,     0.0241,     0.0001,     0.0000],
        [    0.1299,     0.8502,     0.0197,     0.0001,     0.0000],
        [    0.0001,     0.0002,     0.0084,     0.2156,     0.7758],
        [    0.3679,     0.5153,     0.1149,     0.0017,     0.0002],
        [    0.6069,     0.2723,     0.1151,     0.0053,     0.0004],
        [    0.0257,     0.0281,     0.9092,     0.0256,     0.0114],
        [    0.1706,     0.5056,     0.3228,     0.0010,     0.0000],
        [    0.9360,     0.0618,     0.0019,     0.0001,     0.0001],
        [    0.3500,     0.3837,     0.2501,     0.0135,     0.0027],
        [    0.0003,     0.0025,     0.1220,     0.6717,     0.2035],
        [    0.0019,     0.0339,     0.4531,     0.4666,     0.0445],
        [    0.9062,     0.0895,     0.0041,     0.0002,     0.0000],
        [    0.0007,     0.0235,     0.5382,     0.4311,     0.0064],
        [    0.0002,     0.0002,     0.0080,     0.2027,     0.7889],
        [    0.5965,     0.3323,     0.0707,     0.0004,     0.0000],
        [    0.0001,     0.0002,     0.0002,     0.0183,     0.9812]],
       device='cuda:0')
Metric:  tensor(0.6250, device='cuda:0')
------------------------
Labels:  tensor([1, 1, 1, 1, 2, 1, 0, 0, 4, 4, 2, 1, 3, 0, 0, 1], device='cuda:0')
Preds:  tensor([3, 1, 2, 4, 2, 1, 0, 0, 4, 4, 2, 0, 2, 0, 0, 1], device='cuda:0')
Outputs:  tensor([[    0.0008,     0.0138,     0.2897,     0.5554,     0.1402],
        [    0.3244,     0.3845,     0.2812,     0.0093,     0.0005],
        [    0.0402,     0.3422,     0.5767,     0.0397,     0.0012],
        [    0.1577,     0.0933,     0.1696,     0.2057,     0.3737],
        [    0.0139,     0.4517,     0.4697,     0.0619,     0.0028],
        [    0.0722,     0.4548,     0.4437,     0.0242,     0.0051],
        [    0.8826,     0.1027,     0.0118,     0.0012,     0.0018],
        [    0.7431,     0.2499,     0.0069,     0.0000,     0.0000],
        [    0.0012,     0.0005,     0.0042,     0.1732,     0.8209],
        [    0.0004,     0.0001,     0.0013,     0.0526,     0.9456],
        [    0.0046,     0.1124,     0.8040,     0.0787,     0.0003],
        [    0.5110,     0.3642,     0.1063,     0.0085,     0.0100],
        [    0.0001,     0.0037,     0.6339,     0.3623,     0.0000],
        [    0.6437,     0.3252,     0.0300,     0.0011,     0.0000],
        [    0.7245,     0.2274,     0.0429,     0.0030,     0.0022],
        [    0.1832,     0.5834,     0.2302,     0.0031,     0.0001]],
       device='cuda:0')
Metric:  tensor(0.6875, device='cuda:0')
------------------------
Labels:  tensor([3, 2, 3, 1, 3, 4, 3, 0, 3, 1, 1, 0, 0, 3, 2, 0], device='cuda:1')
Preds:  tensor([3, 2, 3, 1, 2, 4, 3, 1, 4, 1, 1, 0, 0, 3, 2, 2], device='cuda:1')
Outputs:  tensor([[    0.0008,     0.0058,     0.3677,     0.6199,     0.0057],
        [    0.0003,     0.0137,     0.6303,     0.3497,     0.0061],
        [    0.0009,     0.0208,     0.4343,     0.5386,     0.0054],
        [    0.3987,     0.4840,     0.1162,     0.0010,     0.0001],
        [    0.0007,     0.0353,     0.9423,     0.0211,     0.0005],
        [    0.0003,     0.0003,     0.0062,     0.1932,     0.8000],
        [    0.0095,     0.0569,     0.3884,     0.4880,     0.0572],
        [    0.1889,     0.6005,     0.2093,     0.0013,     0.0000],
        [    0.0000,     0.0001,     0.0032,     0.3250,     0.6717],
        [    0.1270,     0.5955,     0.2375,     0.0357,     0.0043],
        [    0.1628,     0.5333,     0.2963,     0.0073,     0.0003],
        [    0.9488,     0.0494,     0.0017,     0.0000,     0.0000],
        [    0.6092,     0.3327,     0.0547,     0.0030,     0.0004],
        [    0.0013,     0.0302,     0.4216,     0.5204,     0.0265],
        [    0.0922,     0.3411,     0.4493,     0.0952,     0.0222],
        [    0.0503,     0.2351,     0.5936,     0.1196,     0.0015]],
       device='cuda:1')
Metric:  tensor(0.7500, device='cuda:1')
------------------------
Labels:  tensor([2, 3, 4, 0, 1, 3, 4, 3, 4, 2, 1, 0, 4, 4, 4, 4], device='cuda:1')
Preds:  tensor([1, 3, 4, 1, 2, 4, 4, 2, 4, 2, 0, 0, 4, 4, 3, 4], device='cuda:1')
Outputs:  tensor([[    0.0373,     0.5663,     0.3934,     0.0029,     0.0001],
        [    0.0001,     0.0004,     0.0564,     0.7885,     0.1548],
        [    0.0016,     0.0006,     0.0017,     0.0135,     0.9825],
        [    0.2703,     0.6734,     0.0557,     0.0005,     0.0001],
        [    0.0504,     0.1903,     0.4054,     0.2859,     0.0681],
        [    0.0010,     0.0014,     0.0238,     0.2480,     0.7259],
        [    0.0007,     0.0001,     0.0009,     0.0092,     0.9891],
        [    0.0057,     0.2666,     0.7199,     0.0076,     0.0001],
        [    0.0001,     0.0003,     0.0001,     0.0013,     0.9982],
        [    0.0008,     0.0304,     0.7424,     0.2214,     0.0051],
        [    0.5361,     0.4138,     0.0488,     0.0010,     0.0003],
        [    0.7919,     0.1915,     0.0162,     0.0003,     0.0000],
        [    0.0001,     0.0001,     0.0014,     0.0742,     0.9243],
        [    0.0020,     0.0013,     0.0255,     0.4086,     0.5626],
        [    0.0022,     0.0063,     0.1210,     0.6146,     0.2560],
        [    0.0003,     0.0001,     0.0021,     0.1533,     0.8442]],
       device='cuda:1')
Metric:  tensor(0.5625, device='cuda:1')
------------------------
Labels:  tensor([3, 3, 3, 2, 1, 3, 1, 1, 2, 2, 0, 3, 3, 4, 4, 2], device='cuda:0')
Preds:  tensor([3, 2, 2, 2, 1, 3, 1, 0, 2, 2, 0, 4, 2, 4, 4, 0], device='cuda:0')
Outputs:  tensor([[    0.0001,     0.0003,     0.0156,     0.5587,     0.4253],
        [    0.0003,     0.0060,     0.8373,     0.1429,     0.0134],
        [    0.0008,     0.0207,     0.7422,     0.2319,     0.0045],
        [    0.0301,     0.1895,     0.6770,     0.1024,     0.0010],
        [    0.3784,     0.5719,     0.0488,     0.0008,     0.0001],
        [    0.0253,     0.0701,     0.3960,     0.3992,     0.1093],
        [    0.2497,     0.6449,     0.1044,     0.0010,     0.0000],
        [    0.9890,     0.0108,     0.0002,     0.0000,     0.0000],
        [    0.0004,     0.0092,     0.5534,     0.4177,     0.0193],
        [    0.0565,     0.2974,     0.4590,     0.1772,     0.0099],
        [    0.5840,     0.3575,     0.0583,     0.0002,     0.0000],
        [    0.0000,     0.0000,     0.0001,     0.0097,     0.9901],
        [    0.0011,     0.0478,     0.6962,     0.2524,     0.0025],
        [    0.0001,     0.0001,     0.0027,     0.2013,     0.7958],
        [    0.0027,     0.0022,     0.0299,     0.1496,     0.8157],
        [    0.8274,     0.1604,     0.0117,     0.0004,     0.0001]],
       device='cuda:0')
Metric:  tensor(0.6250, device='cuda:0')
------------------------
Labels:  tensor([4, 0, 4, 0, 4, 1, 1, 3, 0, 4, 4, 3, 0, 2, 3, 0], device='cuda:0')
Preds:  tensor([4, 0, 4, 0, 4, 1, 1, 4, 0, 3, 4, 3, 1, 1, 4, 0], device='cuda:0')
Outputs:  tensor([[    0.0005,     0.0002,     0.0042,     0.1485,     0.8466],
        [    0.7411,     0.2182,     0.0398,     0.0009,     0.0001],
        [    0.0004,     0.0003,     0.0073,     0.2948,     0.6971],
        [    0.8558,     0.1389,     0.0053,     0.0000,     0.0000],
        [    0.0302,     0.0220,     0.0793,     0.1955,     0.6730],
        [    0.0023,     0.9819,     0.0141,     0.0014,     0.0002],
        [    0.1260,     0.5370,     0.3296,     0.0071,     0.0003],
        [    0.0267,     0.2050,     0.1470,     0.2074,     0.4138],
        [    0.9888,     0.0108,     0.0004,     0.0000,     0.0000],
        [    0.0011,     0.0060,     0.2001,     0.4278,     0.3649],
        [    0.0001,     0.0018,     0.0033,     0.2152,     0.7795],
        [    0.0003,     0.0044,     0.3221,     0.6341,     0.0392],
        [    0.2896,     0.6642,     0.0461,     0.0001,     0.0000],
        [    0.1260,     0.5005,     0.3573,     0.0160,     0.0002],
        [    0.0001,     0.0001,     0.0037,     0.2953,     0.7009],
        [    0.9178,     0.0775,     0.0046,     0.0001,     0.0000]],
       device='cuda:0')
Metric:  tensor(0.6875, device='cuda:0')
------------------------
Labels:  tensor([3, 2, 3, 2, 3, 0, 2, 4, 1, 1, 1, 1, 0, 0, 0, 0], device='cuda:1')
Preds:  tensor([4, 2, 2, 2, 4, 0, 1, 4, 2, 0, 1, 2, 0, 0, 0, 0], device='cuda:1')
Outputs:  tensor([[    0.0005,     0.0006,     0.0153,     0.2192,     0.7644],
        [    0.0271,     0.1403,     0.6022,     0.2240,     0.0064],
        [    0.0008,     0.0265,     0.9486,     0.0240,     0.0001],
        [    0.0028,     0.0297,     0.9537,     0.0135,     0.0003],
        [    0.0002,     0.0002,     0.0032,     0.1667,     0.8298],
        [    0.7683,     0.2230,     0.0085,     0.0002,     0.0000],
        [    0.4141,     0.4298,     0.1463,     0.0087,     0.0011],
        [    0.0009,     0.0005,     0.0029,     0.1105,     0.8852],
        [    0.0065,     0.1107,     0.7282,     0.1458,     0.0087],
        [    0.7537,     0.1023,     0.0446,     0.0269,     0.0725],
        [    0.2548,     0.6172,     0.1272,     0.0007,     0.0000],
        [    0.3299,     0.2526,     0.3888,     0.0258,     0.0029],
        [    0.9959,     0.0027,     0.0009,     0.0002,     0.0004],
        [    0.7323,     0.2339,     0.0310,     0.0018,     0.0009],
        [    0.9846,     0.0152,     0.0001,     0.0000,     0.0000],
        [    0.9996,     0.0003,     0.0001,     0.0000,     0.0000]],
       device='cuda:1')
Metric:  tensor(0.5625, device='cuda:1')
------------------------
Labels:  tensor([4, 4, 4, 2, 3, 2, 4, 1, 2, 1, 1, 2, 0, 1, 0, 1], device='cuda:1')
Preds:  tensor([4, 4, 4, 1, 2, 3, 4, 1, 2, 2, 1, 2, 0, 0, 0, 2], device='cuda:1')
Outputs:  tensor([[    0.0001,     0.0003,     0.0103,     0.1362,     0.8531],
        [    0.0002,     0.0001,     0.0066,     0.2804,     0.7127],
        [    0.0002,     0.0001,     0.0012,     0.0375,     0.9611],
        [    0.1985,     0.5775,     0.2223,     0.0016,     0.0000],
        [    0.0028,     0.0234,     0.6241,     0.2878,     0.0618],
        [    0.0001,     0.0017,     0.0996,     0.7694,     0.1292],
        [    0.0008,     0.0002,     0.0012,     0.0074,     0.9903],
        [    0.1031,     0.5182,     0.3450,     0.0330,     0.0008],
        [    0.0012,     0.0909,     0.8707,     0.0371,     0.0001],
        [    0.0324,     0.2833,     0.6035,     0.0797,     0.0010],
        [    0.3128,     0.3443,     0.2783,     0.0618,     0.0028],
        [    0.0024,     0.1586,     0.8195,     0.0193,     0.0002],
        [    0.9929,     0.0070,     0.0001,     0.0000,     0.0000],
        [    0.6859,     0.2923,     0.0213,     0.0004,     0.0000],
        [    0.7732,     0.2181,     0.0084,     0.0002,     0.0000],
        [    0.0049,     0.0974,     0.7337,     0.1629,     0.0010]],
       device='cuda:1')
Metric:  tensor(0.6250, device='cuda:1')
------------------------
Labels:  tensor([4, 1, 1, 0, 0, 1, 2, 4, 2, 4, 4, 1, 0, 1, 2, 1], device='cuda:0')
Preds:  tensor([4, 1, 0, 0, 0, 1, 2, 4, 2, 4, 4, 0, 0, 0, 2, 0], device='cuda:0')
Outputs:  tensor([[    0.0008,     0.0006,     0.0023,     0.0621,     0.9343],
        [    0.2366,     0.6317,     0.1281,     0.0033,     0.0003],
        [    0.9575,     0.0417,     0.0008,     0.0000,     0.0000],
        [    0.8629,     0.1282,     0.0084,     0.0003,     0.0003],
        [    0.7846,     0.2045,     0.0104,     0.0004,     0.0002],
        [    0.0688,     0.6354,     0.2950,     0.0008,     0.0000],
        [    0.0595,     0.2865,     0.4835,     0.1514,     0.0192],
        [    0.0000,     0.0000,     0.0002,     0.1243,     0.8755],
        [    0.0171,     0.3505,     0.6149,     0.0175,     0.0000],
        [    0.0016,     0.0010,     0.0087,     0.3236,     0.6651],
        [    0.0097,     0.0076,     0.0349,     0.0617,     0.8861],
        [    0.4367,     0.0965,     0.0969,     0.1045,     0.2654],
        [    0.9113,     0.0872,     0.0014,     0.0000,     0.0000],
        [    0.5468,     0.3260,     0.1215,     0.0047,     0.0011],
        [    0.1177,     0.2736,     0.4817,     0.1187,     0.0083],
        [    0.5896,     0.3089,     0.0960,     0.0050,     0.0006]],
       device='cuda:0')
Metric:  tensor(0.7500, device='cuda:0')
------------------------
Labels:  tensor([2, 0, 1, 3, 4, 2, 0, 0, 2, 1, 0, 1, 1, 2, 3, 4], device='cuda:0')
Preds:  tensor([4, 0, 2, 2, 4, 2, 1, 0, 1, 0, 0, 0, 0, 1, 4, 4], device='cuda:0')
Outputs:  tensor([[    0.0001,     0.0001,     0.0029,     0.1809,     0.8160],
        [    0.8359,     0.1462,     0.0173,     0.0004,     0.0001],
        [    0.0017,     0.0607,     0.8519,     0.0855,     0.0001],
        [    0.0008,     0.0495,     0.9211,     0.0286,     0.0001],
        [    0.0019,     0.0007,     0.0038,     0.0320,     0.9616],
        [    0.0049,     0.1877,     0.6243,     0.1812,     0.0019],
        [    0.4079,     0.4959,     0.0949,     0.0012,     0.0000],
        [    0.8209,     0.1492,     0.0296,     0.0003,     0.0000],
        [    0.0401,     0.7931,     0.1469,     0.0182,     0.0017],
        [    0.5368,     0.3499,     0.0991,     0.0090,     0.0053],
        [    0.9933,     0.0066,     0.0001,     0.0000,     0.0000],
        [    0.6682,     0.2494,     0.0788,     0.0036,     0.0000],
        [    0.7940,     0.1432,     0.0558,     0.0052,     0.0019],
        [    0.0182,     0.7994,     0.1571,     0.0237,     0.0015],
        [    0.0010,     0.0029,     0.0582,     0.3819,     0.5561],
        [    0.0001,     0.0001,     0.0002,     0.0425,     0.9572]],
       device='cuda:0')
Metric:  tensor(0.3750, device='cuda:0')
------------------------
Labels:  tensor([1, 1, 2, 1, 1, 4, 1, 4, 4, 1, 3, 2, 4, 3, 3, 4], device='cuda:1')
Preds:  tensor([2, 1, 2, 0, 1, 4, 0, 3, 4, 1, 2, 2, 4, 2, 4, 4], device='cuda:1')
Outputs:  tensor([[    0.0387,     0.1644,     0.4719,     0.2521,     0.0730],
        [    0.1297,     0.4551,     0.3903,     0.0243,     0.0005],
        [    0.0300,     0.2416,     0.6141,     0.1142,     0.0002],
        [    0.6278,     0.2909,     0.0805,     0.0007,     0.0000],
        [    0.3089,     0.6097,     0.0811,     0.0003,     0.0000],
        [    0.0023,     0.0023,     0.0062,     0.0851,     0.9041],
        [    0.6463,     0.3189,     0.0337,     0.0010,     0.0002],
        [    0.0001,     0.0001,     0.0063,     0.5956,     0.3979],
        [    0.0011,     0.0006,     0.0020,     0.0461,     0.9502],
        [    0.3173,     0.5935,     0.0881,     0.0011,     0.0000],
        [    0.0093,     0.1206,     0.8089,     0.0611,     0.0001],
        [    0.0008,     0.1035,     0.7068,     0.1860,     0.0029],
        [    0.0002,     0.0003,     0.0038,     0.1512,     0.8445],
        [    0.0002,     0.0111,     0.6787,     0.3003,     0.0097],
        [    0.0004,     0.0003,     0.0112,     0.1280,     0.8601],
        [    0.0001,     0.0003,     0.0124,     0.4366,     0.5505]],
       device='cuda:1')
Metric:  tensor(0.5625, device='cuda:1')
------------------------
Labels:  tensor([4, 4, 2, 0, 0, 4, 4, 1, 4, 2, 0, 1, 1, 2, 2, 1], device='cuda:1')
Preds:  tensor([4, 4, 1, 3, 0, 4, 4, 1, 4, 2, 3, 1, 2, 1, 2, 2], device='cuda:1')
Outputs:  tensor([[    0.0010,     0.0004,     0.0061,     0.0929,     0.8995],
        [    0.0010,     0.0006,     0.0046,     0.1331,     0.8606],
        [    0.4307,     0.4983,     0.0683,     0.0026,     0.0002],
        [    0.0005,     0.0029,     0.0974,     0.5522,     0.3470],
        [    0.4528,     0.1947,     0.2322,     0.0710,     0.0492],
        [    0.0019,     0.0011,     0.0042,     0.0344,     0.9583],
        [    0.0008,     0.0005,     0.0075,     0.1945,     0.7968],
        [    0.1927,     0.6446,     0.1617,     0.0009,     0.0000],
        [    0.0001,     0.0002,     0.0078,     0.2017,     0.7902],
        [    0.0564,     0.2021,     0.5735,     0.1600,     0.0081],
        [    0.0007,     0.0108,     0.3278,     0.5928,     0.0680],
        [    0.3084,     0.3753,     0.2462,     0.0540,     0.0161],
        [    0.0030,     0.0726,     0.9041,     0.0199,     0.0003],
        [    0.1875,     0.5359,     0.2674,     0.0091,     0.0001],
        [    0.0291,     0.3275,     0.4263,     0.2033,     0.0139],
        [    0.0183,     0.3409,     0.6185,     0.0218,     0.0004]],
       device='cuda:1')
Metric:  tensor(0.6250, device='cuda:1')
------------------------
Mean loss[0.9288007060657658] | Mean metric[0.6019399707174231]
Stupid loss[0.0] | Naive soulution metric[0.2]
Labels:  tensor([1, 1, 2, 4, 2, 4, 0, 2, 3, 2, 0, 1, 1, 3, 2, 0], device='cuda:0')
Preds:  tensor([1, 2, 2, 4, 0, 4, 0, 4, 4, 2, 0, 2, 0, 3, 4, 1], device='cuda:0')
Outputs:  tensor([[    0.2544,     0.5389,     0.2062,     0.0005,     0.0000],
        [    0.0894,     0.3674,     0.4245,     0.0831,     0.0355],
        [    0.0001,     0.0029,     0.9956,     0.0014,     0.0000],
        [    0.0001,     0.0002,     0.0003,     0.0474,     0.9521],
        [    0.7429,     0.1859,     0.0673,     0.0035,     0.0004],
        [    0.0003,     0.0001,     0.0004,     0.0153,     0.9839],
        [    0.9829,     0.0169,     0.0001,     0.0000,     0.0000],
        [    0.0001,     0.0000,     0.0013,     0.1157,     0.8829],
        [    0.0000,     0.0000,     0.0034,     0.3815,     0.6150],
        [    0.0591,     0.4120,     0.5240,     0.0049,     0.0000],
        [    0.4055,     0.3391,     0.2144,     0.0403,     0.0008],
        [    0.0125,     0.1857,     0.7160,     0.0846,     0.0013],
        [    0.7162,     0.2163,     0.0401,     0.0078,     0.0195],
        [    0.0017,     0.0027,     0.0394,     0.5945,     0.3617],
        [    0.0080,     0.0017,     0.0049,     0.0199,     0.9655],
        [    0.0893,     0.5659,     0.3309,     0.0138,     0.0001]],
       device='cuda:0')
Metric:  tensor(0.5000, device='cuda:0')
------------------------
Mean loss[0.9320881827654869] | Mean metric[0.6065153733528551]
Stupid loss[0.0] | Naive soulution metric[0.2]
Labels:  tensor([4, 2, 2, 0, 0, 3, 3, 0, 0, 0, 0, 1, 4, 2, 0, 4], device='cuda:0')
Preds:  tensor([4, 4, 2, 0, 0, 3, 3, 1, 0, 0, 4, 0, 3, 2, 0, 4], device='cuda:0')
Outputs:  tensor([[    0.0000,     0.0002,     0.0007,     0.1050,     0.8940],
        [    0.0007,     0.0015,     0.0211,     0.2574,     0.7194],
        [    0.0783,     0.3390,     0.4817,     0.0981,     0.0030],
        [    0.9700,     0.0294,     0.0006,     0.0000,     0.0000],
        [    0.6324,     0.3511,     0.0160,     0.0003,     0.0002],
        [    0.0001,     0.0000,     0.0008,     0.9969,     0.0022],
        [    0.0000,     0.0010,     0.1667,     0.8050,     0.0273],
        [    0.2406,     0.6689,     0.0747,     0.0076,     0.0083],
        [    0.8551,     0.1444,     0.0004,     0.0000,     0.0000],
        [    0.8322,     0.1578,     0.0096,     0.0002,     0.0003],
        [    0.0698,     0.0872,     0.0200,     0.1212,     0.7018],
        [    0.7189,     0.2705,     0.0103,     0.0003,     0.0001],
        [    0.0008,     0.0020,     0.0197,     0.8161,     0.1615],
        [    0.2165,     0.2847,     0.3458,     0.0893,     0.0637],
        [    0.7509,     0.2163,     0.0294,     0.0023,     0.0011],
        [    0.0000,     0.0001,     0.0008,     0.1004,     0.8988]],
       device='cuda:0')
Metric:  tensor(0.6875, device='cuda:0')
------------------------
Mean loss[0.9324173243846353] | Mean metric[0.6029465592972182]
Stupid loss[0.0] | Naive soulution metric[0.2]
Labels:  tensor([0, 4, 0, 3, 0, 1, 2, 1, 4, 2, 1, 1, 4, 3, 1, 3], device='cuda:1')
Preds:  tensor([0, 4, 0, 3, 0, 0, 2, 2, 3, 3, 1, 2, 4, 3, 1, 2], device='cuda:1')
Outputs:  tensor([[    0.5334,     0.4479,     0.0165,     0.0005,     0.0017],
        [    0.0006,     0.0014,     0.0081,     0.1011,     0.8888],
        [    0.8675,     0.1177,     0.0131,     0.0014,     0.0002],
        [    0.0000,     0.0004,     0.0440,     0.7579,     0.1977],
        [    0.8418,     0.1564,     0.0018,     0.0000,     0.0000],
        [    0.6381,     0.3164,     0.0440,     0.0015,     0.0001],
        [    0.1392,     0.3659,     0.4050,     0.0689,     0.0209],
        [    0.0262,     0.4065,     0.5515,     0.0152,     0.0006],
        [    0.0394,     0.0811,     0.3884,     0.4280,     0.0632],
        [    0.0003,     0.0055,     0.3209,     0.5994,     0.0740],
        [    0.0270,     0.5816,     0.3785,     0.0123,     0.0006],
        [    0.0104,     0.1512,     0.7484,     0.0873,     0.0026],
        [    0.0002,     0.0001,     0.0017,     0.2178,     0.7802],
        [    0.0000,     0.0001,     0.0440,     0.8956,     0.0603],
        [    0.0834,     0.4673,     0.4340,     0.0144,     0.0009],
        [    0.0054,     0.2769,     0.3798,     0.2988,     0.0391]],
       device='cuda:1')
Metric:  tensor(0.6250, device='cuda:1')
------------------------
Mean loss[0.9249764387784439] | Mean metric[0.6035566129819424]
Stupid loss[0.0] | Naive soulution metric[0.2]
INFO:torch.distributed.elastic.agent.server.api:[default] worker group successfully finished. Waiting 300 seconds for other agents to finish.
INFO:torch.distributed.elastic.agent.server.api:Local worker group finished (SUCCEEDED). Waiting 300 seconds for other agents to finish
INFO:torch.distributed.elastic.agent.server.api:[default] worker group successfully finished. Waiting 300 seconds for other agents to finish.
INFO:torch.distributed.elastic.agent.server.api:Local worker group finished (SUCCEEDED). Waiting 300 seconds for other agents to finish
INFO:torch.distributed.elastic.agent.server.api:Done waiting for other agents. Elapsed: 0.0004258155822753906 seconds
INFO:torch.distributed.elastic.agent.server.api:Done waiting for other agents. Elapsed: 5.551650524139404 seconds
