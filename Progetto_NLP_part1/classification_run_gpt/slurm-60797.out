Node IP: 10.128.2.153
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
  entrypoint       : train.py
  min_nodes        : 2
  max_nodes        : 2
  nproc_per_node   : 2
  run_id           : 13003
  rdzv_backend     : c10d
  rdzv_endpoint    : 10.128.2.153:29500
  rdzv_configs     : {'timeout': 900}
  max_restarts     : 0
  monitor_interval : 5
  log_dir          : None
  metrics_cfg      : {}

INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
  entrypoint       : train.py
  min_nodes        : 2
  max_nodes        : 2
  nproc_per_node   : 2
  run_id           : 13003
  rdzv_backend     : c10d
  rdzv_endpoint    : 10.128.2.153:29500
  rdzv_configs     : {'timeout': 900}
  max_restarts     : 0
  monitor_interval : 5
  log_dir          : None
  metrics_cfg      : {}

INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /tmp/torchelastic_xbmemby1/13003_vjl3pzwu
INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /tmp/torchelastic_nyvfslzi/13003_c7wh2niv
INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
  restart_count=0
  master_addr=gpu003.hpc
  master_port=36017
  group_rank=1
  group_world_size=2
  local_ranks=[0, 1]
  role_ranks=[2, 3]
  global_ranks=[2, 3]
  role_world_sizes=[4, 4]
  global_world_sizes=[4, 4]

INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
  restart_count=0
  master_addr=gpu003.hpc
  master_port=36017
  group_rank=0
  group_world_size=2
  local_ranks=[0, 1]
  role_ranks=[0, 1]
  global_ranks=[0, 1]
  role_world_sizes=[4, 4]
  global_world_sizes=[4, 4]

INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_nyvfslzi/13003_c7wh2niv/attempt_0/0/error.json
INFO:torch.distributed.elastic.agent.server.local_elastic_agent:Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /tmp/torchelastic_nyvfslzi/13003_c7wh2niv/attempt_0/1/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_xbmemby1/13003_vjl3pzwu/attempt_0/0/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /tmp/torchelastic_xbmemby1/13003_vjl3pzwu/attempt_0/1/error.json
PORT:  36017
WORLD SIZE: PORT:  4
 36017
MASTER NODE:  gpu003.hpc
WORLD SIZE:  4My slurm id is: 
 1
MASTER NODE:  gpu003.hpcMy rank is: 
 3
My slurm id is:  1
My rank is:  2
PORT:  36017
WORLD SIZE:  4
MASTER NODE:  gpu003.hpc
My slurm id is:  0
My rank is:  1
PORT:  36017
WORLD SIZE:  4
MASTER NODE:  gpu003.hpc
My slurm id is:  0
My rank is:  0
Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
------------------------

------------------------

------------------------

------------------------

Loading checkpoint...
Loading checkpoint...
Loading checkpoint...
Loading checkpoint...
Retrieving epoch...
Loading model state...
Retrieving epoch...
Loading model state...
Retrieving epoch...
Loading model state...
Retrieving epoch...
Loading model state...
Loading scheduler state...
Loading optmizer state...
Loading scheduler state...
Loading optmizer state...
Loading scheduler state...
Loading optmizer state...
Loading scheduler state...
Loading optmizer state...
LOADED!
I'm process 2 using GPU 0
LOADED!
I'm process 0 using GPU 0
LOADED!
I'm process 1 using GPU 1
LOADED!
I'm process 3 using GPU 1
Labels:  tensor([3, 0, 0, 1, 0, 3, 0, 0, 3, 1, 4, 4, 4, 1, 2, 0], device='cuda:1')
Preds:  tensor([4, 0, 2, 1, 0, 2, 0, 1, 3, 1, 2, 3, 4, 1, 2, 0], device='cuda:1')
Labels:  tensor([2, 2, 1, 1, 1, 4, 4, 4, 3, 2, 0, 3, 3, 4, 0, 3], device='cuda:0')
Preds:  Labels:  tensor([3, 3, 2, 1, 0, 4, 4, 4, 2, 2, 1, 2, 4, 4, 0, 3], device='cuda:0')
Outputs:  tensor([0, 4, 2, 3, 0, 1, 2, 2, 3, 2, 2, 4, 4, 1, 1, 2], device='cuda:1')
Preds:  tensor([0, 4, 1, 4, 0, 2, 4, 2, 2, 2, 0, 4, 4, 1, 1, 4], device='cuda:1')
Outputs:  tensor([[    0.0004,     0.0006,     0.0140,     0.3543,     0.6308],
        [    0.6781,     0.2940,     0.0261,     0.0010,     0.0008],
        [    0.1721,     0.3453,     0.4526,     0.0286,     0.0014],
        [    0.3151,     0.5424,     0.1403,     0.0020,     0.0002],
        [    0.8296,     0.1500,     0.0203,     0.0001,     0.0000],
        [    0.0197,     0.1222,     0.6243,     0.2233,     0.0105],
        [    0.8951,     0.0985,     0.0064,     0.0000,     0.0000],
        [    0.2984,     0.6685,     0.0319,     0.0010,     0.0001],
        [    0.0000,     0.0017,     0.3565,     0.5856,     0.0561],
        [    0.2172,     0.4892,     0.2832,     0.0096,     0.0007],
        [    0.2660,     0.1459,     0.2745,     0.1358,     0.1777],
        [    0.0428,     0.0516,     0.3695,     0.4360,     0.1001],
        [    0.0004,     0.0002,     0.0044,     0.1848,     0.8102],
        [    0.1718,     0.6356,     0.1353,     0.0450,     0.0124],
        [    0.0017,     0.0866,     0.8826,     0.0288,     0.0003],
        [    0.9888,     0.0111,     0.0001,     0.0000,     0.0000]],
       device='cuda:1')
Outputs:  tensor([[    0.0001,     0.0004,     0.0355,     0.5571,     0.4070],
        [    0.0001,     0.0006,     0.0225,     0.7268,     0.2500],
        [    0.0064,     0.0489,     0.4998,     0.3744,     0.0706],
        [    0.0978,     0.5932,     0.3012,     0.0076,     0.0001],
        [    0.6887,     0.2841,     0.0260,     0.0009,     0.0004],
        [    0.0000,     0.0001,     0.0014,     0.0683,     0.9302],
        [    0.0003,     0.0001,     0.0016,     0.0365,     0.9614],
        [    0.0013,     0.0018,     0.0171,     0.1349,     0.8450],
        [    0.0049,     0.0308,     0.6236,     0.2848,     0.0559],
        [    0.0035,     0.0452,     0.5286,     0.4142,     0.0085],
        [    0.0453,     0.6059,     0.3225,     0.0226,     0.0036],
        [    0.0026,     0.0617,     0.6983,     0.1959,     0.0415],
        [    0.0001,     0.0003,     0.0068,     0.3343,     0.6585],
        [    0.0001,     0.0006,     0.0018,     0.0952,     0.9024],
        [    0.9501,     0.0492,     0.0007,     0.0000,     0.0000],
        [    0.0000,     0.0001,     0.0167,     0.8711,     0.1121]],
       device='cuda:0')
Metric:  tensor(0.6250, device='cuda:1')
------------------------
Metric:  tensor(0.5000, device='cuda:0')
------------------------
tensor([[    0.7845,     0.2044,     0.0110,     0.0001,     0.0000],
        [    0.0002,     0.0001,     0.0009,     0.0616,     0.9372],
        [    0.0331,     0.7920,     0.1416,     0.0287,     0.0045],
        [    0.0001,     0.0000,     0.0003,     0.0196,     0.9801],
        [    0.9930,     0.0053,     0.0005,     0.0003,     0.0009],
        [    0.0661,     0.3139,     0.4920,     0.1250,     0.0030],
        [    0.0008,     0.0047,     0.0706,     0.4209,     0.5030],
        [    0.0005,     0.0135,     0.5378,     0.4396,     0.0086],
        [    0.0848,     0.3955,     0.4747,     0.0443,     0.0006],
        [    0.0018,     0.0331,     0.5675,     0.3746,     0.0229],
        [    0.6445,     0.3035,     0.0504,     0.0011,     0.0006],
        [    0.0000,     0.0000,     0.0009,     0.0723,     0.9267],
        [    0.0003,     0.0000,     0.0001,     0.0008,     0.9988],
        [    0.0120,     0.5013,     0.4122,     0.0648,     0.0097],
        [    0.0021,     0.9958,     0.0015,     0.0005,     0.0001],
        [    0.0036,     0.0024,     0.0253,     0.3296,     0.6391]],
       device='cuda:1')
Metric:  tensor(0.5625, device='cuda:1')
------------------------
Labels:  tensor([3, 1, 1, 4, 0, 2, 4, 1, 3, 0, 2, 3, 2, 2, 4, 4], device='cuda:0')
Preds:  tensor([3, 0, 0, 4, 0, 2, 4, 1, 3, 0, 1, 4, 1, 2, 4, 4], device='cuda:0')
Outputs:  tensor([[    0.0000,     0.0012,     0.0387,     0.9599,     0.0001],
        [    0.4744,     0.4554,     0.0692,     0.0009,     0.0002],
        [    0.4374,     0.4299,     0.1276,     0.0047,     0.0003],
        [    0.0007,     0.0002,     0.0018,     0.0406,     0.9567],
        [    0.7227,     0.0983,     0.0860,     0.0482,     0.0448],
        [    0.0015,     0.0915,     0.8113,     0.0951,     0.0005],
        [    0.0021,     0.0010,     0.0070,     0.1788,     0.8112],
        [    0.4591,     0.5006,     0.0402,     0.0000,     0.0000],
        [    0.0001,     0.0011,     0.2988,     0.6752,     0.0249],
        [    0.5293,     0.2266,     0.2254,     0.0186,     0.0001],
        [    0.1942,     0.5495,     0.2521,     0.0038,     0.0004],
        [    0.0002,     0.0002,     0.0047,     0.3110,     0.6840],
        [    0.0637,     0.6317,     0.3028,     0.0018,     0.0000],
        [    0.0115,     0.0884,     0.5034,     0.3191,     0.0776],
        [    0.0001,     0.0002,     0.0103,     0.3522,     0.6372],
        [    0.0004,     0.0002,     0.0037,     0.1252,     0.8705]],
       device='cuda:0')
Metric:  tensor(0.6875, device='cuda:0')
------------------------
Labels:  tensor([3, 2, 3, 1, 3, 4, 3, 0, 3, 1, 1, 0, 0, 3, 2, 0], device='cuda:1')
Preds:  tensor([3, 2, 3, 1, 2, 4, 3, 1, 4, 1, 1, 0, 0, 3, 2, 2], device='cuda:1')
Outputs:  tensor([[    0.0009,     0.0060,     0.3619,     0.6237,     0.0075],
        [    0.0002,     0.0125,     0.6100,     0.3701,     0.0072],
        [    0.0009,     0.0208,     0.4077,     0.5640,     0.0065],
        [    0.3969,     0.4790,     0.1229,     0.0011,     0.0001],
        [    0.0007,     0.0328,     0.9411,     0.0247,     0.0007],
        [    0.0003,     0.0003,     0.0064,     0.1959,     0.7971],
        [    0.0095,     0.0528,     0.3654,     0.5002,     0.0721],
        [    0.1863,     0.5921,     0.2201,     0.0014,     0.0000],
        [    0.0000,     0.0001,     0.0032,     0.3202,     0.6765],
        [    0.1201,     0.5863,     0.2489,     0.0396,     0.0052],
        [    0.1558,     0.5195,     0.3160,     0.0084,     0.0004],
        [    0.9522,     0.0461,     0.0017,     0.0000,     0.0000],
        [    0.6038,     0.3332,     0.0590,     0.0035,     0.0005],
        [    0.0013,     0.0283,     0.3945,     0.5425,     0.0333],
        [    0.0810,     0.3079,     0.4651,     0.1151,     0.0310],
        [    0.0439,     0.2159,     0.6066,     0.1317,     0.0018]],
       device='cuda:1')
Metric:  tensor(0.7500, device='cuda:1')
------------------------
Labels:  tensor([1, 1, 1, 1, 2, 1, 0, 0, 4, 4, 2, 1, 3, 0, 0, 1], device='cuda:0')
Preds:  tensor([3, 1, 2, 4, 2, 2, 0, 0, 4, 4, 2, 0, 2, 0, 0, 1], device='cuda:0')
Outputs:  tensor([[    0.0008,     0.0132,     0.2819,     0.5565,     0.1476],
        [    0.3167,     0.3812,     0.2915,     0.0100,     0.0006],
        [    0.0372,     0.3146,     0.5978,     0.0487,     0.0016],
        [    0.1165,     0.0745,     0.1465,     0.2148,     0.4478],
        [    0.0132,     0.4189,     0.4910,     0.0730,     0.0038],
        [    0.0672,     0.4289,     0.4700,     0.0281,     0.0057],
        [    0.8815,     0.1021,     0.0125,     0.0015,     0.0025],
        [    0.7521,     0.2407,     0.0071,     0.0000,     0.0000],
        [    0.0012,     0.0005,     0.0045,     0.1763,     0.8174],
        [    0.0004,     0.0001,     0.0014,     0.0559,     0.9423],
        [    0.0042,     0.1047,     0.8045,     0.0863,     0.0003],
        [    0.5039,     0.3590,     0.1143,     0.0104,     0.0123],
        [    0.0001,     0.0036,     0.5836,     0.4127,     0.0000],
        [    0.6430,     0.3239,     0.0319,     0.0012,     0.0000],
        [    0.7258,     0.2237,     0.0438,     0.0037,     0.0031],
        [    0.1765,     0.5765,     0.2435,     0.0035,     0.0001]],
       device='cuda:0')
Metric:  tensor(0.6250, device='cuda:0')
------------------------
Labels:  tensor([0, 1, 4, 2, 3, 2, 1, 0, 2, 2, 2, 0, 2, 4, 3, 4], device='cuda:0')
Preds:  tensor([0, 1, 4, 1, 0, 2, 1, 0, 1, 3, 3, 0, 2, 4, 0, 4], device='cuda:0')
Outputs:  tensor([[    0.5254,     0.4485,     0.0260,     0.0001,     0.0000],
        [    0.1313,     0.8453,     0.0233,     0.0002,     0.0000],
        [    0.0001,     0.0002,     0.0088,     0.2211,     0.7698],
        [    0.3642,     0.5185,     0.1155,     0.0017,     0.0002],
        [    0.5972,     0.2713,     0.1247,     0.0062,     0.0006],
        [    0.0267,     0.0287,     0.9034,     0.0272,     0.0139],
        [    0.1706,     0.4971,     0.3312,     0.0010,     0.0000],
        [    0.9381,     0.0596,     0.0020,     0.0001,     0.0002],
        [    0.3433,     0.3765,     0.2610,     0.0158,     0.0034],
        [    0.0002,     0.0022,     0.1075,     0.6610,     0.2290],
        [    0.0018,     0.0306,     0.4371,     0.4811,     0.0494],
        [    0.9062,     0.0891,     0.0044,     0.0003,     0.0001],
        [    0.0006,     0.0214,     0.5122,     0.4577,     0.0081],
        [    0.0002,     0.0002,     0.0081,     0.2103,     0.7812],
        [    0.5960,     0.3296,     0.0738,     0.0005,     0.0000],
        [    0.0001,     0.0003,     0.0002,     0.0194,     0.9800]],
       device='cuda:0')
Metric:  tensor(0.6250, device='cuda:0')
------------------------
Labels:  tensor([2, 0, 4, 4, 4, 0, 0, 2, 4, 0, 4, 0, 0, 0, 1, 2], device='cuda:1')
Preds:  tensor([2, 0, 4, 4, 4, 0, 0, 2, 4, 1, 4, 4, 0, 0, 2, 4], device='cuda:1')
Outputs:  tensor([[    0.0108,     0.0244,     0.4462,     0.4278,     0.0908],
        [    0.5108,     0.4348,     0.0516,     0.0021,     0.0007],
        [    0.0003,     0.0010,     0.0002,     0.0149,     0.9836],
        [    0.0001,     0.0000,     0.0003,     0.0414,     0.9582],
        [    0.0006,     0.0008,     0.0121,     0.2383,     0.7483],
        [    0.5845,     0.3266,     0.0829,     0.0047,     0.0012],
        [    0.7470,     0.2136,     0.0365,     0.0026,     0.0002],
        [    0.0337,     0.2600,     0.6884,     0.0177,     0.0002],
        [    0.0002,     0.0006,     0.0197,     0.2843,     0.6952],
        [    0.0775,     0.4896,     0.4243,     0.0083,     0.0003],
        [    0.0007,     0.0006,     0.0096,     0.2243,     0.7648],
        [    0.0799,     0.0578,     0.0762,     0.1335,     0.6526],
        [    0.6049,     0.3693,     0.0237,     0.0006,     0.0015],
        [    0.9142,     0.0845,     0.0013,     0.0000,     0.0000],
        [    0.0116,     0.2682,     0.6985,     0.0217,     0.0000],
        [    0.1040,     0.1575,     0.2570,     0.1230,     0.3586]],
       device='cuda:1')
Metric:  tensor(0.7500, device='cuda:1')
------------------------
Labels:  tensor([3, 2, 3, 2, 3, 0, 2, 4, 1, 1, 1, 1, 0, 0, 0, 0], device='cuda:1')
Preds:  tensor([4, 2, 2, 2, 4, 0, 1, 4, 2, 0, 1, 2, 0, 0, 0, 0], device='cuda:1')
Outputs:  tensor([[    0.0005,     0.0007,     0.0159,     0.2250,     0.7580],
        [    0.0258,     0.1339,     0.5976,     0.2349,     0.0078],
        [    0.0008,     0.0253,     0.9473,     0.0266,     0.0001],
        [    0.0025,     0.0271,     0.9540,     0.0160,     0.0005],
        [    0.0002,     0.0002,     0.0035,     0.1759,     0.8201],
        [    0.7680,     0.2233,     0.0085,     0.0001,     0.0000],
        [    0.4073,     0.4228,     0.1575,     0.0109,     0.0015],
        [    0.0010,     0.0006,     0.0032,     0.1195,     0.8757],
        [    0.0059,     0.0997,     0.7108,     0.1704,     0.0132],
        [    0.7277,     0.1003,     0.0469,     0.0329,     0.0921],
        [    0.2391,     0.6146,     0.1454,     0.0009,     0.0000],
        [    0.3255,     0.2528,     0.3918,     0.0264,     0.0034],
        [    0.9957,     0.0028,     0.0009,     0.0002,     0.0005],
        [    0.7350,     0.2304,     0.0316,     0.0020,     0.0010],
        [    0.9854,     0.0145,     0.0001,     0.0000,     0.0000],
        [    0.9995,     0.0003,     0.0001,     0.0000,     0.0000]],
       device='cuda:1')
Metric:  tensor(0.5625, device='cuda:1')
------------------------
Labels:  tensor([4, 0, 4, 0, 4, 1, 1, 3, 0, 4, 4, 3, 0, 2, 3, 0], device='cuda:0')
Preds:  tensor([4, 0, 4, 0, 4, 1, 1, 4, 0, 3, 4, 3, 1, 1, 4, 0], device='cuda:0')
Outputs:  tensor([[    0.0005,     0.0003,     0.0044,     0.1522,     0.8427],
        [    0.7418,     0.2169,     0.0402,     0.0009,     0.0001],
        [    0.0004,     0.0003,     0.0076,     0.3054,     0.6862],
        [    0.8615,     0.1332,     0.0052,     0.0001,     0.0000],
        [    0.0319,     0.0229,     0.0792,     0.1969,     0.6691],
        [    0.0025,     0.9818,     0.0140,     0.0015,     0.0002],
        [    0.1209,     0.5205,     0.3500,     0.0082,     0.0003],
        [    0.0257,     0.1753,     0.1370,     0.2064,     0.4555],
        [    0.9877,     0.0118,     0.0004,     0.0000,     0.0000],
        [    0.0010,     0.0056,     0.1848,     0.4202,     0.3884],
        [    0.0001,     0.0019,     0.0036,     0.2234,     0.7710],
        [    0.0003,     0.0044,     0.3144,     0.6384,     0.0426],
        [    0.2868,     0.6621,     0.0510,     0.0001,     0.0000],
        [    0.1219,     0.4873,     0.3729,     0.0176,     0.0002],
        [    0.0001,     0.0001,     0.0038,     0.2996,     0.6964],
        [    0.9243,     0.0714,     0.0042,     0.0001,     0.0000]],
       device='cuda:0')
Metric:  tensor(0.6875, device='cuda:0')
------------------------
Labels:  tensor([3, 3, 3, 2, 1, 3, 1, 1, 2, 2, 0, 3, 3, 4, 4, 2], device='cuda:0')
Preds:  tensor([3, 2, 2, 2, 1, 3, 1, 0, 2, 2, 0, 4, 2, 4, 4, 0], device='cuda:0')
Outputs:  tensor([[    0.0001,     0.0003,     0.0154,     0.5469,     0.4372],
        [    0.0003,     0.0059,     0.8125,     0.1621,     0.0192],
        [    0.0007,     0.0203,     0.7381,     0.2357,     0.0051],
        [    0.0291,     0.1816,     0.6836,     0.1046,     0.0012],
        [    0.3933,     0.5554,     0.0502,     0.0009,     0.0001],
        [    0.0242,     0.0670,     0.3869,     0.4056,     0.1164],
        [    0.2382,     0.6392,     0.1213,     0.0012,     0.0001],
        [    0.9893,     0.0105,     0.0002,     0.0000,     0.0000],
        [    0.0003,     0.0084,     0.5356,     0.4341,     0.0216],
        [    0.0524,     0.2702,     0.4639,     0.1996,     0.0139],
        [    0.5787,     0.3592,     0.0619,     0.0002,     0.0000],
        [    0.0001,     0.0000,     0.0002,     0.0105,     0.9893],
        [    0.0010,     0.0434,     0.6848,     0.2677,     0.0032],
        [    0.0001,     0.0001,     0.0029,     0.2066,     0.7902],
        [    0.0026,     0.0021,     0.0272,     0.1351,     0.8329],
        [    0.8143,     0.1707,     0.0144,     0.0005,     0.0001]],
       device='cuda:0')
Metric:  tensor(0.6250, device='cuda:0')
------------------------
Labels:  tensor([2, 3, 4, 0, 1, 3, 4, 3, 4, 2, 1, 0, 4, 4, 4, 4], device='cuda:1')
Preds:  tensor([1, 3, 4, 1, 2, 4, 4, 2, 4, 2, 0, 0, 4, 4, 3, 4], device='cuda:1')
Outputs:  tensor([[    0.0359,     0.5435,     0.4171,     0.0034,     0.0001],
        [    0.0001,     0.0004,     0.0561,     0.7803,     0.1632],
        [    0.0016,     0.0006,     0.0017,     0.0133,     0.9829],
        [    0.2706,     0.6700,     0.0588,     0.0005,     0.0001],
        [    0.0438,     0.1689,     0.4007,     0.3075,     0.0791],
        [    0.0009,     0.0012,     0.0193,     0.2169,     0.7616],
        [    0.0008,     0.0001,     0.0010,     0.0098,     0.9883],
        [    0.0053,     0.2558,     0.7314,     0.0073,     0.0001],
        [    0.0002,     0.0004,     0.0001,     0.0014,     0.9979],
        [    0.0007,     0.0246,     0.7122,     0.2553,     0.0073],
        [    0.5168,     0.4244,     0.0572,     0.0013,     0.0004],
        [    0.7694,     0.2109,     0.0193,     0.0003,     0.0000],
        [    0.0001,     0.0001,     0.0015,     0.0786,     0.9197],
        [    0.0020,     0.0014,     0.0258,     0.4132,     0.5577],
        [    0.0020,     0.0057,     0.1067,     0.6000,     0.2855],
        [    0.0003,     0.0001,     0.0022,     0.1576,     0.8398]],
       device='cuda:1')
Metric:  tensor(0.5625, device='cuda:1')
------------------------
Labels:  tensor([1, 1, 2, 1, 1, 4, 1, 4, 4, 1, 3, 2, 4, 3, 3, 4], device='cuda:1')
Preds:  tensor([2, 1, 2, 0, 1, 4, 0, 3, 4, 1, 2, 2, 4, 2, 4, 4], device='cuda:1')
Outputs:  tensor([[    0.0316,     0.1346,     0.4610,     0.2841,     0.0887],
        [    0.1244,     0.4326,     0.4136,     0.0287,     0.0007],
        [    0.0275,     0.2293,     0.6202,     0.1229,     0.0002],
        [    0.6341,     0.2851,     0.0800,     0.0007,     0.0000],
        [    0.3042,     0.6080,     0.0874,     0.0004,     0.0000],
        [    0.0022,     0.0022,     0.0060,     0.0837,     0.9059],
        [    0.6429,     0.3188,     0.0369,     0.0011,     0.0003],
        [    0.0001,     0.0001,     0.0064,     0.5867,     0.4068],
        [    0.0011,     0.0006,     0.0021,     0.0475,     0.9487],
        [    0.3249,     0.5816,     0.0923,     0.0012,     0.0000],
        [    0.0091,     0.1239,     0.8074,     0.0595,     0.0001],
        [    0.0008,     0.0968,     0.7101,     0.1890,     0.0033],
        [    0.0002,     0.0003,     0.0041,     0.1611,     0.8343],
        [    0.0002,     0.0111,     0.6669,     0.3100,     0.0117],
        [    0.0004,     0.0004,     0.0120,     0.1362,     0.8509],
        [    0.0001,     0.0003,     0.0126,     0.4350,     0.5520]],
       device='cuda:1')
Metric:  tensor(0.5625, device='cuda:1')
------------------------
Labels:  tensor([2, 0, 1, 3, 4, 2, 0, 0, 2, 1, 0, 1, 1, 2, 3, 4], device='cuda:0')
Preds:  tensor([4, 0, 2, 2, 4, 2, 1, 0, 1, 0, 0, 0, 0, 1, 4, 4], device='cuda:0')
Outputs:  tensor([[    0.0001,     0.0001,     0.0031,     0.1863,     0.8104],
        [    0.8247,     0.1547,     0.0199,     0.0005,     0.0001],
        [    0.0017,     0.0573,     0.8500,     0.0909,     0.0001],
        [    0.0007,     0.0469,     0.9203,     0.0319,     0.0001],
        [    0.0020,     0.0008,     0.0040,     0.0341,     0.9591],
        [    0.0043,     0.1725,     0.6305,     0.1904,     0.0023],
        [    0.4017,     0.4937,     0.1031,     0.0014,     0.0000],
        [    0.8235,     0.1462,     0.0300,     0.0003,     0.0000],
        [    0.0399,     0.7930,     0.1478,     0.0176,     0.0017],
        [    0.5451,     0.3397,     0.0991,     0.0098,     0.0064],
        [    0.9936,     0.0063,     0.0001,     0.0000,     0.0000],
        [    0.6663,     0.2499,     0.0801,     0.0037,     0.0000],
        [    0.7937,     0.1436,     0.0554,     0.0054,     0.0020],
        [    0.0185,     0.7975,     0.1573,     0.0250,     0.0017],
        [    0.0010,     0.0029,     0.0563,     0.3767,     0.5632],
        [    0.0001,     0.0001,     0.0002,     0.0446,     0.9551]],
       device='cuda:0')
Metric:  tensor(0.3750, device='cuda:0')
------------------------
Labels:  tensor([4, 1, 1, 0, 0, 1, 2, 4, 2, 4, 4, 1, 0, 1, 2, 1], device='cuda:0')
Preds:  tensor([4, 1, 0, 0, 0, 1, 2, 4, 2, 4, 4, 0, 0, 0, 2, 0], device='cuda:0')
Outputs:  tensor([[    0.0008,     0.0006,     0.0022,     0.0632,     0.9332],
        [    0.2345,     0.6212,     0.1400,     0.0039,     0.0004],
        [    0.9576,     0.0415,     0.0009,     0.0000,     0.0000],
        [    0.8575,     0.1327,     0.0091,     0.0003,     0.0003],
        [    0.7801,     0.2080,     0.0113,     0.0004,     0.0002],
        [    0.0699,     0.6218,     0.3073,     0.0009,     0.0000],
        [    0.0563,     0.2706,     0.4855,     0.1660,     0.0217],
        [    0.0000,     0.0001,     0.0002,     0.1312,     0.8685],
        [    0.0161,     0.3277,     0.6373,     0.0190,     0.0000],
        [    0.0016,     0.0010,     0.0087,     0.3123,     0.6764],
        [    0.0108,     0.0080,     0.0347,     0.0634,     0.8832],
        [    0.3924,     0.0903,     0.0982,     0.1184,     0.3007],
        [    0.9112,     0.0872,     0.0016,     0.0000,     0.0000],
        [    0.5522,     0.3188,     0.1226,     0.0051,     0.0013],
        [    0.1186,     0.2686,     0.4792,     0.1236,     0.0101],
        [    0.5809,     0.3065,     0.1054,     0.0063,     0.0009]],
       device='cuda:0')
Metric:  tensor(0.7500, device='cuda:0')
------------------------
Labels:  tensor([4, 4, 4, 2, 3, 2, 4, 1, 2, 1, 1, 2, 0, 1, 0, 1], device='cuda:1')
Preds:  tensor([4, 4, 4, 1, 2, 3, 4, 1, 2, 2, 1, 2, 0, 0, 0, 2], device='cuda:1')
Outputs:  tensor([[    0.0001,     0.0003,     0.0100,     0.1356,     0.8540],
        [    0.0002,     0.0002,     0.0069,     0.2800,     0.7128],
        [    0.0002,     0.0001,     0.0013,     0.0403,     0.9581],
        [    0.1967,     0.5759,     0.2258,     0.0017,     0.0000],
        [    0.0027,     0.0223,     0.5951,     0.2991,     0.0808],
        [    0.0002,     0.0019,     0.1015,     0.7586,     0.1378],
        [    0.0008,     0.0002,     0.0011,     0.0077,     0.9901],
        [    0.0999,     0.5091,     0.3548,     0.0352,     0.0009],
        [    0.0013,     0.0890,     0.8714,     0.0382,     0.0001],
        [    0.0312,     0.2740,     0.6100,     0.0837,     0.0011],
        [    0.3038,     0.3347,     0.2882,     0.0698,     0.0035],
        [    0.0025,     0.1564,     0.8204,     0.0205,     0.0002],
        [    0.9932,     0.0067,     0.0001,     0.0000,     0.0000],
        [    0.6975,     0.2805,     0.0215,     0.0004,     0.0000],
        [    0.7663,     0.2234,     0.0100,     0.0002,     0.0001],
        [    0.0047,     0.0936,     0.7275,     0.1730,     0.0012]],
       device='cuda:1')
Metric:  tensor(0.6250, device='cuda:1')
------------------------
Labels:  tensor([0, 4, 0, 3, 0, 1, 2, 1, 4, 2, 1, 1, 4, 3, 1, 3], device='cuda:1')
Preds:  tensor([0, 4, 0, 3, 0, 0, 2, 2, 3, 3, 1, 2, 4, 3, 2, 2], device='cuda:1')
Outputs:  tensor([[    0.5472,     0.4334,     0.0165,     0.0006,     0.0023],
        [    0.0007,     0.0014,     0.0083,     0.1051,     0.8845],
        [    0.8675,     0.1160,     0.0143,     0.0018,     0.0004],
        [    0.0000,     0.0005,     0.0441,     0.7532,     0.2022],
        [    0.8475,     0.1507,     0.0018,     0.0000,     0.0000],
        [    0.6286,     0.3182,     0.0511,     0.0020,     0.0001],
        [    0.1319,     0.3413,     0.4197,     0.0790,     0.0281],
        [    0.0258,     0.3888,     0.5679,     0.0167,     0.0008],
        [    0.0365,     0.0750,     0.3724,     0.4404,     0.0757],
        [    0.0003,     0.0053,     0.3118,     0.6051,     0.0776],
        [    0.0277,     0.5724,     0.3857,     0.0134,     0.0008],
        [    0.0091,     0.1299,     0.7526,     0.1045,     0.0039],
        [    0.0002,     0.0001,     0.0018,     0.2293,     0.7685],
        [    0.0000,     0.0001,     0.0429,     0.8921,     0.0649],
        [    0.0789,     0.4446,     0.4581,     0.0172,     0.0011],
        [    0.0051,     0.2476,     0.3702,     0.3252,     0.0519]],
       device='cuda:1')
Metric:  tensor(0.5625, device='cuda:1')
------------------------
Mean loss[0.9284073828400025] | Mean metric[0.6011774036115178]
Stupid loss[0.0] | Naive soulution metric[0.2]
Freezed:  module.transformer.wte.weight
Freezed:  module.transformer.wpe.weight
Freezed:  module.transformer.h.0.ln_1.weight
Freezed:  module.transformer.h.0.ln_1.bias
Freezed:  module.transformer.h.0.attn.c_attn.weight
Freezed:  module.transformer.h.0.attn.c_attn.bias
Freezed:  module.transformer.h.0.attn.c_proj.weight
Freezed:  module.transformer.h.0.attn.c_proj.bias
Freezed:  module.transformer.h.0.ln_2.weight
Freezed:  module.transformer.h.0.ln_2.bias
Freezed:  module.transformer.h.0.mlp.c_fc.weight
Freezed:  module.transformer.h.0.mlp.c_fc.bias
Freezed:  module.transformer.h.0.mlp.c_proj.weight
Freezed:  module.transformer.h.0.mlp.c_proj.bias
Freezed:  module.transformer.h.1.ln_1.weight
Freezed:  module.transformer.h.1.ln_1.bias
Freezed:  module.transformer.h.1.attn.c_attn.weight
Freezed:  module.transformer.h.1.attn.c_attn.bias
Freezed:  module.transformer.h.1.attn.c_proj.weight
Freezed:  module.transformer.h.1.attn.c_proj.bias
Freezed:  module.transformer.h.1.ln_2.weight
Freezed:  module.transformer.h.1.ln_2.bias
Freezed:  module.transformer.h.1.mlp.c_fc.weight
Freezed:  module.transformer.h.1.mlp.c_fc.bias
Freezed:  module.transformer.h.1.mlp.c_proj.weight
Freezed:  module.transformer.h.1.mlp.c_proj.bias
Freezed:  module.transformer.h.2.ln_1.weight
Freezed:  module.transformer.h.2.ln_1.bias
Freezed:  module.transformer.h.2.attn.c_attn.weight
Labels:  tensor([4, 2, 2, 0, 0, 3, 3, 0, 0, 0, 0, 1, 4, 2, 0, 4], device='cuda:0')
Freezed:  module.transformer.h.2.attn.c_attn.bias
Freezed:  module.transformer.h.2.attn.c_proj.weight
Freezed:  module.transformer.h.2.attn.c_proj.bias
Freezed:  module.transformer.h.2.ln_2.weight
Freezed:  module.transformer.h.2.ln_2.bias
Freezed:  module.transformer.h.2.mlp.c_fc.weight
Freezed:  module.transformer.h.2.mlp.c_fc.bias
Freezed:  module.transformer.h.2.mlp.c_proj.weight
Freezed:  module.transformer.h.2.mlp.c_proj.bias
Freezed:  module.transformer.h.3.ln_1.weight
Freezed:  module.transformer.h.3.ln_1.bias
Freezed:  module.transformer.h.3.attn.c_attn.weight
Freezed:  module.transformer.h.3.attn.c_attn.bias
Freezed:  module.transformer.h.3.attn.c_proj.weight
Freezed:  module.transformer.h.3.attn.c_proj.bias
Freezed:  module.transformer.h.3.ln_2.weight
Freezed:  module.transformer.h.3.ln_2.bias
Freezed:  module.transformer.h.3.mlp.c_fc.weight
Freezed:  module.transformer.h.3.mlp.c_fc.bias
Freezed:  module.transformer.h.3.mlp.c_proj.weight
Freezed:  module.transformer.h.3.mlp.c_proj.bias
Freezed:  module.transformer.h.4.ln_1.weight
Freezed:  module.transformer.h.4.ln_1.bias
Freezed:  module.transformer.h.4.attn.c_attn.weight
Freezed:  module.transformer.h.4.attn.c_attn.bias
Freezed:  module.transformer.h.4.attn.c_proj.weight
Freezed:  module.transformer.h.4.attn.c_proj.bias
Freezed:  module.transformer.h.4.ln_2.weight
Freezed:  module.transformer.h.4.ln_2.bias
Freezed:  module.transformer.h.4.mlp.c_fc.weight
Freezed:  module.transformer.h.4.mlp.c_fc.bias
Freezed:  module.transformer.h.4.mlp.c_proj.weight
Freezed:  module.transformer.h.4.mlp.c_proj.bias
Freezed:  module.transformer.h.5.ln_1.weight
Freezed:  module.transformer.h.5.ln_1.bias
Freezed:  module.transformer.h.5.attn.c_attn.weight
Freezed:  module.transformer.h.5.attn.c_attn.bias
Freezed:  module.transformer.h.5.attn.c_proj.weight
Freezed:  module.transformer.h.5.attn.c_proj.bias
Freezed:  module.transformer.h.5.ln_2.weight
Freezed:  module.transformer.h.5.ln_2.bias
Freezed:  module.transformer.h.5.mlp.c_fc.weight
Freezed:  module.transformer.h.5.mlp.c_fc.bias
Freezed:  module.transformer.h.5.mlp.c_proj.weight
Freezed:  module.transformer.h.5.mlp.c_proj.bias
Preds:  tensor([4, 4, 2, 0, 0, 3, 3, 1, 0, 0, 4, 0, 3, 2, 0, 4], device='cuda:0')
EPOCH 3
--------------
Outputs:  tensor([[    0.0001,     0.0003,     0.0008,     0.1183,     0.8806],
        [    0.0007,     0.0015,     0.0211,     0.2630,     0.7136],
        [    0.0789,     0.3420,     0.4778,     0.0980,     0.0033],
        [    0.9691,     0.0302,     0.0006,     0.0000,     0.0000],
        [    0.6242,     0.3580,     0.0172,     0.0003,     0.0003],
        [    0.0001,     0.0000,     0.0008,     0.9970,     0.0021],
        [    0.0001,     0.0010,     0.1575,     0.8094,     0.0321],
        [    0.2437,     0.6568,     0.0807,     0.0084,     0.0103],
        [    0.8528,     0.1467,     0.0005,     0.0000,     0.0000],
        [    0.8342,     0.1554,     0.0099,     0.0002,     0.0003],
        [    0.0548,     0.0672,     0.0176,     0.1282,     0.7321],
        [    0.7265,     0.2625,     0.0106,     0.0003,     0.0001],
        [    0.0007,     0.0020,     0.0205,     0.8101,     0.1667],
        [    0.2110,     0.2727,     0.3448,     0.0975,     0.0740],
        [    0.7564,     0.2098,     0.0300,     0.0026,     0.0013],
        [    0.0000,     0.0001,     0.0008,     0.1031,     0.8961]],
       device='cuda:0')
Metric:  tensor(0.6875, device='cuda:0')
------------------------
Mean loss[0.936229544872188] | Mean metric[0.6007198633479747]
Stupid loss[0.0] | Naive soulution metric[0.2]
Freezed:  module.transformer.wte.weight
Freezed:  module.transformer.wpe.weight
Freezed:  module.transformer.h.0.ln_1.weight
Freezed:  module.transformer.h.0.ln_1.bias
Freezed:  module.transformer.h.0.attn.c_attn.weight
Freezed:  module.transformer.h.0.attn.c_attn.bias
Freezed:  module.transformer.h.0.attn.c_proj.weight
Freezed:  module.transformer.h.0.attn.c_proj.bias
Freezed:  module.transformer.h.0.ln_2.weight
Freezed:  module.transformer.h.0.ln_2.bias
Freezed:  module.transformer.h.0.mlp.c_fc.weight
Freezed:  module.transformer.h.0.mlp.c_fc.bias
Freezed:  module.transformer.h.0.mlp.c_proj.weight
Freezed:  module.transformer.h.0.mlp.c_proj.bias
Freezed:  module.transformer.h.1.ln_1.weight
Freezed:  module.transformer.h.1.ln_1.bias
Freezed:  module.transformer.h.1.attn.c_attn.weight
Freezed:  module.transformer.h.1.attn.c_attn.bias
Freezed:  module.transformer.h.1.attn.c_proj.weight
Freezed:  module.transformer.h.1.attn.c_proj.bias
Freezed:  module.transformer.h.1.ln_2.weight
Freezed:  module.transformer.h.1.ln_2.bias
Freezed:  module.transformer.h.1.mlp.c_fc.weight
Freezed:  module.transformer.h.1.mlp.c_fc.bias
Freezed:  module.transformer.h.1.mlp.c_proj.weight
Freezed:  module.transformer.h.1.mlp.c_proj.bias
Freezed:  module.transformer.h.2.ln_1.weight
Freezed:  module.transformer.h.2.ln_1.bias
Freezed:  module.transformer.h.2.attn.c_attn.weight
Freezed:  module.transformer.h.2.attn.c_attn.bias
Freezed:  module.transformer.h.2.attn.c_proj.weight
Freezed:  module.transformer.h.2.attn.c_proj.bias
Freezed:  module.transformer.h.2.ln_2.weight
Freezed:  module.transformer.h.2.ln_2.bias
Freezed:  module.transformer.h.2.mlp.c_fc.weight
Freezed:  module.transformer.h.2.mlp.c_fc.bias
Freezed:  module.transformer.h.2.mlp.c_proj.weight
Freezed:  module.transformer.h.2.mlp.c_proj.bias
Freezed:  module.transformer.h.3.ln_1.weight
Freezed:  module.transformer.h.3.ln_1.bias
Freezed:  module.transformer.h.3.attn.c_attn.weight
Freezed:  module.transformer.h.3.attn.c_attn.bias
Freezed:  module.transformer.h.3.attn.c_proj.weight
Freezed:  module.transformer.h.3.attn.c_proj.bias
Freezed:  module.transformer.h.3.ln_2.weight
Freezed:  module.transformer.h.3.ln_2.bias
Freezed:  module.transformer.h.3.mlp.c_fc.weight
Freezed:  module.transformer.h.3.mlp.c_fc.bias
Freezed:  module.transformer.h.3.mlp.c_proj.weight
Freezed:  module.transformer.h.3.mlp.c_proj.bias
Freezed:  module.transformer.h.4.ln_1.weight
Freezed:  module.transformer.h.4.ln_1.bias
Freezed:  module.transformer.h.4.attn.c_attn.weight
Freezed:  module.transformer.h.4.attn.c_attn.bias
Freezed:  module.transformer.h.4.attn.c_proj.weight
Freezed:  module.transformer.h.4.attn.c_proj.bias
Freezed:  module.transformer.h.4.ln_2.weight
Freezed:  module.transformer.h.4.ln_2.bias
Freezed:  module.transformer.h.4.mlp.c_fc.weight
Freezed:  module.transformer.h.4.mlp.c_fc.bias
Freezed:  module.transformer.h.4.mlp.c_proj.weight
Freezed:  module.transformer.h.4.mlp.c_proj.bias
Freezed:  module.transformer.h.5.ln_1.weight
Freezed:  module.transformer.h.5.ln_1.bias
Freezed:  module.transformer.h.5.attn.c_attn.weight
Freezed:  module.transformer.h.5.attn.c_attn.bias
Freezed:  module.transformer.h.5.attn.c_proj.weight
Freezed:  module.transformer.h.5.attn.c_proj.bias
Freezed:  module.transformer.h.5.ln_2.weight
Freezed:  module.transformer.h.5.ln_2.bias
Freezed:  module.transformer.h.5.mlp.c_fc.weight
Freezed:  module.transformer.h.5.mlp.c_fc.bias
Freezed:  module.transformer.h.5.mlp.c_proj.weight
Freezed:  module.transformer.h.5.mlp.c_proj.bias
EPOCH 3
--------------
Labels:  tensor([1, 1, 2, 4, 2, 4, 0, 2, 3, 2, 0, 1, 1, 3, 2, 0], device='cuda:0')
Preds:  tensor([1, 2, 2, 4, 0, 4, 0, 4, 4, 2, 0, 2, 0, 3, 4, 1], device='cuda:0')
Outputs:  tensor([[    0.2488,     0.5339,     0.2167,     0.0005,     0.0000],
        [    0.0789,     0.3217,     0.4372,     0.1083,     0.0538],
        [    0.0001,     0.0028,     0.9956,     0.0014,     0.0000],
        [    0.0001,     0.0003,     0.0003,     0.0498,     0.9496],
        [    0.7431,     0.1867,     0.0662,     0.0036,     0.0005],
        [    0.0003,     0.0001,     0.0005,     0.0164,     0.9827],
        [    0.9832,     0.0166,     0.0001,     0.0000,     0.0000],
        [    0.0001,     0.0001,     0.0014,     0.1198,     0.8787],
        [    0.0000,     0.0000,     0.0037,     0.3894,     0.6068],
        [    0.0534,     0.3945,     0.5467,     0.0054,     0.0000],
        [    0.3875,     0.3323,     0.2298,     0.0495,     0.0009],
        [    0.0125,     0.1768,     0.7148,     0.0941,     0.0017],
        [    0.6936,     0.2206,     0.0481,     0.0108,     0.0269],
        [    0.0018,     0.0028,     0.0398,     0.6027,     0.3529],
        [    0.0086,     0.0017,     0.0048,     0.0206,     0.9642],
        [    0.0840,     0.5486,     0.3519,     0.0155,     0.0001]],
       device='cuda:0')
Metric:  tensor(0.5000, device='cuda:0')
------------------------
Mean loss[0.9353864741011211] | Mean metric[0.6033430941922889]
Stupid loss[0.0] | Naive soulution metric[0.2]
Freezed:  module.transformer.wte.weight
Freezed:  module.transformer.wpe.weight
Freezed:  module.transformer.h.0.ln_1.weight
Freezed:  module.transformer.h.0.ln_1.bias
Freezed:  module.transformer.h.0.attn.c_attn.weight
Freezed:  module.transformer.h.0.attn.c_attn.bias
Freezed:  module.transformer.h.0.attn.c_proj.weight
Freezed:  module.transformer.h.0.attn.c_proj.bias
Freezed:  module.transformer.h.0.ln_2.weight
Freezed:  module.transformer.h.0.ln_2.bias
Freezed:  module.transformer.h.0.mlp.c_fc.weight
Freezed:  module.transformer.h.0.mlp.c_fc.bias
Freezed:  module.transformer.h.0.mlp.c_proj.weight
Freezed:  module.transformer.h.0.mlp.c_proj.bias
Freezed:  module.transformer.h.1.ln_1.weight
Freezed:  module.transformer.h.1.ln_1.bias
Freezed:  module.transformer.h.1.attn.c_attn.weight
Freezed:  module.transformer.h.1.attn.c_attn.bias
Freezed:  module.transformer.h.1.attn.c_proj.weight
Freezed:  module.transformer.h.1.attn.c_proj.bias
Freezed:  module.transformer.h.1.ln_2.weight
Freezed:  module.transformer.h.1.ln_2.bias
Freezed:  module.transformer.h.1.mlp.c_fc.weight
Freezed:  module.transformer.h.1.mlp.c_fc.bias
Freezed:  module.transformer.h.1.mlp.c_proj.weight
Freezed:  module.transformer.h.1.mlp.c_proj.bias
Freezed:  module.transformer.h.2.ln_1.weight
Freezed:  module.transformer.h.2.ln_1.bias
Freezed:  module.transformer.h.2.attn.c_attn.weight
Freezed:  module.transformer.h.2.attn.c_attn.bias
Freezed:  module.transformer.h.2.attn.c_proj.weight
Freezed:  module.transformer.h.2.attn.c_proj.bias
Freezed:  module.transformer.h.2.ln_2.weight
Freezed:  module.transformer.h.2.ln_2.bias
Freezed:  module.transformer.h.2.mlp.c_fc.weight
Freezed:  module.transformer.h.2.mlp.c_fc.bias
Freezed:  module.transformer.h.2.mlp.c_proj.weight
Freezed:  module.transformer.h.2.mlp.c_proj.bias
Freezed:  module.transformer.h.3.ln_1.weight
Freezed:  module.transformer.h.3.ln_1.bias
Freezed:  module.transformer.h.3.attn.c_attn.weight
Freezed:  module.transformer.h.3.attn.c_attn.bias
Freezed:  module.transformer.h.3.attn.c_proj.weight
Freezed:  module.transformer.h.3.attn.c_proj.bias
Freezed:  module.transformer.h.3.ln_2.weight
Freezed:  module.transformer.h.3.ln_2.bias
Freezed:  module.transformer.h.3.mlp.c_fc.weight
Freezed:  module.transformer.h.3.mlp.c_fc.bias
Freezed:  module.transformer.h.3.mlp.c_proj.weight
Freezed:  module.transformer.h.3.mlp.c_proj.bias
Freezed:  module.transformer.h.4.ln_1.weight
Freezed:  module.transformer.h.4.ln_1.bias
Freezed:  module.transformer.h.4.attn.c_attn.weight
Freezed:  module.transformer.h.4.attn.c_attn.bias
Freezed:  module.transformer.h.4.attn.c_proj.weight
Freezed:  module.transformer.h.4.attn.c_proj.bias
Freezed:  module.transformer.h.4.ln_2.weight
Freezed:  module.transformer.h.4.ln_2.bias
Freezed:  module.transformer.h.4.mlp.c_fc.weight
Freezed:  module.transformer.h.4.mlp.c_fc.bias
Freezed:  module.transformer.h.4.mlp.c_proj.weight
Freezed:  module.transformer.h.4.mlp.c_proj.bias
Freezed:  module.transformer.h.5.ln_1.weight
Freezed:  module.transformer.h.5.ln_1.bias
Freezed:  module.transformer.h.5.attn.c_attn.weight
Freezed:  module.transformer.h.5.attn.c_attn.bias
Freezed:  module.transformer.h.5.attn.c_proj.weight
Freezed:  module.transformer.h.5.attn.c_proj.bias
Freezed:  module.transformer.h.5.ln_2.weight
Freezed:  module.transformer.h.5.ln_2.bias
Freezed:  module.transformer.h.5.mlp.c_fc.weight
Freezed:  module.transformer.h.5.mlp.c_fc.bias
Freezed:  module.transformer.h.5.mlp.c_proj.weight
Freezed:  module.transformer.h.5.mlp.c_proj.bias
EPOCH 3
--------------
Labels:  tensor([4, 4, 2, 0, 0, 4, 4, 1, 4, 2, 0, 1, 1, 2, 2, 1], device='cuda:1')
Preds:  tensor([4, 4, 1, 3, 0, 4, 4, 1, 4, 2, 3, 1, 2, 1, 2, 2], device='cuda:1')
Outputs:  tensor([[    0.0012,     0.0005,     0.0070,     0.1038,     0.8875],
        [    0.0011,     0.0007,     0.0045,     0.1292,     0.8646],
        [    0.4223,     0.4997,     0.0747,     0.0031,     0.0002],
        [    0.0004,     0.0025,     0.0876,     0.5425,     0.3670],
        [    0.4504,     0.1887,     0.2281,     0.0749,     0.0578],
        [    0.0018,     0.0011,     0.0039,     0.0329,     0.9604],
        [    0.0008,     0.0006,     0.0081,     0.2034,     0.7872],
        [    0.1727,     0.6469,     0.1793,     0.0011,     0.0000],
        [    0.0001,     0.0002,     0.0079,     0.2012,     0.7907],
        [    0.0562,     0.2037,     0.5708,     0.1610,     0.0083],
        [    0.0007,     0.0100,     0.3006,     0.5990,     0.0898],
        [    0.2845,     0.3521,     0.2657,     0.0719,     0.0258],
        [    0.0030,     0.0709,     0.9034,     0.0223,     0.0004],
        [    0.1801,     0.5101,     0.2977,     0.0119,     0.0002],
        [    0.0264,     0.3189,     0.4240,     0.2125,     0.0181],
        [    0.0174,     0.3250,     0.6327,     0.0244,     0.0005]],
       device='cuda:1')
Metric:  tensor(0.6250, device='cuda:1')
------------------------
Mean loss[0.9319543179039143] | Mean metric[0.5998657881893606]
Stupid loss[0.0] | Naive soulution metric[0.2]
Freezed:  module.transformer.wte.weight
Freezed:  module.transformer.wpe.weight
Freezed:  module.transformer.h.0.ln_1.weight
Freezed:  module.transformer.h.0.ln_1.bias
Freezed:  module.transformer.h.0.attn.c_attn.weight
Freezed:  module.transformer.h.0.attn.c_attn.bias
Freezed:  module.transformer.h.0.attn.c_proj.weight
Freezed:  module.transformer.h.0.attn.c_proj.bias
Freezed:  module.transformer.h.0.ln_2.weight
Freezed:  module.transformer.h.0.ln_2.bias
Freezed:  module.transformer.h.0.mlp.c_fc.weight
Freezed:  module.transformer.h.0.mlp.c_fc.bias
Freezed:  module.transformer.h.0.mlp.c_proj.weight
Freezed:  module.transformer.h.0.mlp.c_proj.bias
Freezed:  module.transformer.h.1.ln_1.weight
Freezed:  module.transformer.h.1.ln_1.bias
Freezed:  module.transformer.h.1.attn.c_attn.weight
Freezed:  module.transformer.h.1.attn.c_attn.bias
Freezed:  module.transformer.h.1.attn.c_proj.weight
Freezed:  module.transformer.h.1.attn.c_proj.bias
Freezed:  module.transformer.h.1.ln_2.weight
Freezed:  module.transformer.h.1.ln_2.bias
Freezed:  module.transformer.h.1.mlp.c_fc.weight
Freezed:  module.transformer.h.1.mlp.c_fc.bias
Freezed:  module.transformer.h.1.mlp.c_proj.weight
Freezed:  module.transformer.h.1.mlp.c_proj.bias
Freezed:  module.transformer.h.2.ln_1.weight
Freezed:  module.transformer.h.2.ln_1.bias
Freezed:  module.transformer.h.2.attn.c_attn.weight
Freezed:  module.transformer.h.2.attn.c_attn.bias
Freezed:  module.transformer.h.2.attn.c_proj.weight
Freezed:  module.transformer.h.2.attn.c_proj.bias
Freezed:  module.transformer.h.2.ln_2.weight
Freezed:  module.transformer.h.2.ln_2.bias
Freezed:  module.transformer.h.2.mlp.c_fc.weight
Freezed:  module.transformer.h.2.mlp.c_fc.bias
Freezed:  module.transformer.h.2.mlp.c_proj.weight
Freezed:  module.transformer.h.2.mlp.c_proj.bias
Freezed:  module.transformer.h.3.ln_1.weight
Freezed:  module.transformer.h.3.ln_1.bias
Freezed:  module.transformer.h.3.attn.c_attn.weight
Freezed:  module.transformer.h.3.attn.c_attn.bias
Freezed:  module.transformer.h.3.attn.c_proj.weight
Freezed:  module.transformer.h.3.attn.c_proj.bias
Freezed:  module.transformer.h.3.ln_2.weight
Freezed:  module.transformer.h.3.ln_2.bias
Freezed:  module.transformer.h.3.mlp.c_fc.weight
Freezed:  module.transformer.h.3.mlp.c_fc.bias
Freezed:  module.transformer.h.3.mlp.c_proj.weight
Freezed:  module.transformer.h.3.mlp.c_proj.bias
Freezed:  module.transformer.h.4.ln_1.weight
Freezed:  module.transformer.h.4.ln_1.bias
Freezed:  module.transformer.h.4.attn.c_attn.weight
Freezed:  module.transformer.h.4.attn.c_attn.bias
Freezed:  module.transformer.h.4.attn.c_proj.weight
Freezed:  module.transformer.h.4.attn.c_proj.bias
Freezed:  module.transformer.h.4.ln_2.weight
Freezed:  module.transformer.h.4.ln_2.bias
Freezed:  module.transformer.h.4.mlp.c_fc.weight
Freezed:  module.transformer.h.4.mlp.c_fc.bias
Freezed:  module.transformer.h.4.mlp.c_proj.weight
Freezed:  module.transformer.h.4.mlp.c_proj.bias
Freezed:  module.transformer.h.5.ln_1.weight
Freezed:  module.transformer.h.5.ln_1.bias
Freezed:  module.transformer.h.5.attn.c_attn.weight
Freezed:  module.transformer.h.5.attn.c_attn.bias
Freezed:  module.transformer.h.5.attn.c_proj.weight
Freezed:  module.transformer.h.5.attn.c_proj.bias
Freezed:  module.transformer.h.5.ln_2.weight
Freezed:  module.transformer.h.5.ln_2.bias
Freezed:  module.transformer.h.5.mlp.c_fc.weight
Freezed:  module.transformer.h.5.mlp.c_fc.bias
Freezed:  module.transformer.h.5.mlp.c_proj.weight
Freezed:  module.transformer.h.5.mlp.c_proj.bias
EPOCH 3
--------------
Step[500] | Loss[0.9223931431770325] | Lr[4.000000000000001e-07]
Step[500] | Loss[0.638446033000946] | Lr[4.000000000000001e-07]
Step[500] | Loss[0.7210552096366882] | Lr[4.000000000000001e-07]Step[500] | Loss[0.5835193991661072] | Lr[4.000000000000001e-07]

Step[1000] | Loss[0.3449845612049103] | Lr[4.000000000000001e-07]
Step[1000] | Loss[0.905507504940033] | Lr[4.000000000000001e-07]
Step[1000] | Loss[0.9146347641944885] | Lr[4.000000000000001e-07]
Step[1000] | Loss[0.7768194675445557] | Lr[4.000000000000001e-07]
Step[1500] | Loss[0.5521858930587769] | Lr[4.000000000000001e-07]
Step[1500] | Loss[0.9897630214691162] | Lr[4.000000000000001e-07]
Step[1500] | Loss[0.8102951645851135] | Lr[4.000000000000001e-07]
Step[1500] | Loss[0.5680151581764221] | Lr[4.000000000000001e-07]
Step[2000] | Loss[0.6740279793739319] | Lr[4.000000000000001e-07]
Step[2000] | Loss[0.5762519240379333] | Lr[4.000000000000001e-07]
Step[2000] | Loss[0.7732254862785339] | Lr[4.000000000000001e-07]
Step[2000] | Loss[1.2202073335647583] | Lr[4.000000000000001e-07]
Step[2500] | Loss[0.39582863450050354] | Lr[4.000000000000001e-07]
Step[2500] | Loss[0.7609109878540039] | Lr[4.000000000000001e-07]
Step[2500] | Loss[0.8438769578933716] | Lr[4.000000000000001e-07]
Step[2500] | Loss[0.46109139919281006] | Lr[4.000000000000001e-07]
Step[3000] | Loss[0.6723878383636475] | Lr[4.000000000000001e-07]
Step[3000] | Loss[0.8046315312385559] | Lr[4.000000000000001e-07]
Step[3000] | Loss[0.6780136823654175] | Lr[4.000000000000001e-07]
Step[3000] | Loss[0.5701371431350708] | Lr[4.000000000000001e-07]
Step[3500] | Loss[0.698502779006958] | Lr[4.000000000000001e-07]
Step[3500] | Loss[0.4836909770965576] | Lr[4.000000000000001e-07]
Step[3500] | Loss[0.4000154733657837] | Lr[4.000000000000001e-07]
Step[3500] | Loss[0.6820176243782043] | Lr[4.000000000000001e-07]
Step[4000] | Loss[0.6069502234458923] | Lr[4.000000000000001e-07]
Step[4000] | Loss[0.6531885266304016] | Lr[4.000000000000001e-07]
Step[4000] | Loss[0.4843403398990631] | Lr[4.000000000000001e-07]
Step[4000] | Loss[0.4552658498287201] | Lr[4.000000000000001e-07]
Step[4500] | Loss[0.9164125323295593] | Lr[4.000000000000001e-07]
Step[4500] | Loss[0.5161343216896057] | Lr[4.000000000000001e-07]
Step[4500] | Loss[0.27048736810684204] | Lr[4.000000000000001e-07]
Step[4500] | Loss[0.5202396512031555] | Lr[4.000000000000001e-07]
Step[5000] | Loss[0.5246350765228271] | Lr[4.000000000000001e-07]
Step[5000] | Loss[0.7435215711593628] | Lr[4.000000000000001e-07]
Step[5000] | Loss[0.7029827833175659] | Lr[4.000000000000001e-07]
Step[5000] | Loss[0.5505670309066772] | Lr[4.000000000000001e-07]
Step[5500] | Loss[0.13436150550842285] | Lr[4.000000000000001e-07]
Step[5500] | Loss[0.7861185073852539] | Lr[4.000000000000001e-07]
Step[5500] | Loss[0.7703106999397278] | Lr[4.000000000000001e-07]
Step[5500] | Loss[0.7088292241096497] | Lr[4.000000000000001e-07]
Step[6000] | Loss[0.7036046385765076] | Lr[4.000000000000001e-07]
Step[6000] | Loss[0.5052617788314819] | Lr[4.000000000000001e-07]
Step[6000] | Loss[0.6285966038703918] | Lr[4.000000000000001e-07]
Step[6000] | Loss[0.25168806314468384] | Lr[4.000000000000001e-07]
Step[6500] | Loss[0.8541911840438843] | Lr[4.000000000000001e-07]
Step[6500] | Loss[0.613429605960846] | Lr[4.000000000000001e-07]
Step[6500] | Loss[0.5140479803085327] | Lr[4.000000000000001e-07]
Step[6500] | Loss[0.6264954805374146] | Lr[4.000000000000001e-07]
Step[7000] | Loss[0.947257399559021] | Lr[4.000000000000001e-07]
Step[7000] | Loss[0.44410645961761475] | Lr[4.000000000000001e-07]
Step[7000] | Loss[0.8997876644134521] | Lr[4.000000000000001e-07]
Step[7000] | Loss[0.8609253168106079] | Lr[4.000000000000001e-07]
Step[7500] | Loss[0.4489962160587311] | Lr[4.000000000000001e-07]
Step[7500] | Loss[0.7771151661872864] | Lr[4.000000000000001e-07]
Step[7500] | Loss[0.6484674215316772] | Lr[4.000000000000001e-07]
Step[7500] | Loss[0.8076205849647522] | Lr[4.000000000000001e-07]
Step[8000] | Loss[0.6104450225830078] | Lr[4.000000000000001e-07]
Step[8000] | Loss[0.6285513043403625] | Lr[4.000000000000001e-07]
Step[8000] | Loss[0.5480113625526428] | Lr[4.000000000000001e-07]
Step[8000] | Loss[1.0553293228149414] | Lr[4.000000000000001e-07]
Step[8500] | Loss[0.469880074262619] | Lr[4.000000000000001e-07]
Step[8500] | Loss[0.6053428649902344] | Lr[4.000000000000001e-07]
Step[8500] | Loss[0.6724838018417358] | Lr[4.000000000000001e-07]
Step[8500] | Loss[0.547143280506134] | Lr[4.000000000000001e-07]
Step[9000] | Loss[0.49159327149391174] | Lr[4.000000000000001e-07]
Step[9000] | Loss[0.5983074903488159] | Lr[4.000000000000001e-07]
Step[9000] | Loss[0.7981720566749573] | Lr[4.000000000000001e-07]
Step[9000] | Loss[1.1004161834716797] | Lr[4.000000000000001e-07]
Step[9500] | Loss[0.6603924036026001] | Lr[4.000000000000001e-07]
Step[9500] | Loss[0.5560689568519592] | Lr[4.000000000000001e-07]
Step[9500] | Loss[1.1439858675003052] | Lr[4.000000000000001e-07]
Step[9500] | Loss[0.8896868824958801] | Lr[4.000000000000001e-07]
Step[10000] | Loss[0.6117426753044128] | Lr[4.000000000000001e-07]
Step[10000] | Loss[0.674351692199707] | Lr[4.000000000000001e-07]
Step[10000] | Loss[0.8737066388130188] | Lr[4.000000000000001e-07]
Step[10000] | Loss[0.4959752857685089] | Lr[4.000000000000001e-07]
Step[10500] | Loss[0.4645494222640991] | Lr[4.000000000000001e-07]
Step[10500] | Loss[0.4428084194660187] | Lr[4.000000000000001e-07]
Step[10500] | Loss[0.5707059502601624] | Lr[4.000000000000001e-07]
Step[10500] | Loss[0.7904408574104309] | Lr[4.000000000000001e-07]
Step[11000] | Loss[0.6992803812026978] | Lr[4.000000000000001e-07]
Step[11000] | Loss[0.5015053749084473] | Lr[4.000000000000001e-07]
Step[11000] | Loss[0.5909733772277832] | Lr[4.000000000000001e-07]
Step[11000] | Loss[0.7456023693084717] | Lr[4.000000000000001e-07]
Step[11500] | Loss[0.3578384816646576] | Lr[4.000000000000001e-07]
Step[11500] | Loss[0.9531890153884888] | Lr[4.000000000000001e-07]
Step[11500] | Loss[0.8718522191047668] | Lr[4.000000000000001e-07]
Step[11500] | Loss[0.5888819098472595] | Lr[4.000000000000001e-07]
Step[12000] | Loss[0.7925369143486023] | Lr[4.000000000000001e-07]
Step[12000] | Loss[0.5506783127784729] | Lr[4.000000000000001e-07]
Step[12000] | Loss[0.9265360236167908] | Lr[4.000000000000001e-07]
Step[12000] | Loss[0.44069981575012207] | Lr[4.000000000000001e-07]
Step[12500] | Loss[0.5190830826759338] | Lr[4.000000000000001e-07]
Step[12500] | Loss[0.5927958488464355] | Lr[4.000000000000001e-07]
Step[12500] | Loss[0.20595340430736542] | Lr[4.000000000000001e-07]
Step[12500] | Loss[0.8958008289337158] | Lr[4.000000000000001e-07]
Step[13000] | Loss[0.5969266295433044] | Lr[4.000000000000001e-07]
Step[13000] | Loss[0.924701988697052] | Lr[4.000000000000001e-07]
Step[13000] | Loss[0.9269787073135376] | Lr[4.000000000000001e-07]
Step[13000] | Loss[0.9049230217933655] | Lr[4.000000000000001e-07]
Step[13500] | Loss[0.8313263058662415] | Lr[4.000000000000001e-07]
Step[13500] | Loss[0.7816322445869446] | Lr[4.000000000000001e-07]
Step[13500] | Loss[1.1258732080459595] | Lr[4.000000000000001e-07]
Step[13500] | Loss[0.3958268463611603] | Lr[4.000000000000001e-07]
Step[14000] | Loss[0.6074464321136475] | Lr[4.000000000000001e-07]
Step[14000] | Loss[0.6440963745117188] | Lr[4.000000000000001e-07]
Step[14000] | Loss[0.46738845109939575] | Lr[4.000000000000001e-07]
Step[14000] | Loss[0.51256263256073] | Lr[4.000000000000001e-07]
Step[14500] | Loss[0.6788564920425415] | Lr[4.000000000000001e-07]
Step[14500] | Loss[1.2145216464996338] | Lr[4.000000000000001e-07]
Step[14500] | Loss[0.5849000215530396] | Lr[4.000000000000001e-07]
Step[14500] | Loss[0.4587652385234833] | Lr[4.000000000000001e-07]
Step[15000] | Loss[0.4665495753288269] | Lr[4.000000000000001e-07]
Step[15000] | Loss[0.7989068627357483] | Lr[4.000000000000001e-07]
Step[15000] | Loss[0.6099147200584412] | Lr[4.000000000000001e-07]
Step[15000] | Loss[0.44878217577934265] | Lr[4.000000000000001e-07]
Step[15500] | Loss[0.8334030508995056] | Lr[4.000000000000001e-07]
Step[15500] | Loss[1.0329418182373047] | Lr[4.000000000000001e-07]
Step[15500] | Loss[0.6563753485679626] | Lr[4.000000000000001e-07]
Step[15500] | Loss[0.7128516435623169] | Lr[4.000000000000001e-07]
Step[16000] | Loss[0.8730265498161316] | Lr[4.000000000000001e-07]
Step[16000] | Loss[0.75250244140625] | Lr[4.000000000000001e-07]
Step[16000] | Loss[0.6910106539726257] | Lr[4.000000000000001e-07]
Step[16000] | Loss[0.6136852502822876] | Lr[4.000000000000001e-07]
Step[16500] | Loss[0.6197801828384399] | Lr[4.000000000000001e-07]
Step[16500] | Loss[0.8128519058227539] | Lr[4.000000000000001e-07]
Step[16500] | Loss[0.47623777389526367] | Lr[4.000000000000001e-07]
Step[16500] | Loss[0.5005365610122681] | Lr[4.000000000000001e-07]
Step[17000] | Loss[0.6205800175666809] | Lr[4.000000000000001e-07]
Step[17000] | Loss[0.9461537599563599] | Lr[4.000000000000001e-07]
Step[17000] | Loss[0.3658851385116577] | Lr[4.000000000000001e-07]
Step[17000] | Loss[0.46422016620635986] | Lr[4.000000000000001e-07]
Step[17500] | Loss[0.7244104743003845] | Lr[4.000000000000001e-07]
Step[17500] | Loss[0.6420986652374268] | Lr[4.000000000000001e-07]
Step[17500] | Loss[0.6347489356994629] | Lr[4.000000000000001e-07]
Step[17500] | Loss[0.5776847004890442] | Lr[4.000000000000001e-07]
Step[18000] | Loss[0.6171868443489075] | Lr[4.000000000000001e-07]
Step[18000] | Loss[0.6356770396232605] | Lr[4.000000000000001e-07]
Step[18000] | Loss[0.7603089213371277] | Lr[4.000000000000001e-07]
Step[18000] | Loss[1.0210013389587402] | Lr[4.000000000000001e-07]
Step[18500] | Loss[0.5921204090118408] | Lr[4.000000000000001e-07]
Step[18500] | Loss[0.4020587205886841] | Lr[4.000000000000001e-07]
Step[18500] | Loss[0.5476481914520264] | Lr[4.000000000000001e-07]
Step[18500] | Loss[1.1615840196609497] | Lr[4.000000000000001e-07]
Step[19000] | Loss[0.4155084788799286] | Lr[4.000000000000001e-07]
Step[19000] | Loss[0.7950019836425781] | Lr[4.000000000000001e-07]
Step[19000] | Loss[0.541828453540802] | Lr[4.000000000000001e-07]
Step[19000] | Loss[0.6390432715415955] | Lr[4.000000000000001e-07]
Step[19500] | Loss[0.6265408396720886] | Lr[4.000000000000001e-07]
Step[19500] | Loss[0.7027592062950134] | Lr[4.000000000000001e-07]
Step[19500] | Loss[0.9739720225334167] | Lr[4.000000000000001e-07]
Step[19500] | Loss[0.43411633372306824] | Lr[4.000000000000001e-07]
Step[20000] | Loss[0.7247920632362366] | Lr[4.000000000000001e-07]
Step[20000] | Loss[0.834370493888855] | Lr[4.000000000000001e-07]
Step[20000] | Loss[0.7363142967224121] | Lr[4.000000000000001e-07]
Step[20000] | Loss[0.6003925800323486] | Lr[4.000000000000001e-07]
Step[20500] | Loss[0.5292303562164307] | Lr[4.000000000000001e-07]
Step[20500] | Loss[0.6739512085914612] | Lr[4.000000000000001e-07]
Step[20500] | Loss[0.8338268995285034] | Lr[4.000000000000001e-07]
Step[20500] | Loss[0.7847907543182373] | Lr[4.000000000000001e-07]
Step[21000] | Loss[0.7540023922920227] | Lr[4.000000000000001e-07]
Step[21000] | Loss[0.804236114025116] | Lr[4.000000000000001e-07]
Step[21000] | Loss[0.4983336925506592] | Lr[4.000000000000001e-07]
Step[21000] | Loss[0.5558100342750549] | Lr[4.000000000000001e-07]
Step[21500] | Loss[0.8657346963882446] | Lr[4.000000000000001e-07]
Step[21500] | Loss[0.6202907562255859] | Lr[4.000000000000001e-07]
Step[21500] | Loss[1.053000807762146] | Lr[4.000000000000001e-07]
Step[21500] | Loss[0.36781468987464905] | Lr[4.000000000000001e-07]
Step[22000] | Loss[0.8080944418907166] | Lr[4.000000000000001e-07]
Step[22000] | Loss[0.6581174731254578] | Lr[4.000000000000001e-07]
Step[22000] | Loss[0.866105318069458] | Lr[4.000000000000001e-07]
Step[22000] | Loss[1.0441174507141113] | Lr[4.000000000000001e-07]
Step[22500] | Loss[1.0081849098205566] | Lr[4.000000000000001e-07]
Step[22500] | Loss[0.5566187500953674] | Lr[4.000000000000001e-07]
Step[22500] | Loss[0.6735661029815674] | Lr[4.000000000000001e-07]
Step[22500] | Loss[0.6655252575874329] | Lr[4.000000000000001e-07]
Step[23000] | Loss[0.7117723822593689] | Lr[4.000000000000001e-07]
Step[23000] | Loss[0.3609994351863861] | Lr[4.000000000000001e-07]
Step[23000] | Loss[0.7750014066696167] | Lr[4.000000000000001e-07]
Step[23000] | Loss[0.9913056492805481] | Lr[4.000000000000001e-07]
Step[23500] | Loss[0.5266546607017517] | Lr[4.000000000000001e-07]
Step[23500] | Loss[0.7954838871955872] | Lr[4.000000000000001e-07]
Step[23500] | Loss[0.48186999559402466] | Lr[4.000000000000001e-07]
Step[23500] | Loss[0.7616732120513916] | Lr[4.000000000000001e-07]
Step[24000] | Loss[0.7281526923179626] | Lr[4.000000000000001e-07]
Step[24000] | Loss[0.6374509334564209] | Lr[4.000000000000001e-07]
Step[24000] | Loss[0.5615147948265076] | Lr[4.000000000000001e-07]
Step[24000] | Loss[0.8340359330177307] | Lr[4.000000000000001e-07]
Step[24500] | Loss[0.5347643494606018] | Lr[4.000000000000001e-07]
Step[24500] | Loss[0.8005865812301636] | Lr[4.000000000000001e-07]
Step[24500] | Loss[0.6784620881080627] | Lr[4.000000000000001e-07]
Step[24500] | Loss[0.9698505401611328] | Lr[4.000000000000001e-07]
Step[25000] | Loss[0.44544270634651184] | Lr[4.000000000000001e-07]
Step[25000] | Loss[0.6001209616661072] | Lr[4.000000000000001e-07]
Step[25000] | Loss[0.4147776663303375] | Lr[4.000000000000001e-07]
Step[25000] | Loss[0.6228213310241699] | Lr[4.000000000000001e-07]
Step[25500] | Loss[0.8449394702911377] | Lr[4.000000000000001e-07]
Step[25500] | Loss[0.5857625603675842] | Lr[4.000000000000001e-07]
Step[25500] | Loss[0.5461860299110413] | Lr[4.000000000000001e-07]
Step[25500] | Loss[0.5462595820426941] | Lr[4.000000000000001e-07]
Step[26000] | Loss[0.5937383770942688] | Lr[4.000000000000001e-07]
Step[26000] | Loss[0.5707862973213196] | Lr[4.000000000000001e-07]
Step[26000] | Loss[0.8615851998329163] | Lr[4.000000000000001e-07]
Step[26000] | Loss[1.1966878175735474] | Lr[4.000000000000001e-07]
Step[26500] | Loss[0.4618701934814453] | Lr[4.000000000000001e-07]
Step[26500] | Loss[0.5592433214187622] | Lr[4.000000000000001e-07]
Step[26500] | Loss[0.5742196440696716] | Lr[4.000000000000001e-07]
Step[26500] | Loss[0.6164266467094421] | Lr[4.000000000000001e-07]
Step[27000] | Loss[0.5537073612213135] | Lr[4.000000000000001e-07]
Step[27000] | Loss[0.8681840896606445] | Lr[4.000000000000001e-07]
Step[27000] | Loss[0.8699356317520142] | Lr[4.000000000000001e-07]
Step[27000] | Loss[0.6665639281272888] | Lr[4.000000000000001e-07]
Step[27500] | Loss[0.4366103410720825] | Lr[4.000000000000001e-07]
Step[27500] | Loss[0.5207287669181824] | Lr[4.000000000000001e-07]
Step[27500] | Loss[0.6320366263389587] | Lr[4.000000000000001e-07]
Step[27500] | Loss[1.2181185483932495] | Lr[4.000000000000001e-07]
Step[28000] | Loss[0.7801241278648376] | Lr[4.000000000000001e-07]
Step[28000] | Loss[1.003404974937439] | Lr[4.000000000000001e-07]
Step[28000] | Loss[0.5040349364280701] | Lr[4.000000000000001e-07]
Step[28000] | Loss[0.623832106590271] | Lr[4.000000000000001e-07]
Step[28500] | Loss[0.5481464862823486] | Lr[4.000000000000001e-07]
Step[28500] | Loss[0.6900900602340698] | Lr[4.000000000000001e-07]
Step[28500] | Loss[0.7395666241645813] | Lr[4.000000000000001e-07]
Step[28500] | Loss[0.674274206161499] | Lr[4.000000000000001e-07]
Step[29000] | Loss[0.3506055474281311] | Lr[4.000000000000001e-07]
Step[29000] | Loss[0.8509587645530701] | Lr[4.000000000000001e-07]
Step[29000] | Loss[0.3674137592315674] | Lr[4.000000000000001e-07]
Step[29000] | Loss[0.3547728359699249] | Lr[4.000000000000001e-07]
Step[29500] | Loss[0.775684118270874] | Lr[4.000000000000001e-07]
Step[29500] | Loss[0.8513196706771851] | Lr[4.000000000000001e-07]
Step[29500] | Loss[1.1999576091766357] | Lr[4.000000000000001e-07]
Step[29500] | Loss[0.3662223815917969] | Lr[4.000000000000001e-07]
Step[30000] | Loss[0.5058501362800598] | Lr[4.000000000000001e-07]
Step[30000] | Loss[0.6336435675621033] | Lr[4.000000000000001e-07]
Step[30000] | Loss[0.573762059211731] | Lr[4.000000000000001e-07]
Step[30000] | Loss[0.74251788854599] | Lr[4.000000000000001e-07]
Step[30500] | Loss[0.7305369973182678] | Lr[4.000000000000001e-07]
Step[30500] | Loss[0.4382106363773346] | Lr[4.000000000000001e-07]
Step[30500] | Loss[0.5247602462768555] | Lr[4.000000000000001e-07]
Step[30500] | Loss[0.46239373087882996] | Lr[4.000000000000001e-07]
Step[31000] | Loss[0.6494618058204651] | Lr[4.000000000000001e-07]
Step[31000] | Loss[0.5752301812171936] | Lr[4.000000000000001e-07]
Step[31000] | Loss[0.40057843923568726] | Lr[4.000000000000001e-07]
Step[31000] | Loss[0.5111412405967712] | Lr[4.000000000000001e-07]
Step[31500] | Loss[0.5870410799980164] | Lr[4.000000000000001e-07]
Step[31500] | Loss[0.6833332777023315] | Lr[4.000000000000001e-07]
Step[31500] | Loss[0.6653041839599609] | Lr[4.000000000000001e-07]
Step[31500] | Loss[0.6332508325576782] | Lr[4.000000000000001e-07]
Step[32000] | Loss[0.7650943994522095] | Lr[4.000000000000001e-07]
Step[32000] | Loss[0.9385417699813843] | Lr[4.000000000000001e-07]
Step[32000] | Loss[0.6487872004508972] | Lr[4.000000000000001e-07]
Step[32000] | Loss[1.0813744068145752] | Lr[4.000000000000001e-07]
Step[32500] | Loss[0.7423726916313171] | Lr[4.000000000000001e-07]
Step[32500] | Loss[0.5689385533332825] | Lr[4.000000000000001e-07]
Step[32500] | Loss[0.5885075926780701] | Lr[4.000000000000001e-07]
Step[32500] | Loss[0.5414061546325684] | Lr[4.000000000000001e-07]
Step[33000] | Loss[1.043518304824829] | Lr[4.000000000000001e-07]
Step[33000] | Loss[0.5972790718078613] | Lr[4.000000000000001e-07]
Step[33000] | Loss[0.4890899062156677] | Lr[4.000000000000001e-07]
Step[33000] | Loss[0.8120567798614502] | Lr[4.000000000000001e-07]
Step[33500] | Loss[1.1411168575286865] | Lr[4.000000000000001e-07]
Step[33500] | Loss[0.6543967127799988] | Lr[4.000000000000001e-07]Step[33500] | Loss[0.6145397424697876] | Lr[4.000000000000001e-07]

Step[33500] | Loss[0.5059196949005127] | Lr[4.000000000000001e-07]
Step[34000] | Loss[0.5925784707069397] | Lr[4.000000000000001e-07]
Step[34000] | Loss[0.6388769149780273] | Lr[4.000000000000001e-07]
Step[34000] | Loss[0.7325760126113892] | Lr[4.000000000000001e-07]
Step[34000] | Loss[0.759986400604248] | Lr[4.000000000000001e-07]
Step[34500] | Loss[0.38486576080322266] | Lr[4.000000000000001e-07]
Step[34500] | Loss[0.9216955304145813] | Lr[4.000000000000001e-07]
Step[34500] | Loss[0.7693357467651367] | Lr[4.000000000000001e-07]
Step[34500] | Loss[1.0050214529037476] | Lr[4.000000000000001e-07]
Step[35000] | Loss[0.3628610074520111] | Lr[4.000000000000001e-07]
Step[35000] | Loss[0.6727224588394165] | Lr[4.000000000000001e-07]
Step[35000] | Loss[0.4600781798362732] | Lr[4.000000000000001e-07]
Step[35000] | Loss[0.5664507746696472] | Lr[4.000000000000001e-07]
Step[35500] | Loss[0.34548622369766235] | Lr[4.000000000000001e-07]
Step[35500] | Loss[0.6271602511405945] | Lr[4.000000000000001e-07]
Step[35500] | Loss[0.6624782085418701] | Lr[4.000000000000001e-07]
Step[35500] | Loss[0.6813188791275024] | Lr[4.000000000000001e-07]
Step[36000] | Loss[0.6309287548065186] | Lr[4.000000000000001e-07]
Step[36000] | Loss[0.869502067565918] | Lr[4.000000000000001e-07]
Step[36000] | Loss[0.7308924198150635] | Lr[4.000000000000001e-07]
Step[36000] | Loss[0.5098706483840942] | Lr[4.000000000000001e-07]
Step[36500] | Loss[0.5608218908309937] | Lr[4.000000000000001e-07]
Step[36500] | Loss[0.7750401496887207] | Lr[4.000000000000001e-07]
Step[36500] | Loss[0.6387555003166199] | Lr[4.000000000000001e-07]
Step[36500] | Loss[0.9037721753120422] | Lr[4.000000000000001e-07]
Step[37000] | Loss[0.8200508952140808] | Lr[4.000000000000001e-07]
Step[37000] | Loss[0.4327971935272217] | Lr[4.000000000000001e-07]
Step[37000] | Loss[0.5653679966926575] | Lr[4.000000000000001e-07]
Step[37000] | Loss[0.47116726636886597] | Lr[4.000000000000001e-07]
Step[37500] | Loss[1.0710999965667725] | Lr[4.000000000000001e-07]
Step[37500] | Loss[0.5727388858795166] | Lr[4.000000000000001e-07]
Step[37500] | Loss[0.6942163109779358] | Lr[4.000000000000001e-07]
Step[37500] | Loss[0.44049692153930664] | Lr[4.000000000000001e-07]
Step[38000] | Loss[0.9770675301551819] | Lr[4.000000000000001e-07]
Step[38000] | Loss[0.9784802198410034] | Lr[4.000000000000001e-07]
Step[38000] | Loss[0.9346736669540405] | Lr[4.000000000000001e-07]
Step[38000] | Loss[1.004492998123169] | Lr[4.000000000000001e-07]
Step[38500] | Loss[0.5612462162971497] | Lr[4.000000000000001e-07]
Step[38500] | Loss[0.5509068965911865] | Lr[4.000000000000001e-07]
Step[38500] | Loss[0.4338681101799011] | Lr[4.000000000000001e-07]
Step[38500] | Loss[0.8093757629394531] | Lr[4.000000000000001e-07]
Step[39000] | Loss[0.34616366028785706] | Lr[4.000000000000001e-07]
Step[39000] | Loss[0.5659817457199097] | Lr[4.000000000000001e-07]
Step[39000] | Loss[1.1089085340499878] | Lr[4.000000000000001e-07]
Step[39000] | Loss[0.7923688292503357] | Lr[4.000000000000001e-07]
Step[39500] | Loss[0.46517467498779297] | Lr[4.000000000000001e-07]
Step[39500] | Loss[0.48705992102622986] | Lr[4.000000000000001e-07]
Step[39500] | Loss[0.4059653580188751] | Lr[4.000000000000001e-07]
Step[39500] | Loss[0.6625683307647705] | Lr[4.000000000000001e-07]
Step[40000] | Loss[0.5533405542373657] | Lr[4.000000000000001e-07]
Step[40000] | Loss[0.7330113649368286] | Lr[4.000000000000001e-07]
Step[40000] | Loss[0.8389787673950195] | Lr[4.000000000000001e-07]
Step[40000] | Loss[0.4819871783256531] | Lr[4.000000000000001e-07]
Step[40500] | Loss[0.9214818477630615] | Lr[4.000000000000001e-07]
Step[40500] | Loss[0.8264040946960449] | Lr[4.000000000000001e-07]
Step[40500] | Loss[0.7190900444984436] | Lr[4.000000000000001e-07]
Step[40500] | Loss[0.4735580384731293] | Lr[4.000000000000001e-07]
Step[41000] | Loss[0.6855502724647522] | Lr[4.000000000000001e-07]
Step[41000] | Loss[0.7147516012191772] | Lr[4.000000000000001e-07]
Step[41000] | Loss[0.6754257082939148] | Lr[4.000000000000001e-07]
Step[41000] | Loss[0.4538900852203369] | Lr[4.000000000000001e-07]
Step[41500] | Loss[0.6345061659812927] | Lr[4.000000000000001e-07]
Step[41500] | Loss[0.4527320861816406] | Lr[4.000000000000001e-07]
Step[41500] | Loss[0.6523061394691467] | Lr[4.000000000000001e-07]
Step[41500] | Loss[0.7393389344215393] | Lr[4.000000000000001e-07]
Step[42000] | Loss[0.7020523548126221] | Lr[4.000000000000001e-07]
Step[42000] | Loss[0.8068690299987793] | Lr[4.000000000000001e-07]
Step[42000] | Loss[0.7848669290542603] | Lr[4.000000000000001e-07]
Step[42000] | Loss[0.6638957858085632] | Lr[4.000000000000001e-07]
Step[42500] | Loss[0.9009901285171509] | Lr[4.000000000000001e-07]
Step[42500] | Loss[0.8237449526786804] | Lr[4.000000000000001e-07]
Step[42500] | Loss[0.63648521900177] | Lr[4.000000000000001e-07]
Step[42500] | Loss[0.5516601204872131] | Lr[4.000000000000001e-07]
Step[43000] | Loss[0.57763671875] | Lr[4.000000000000001e-07]
Step[43000] | Loss[0.7096760272979736] | Lr[4.000000000000001e-07]
Step[43000] | Loss[0.59586101770401] | Lr[4.000000000000001e-07]
Step[43000] | Loss[0.5127096772193909] | Lr[4.000000000000001e-07]
Step[43500] | Loss[0.5207523703575134] | Lr[4.000000000000001e-07]
Step[43500] | Loss[0.34205761551856995] | Lr[4.000000000000001e-07]
Step[43500] | Loss[0.8521071672439575] | Lr[4.000000000000001e-07]
Step[43500] | Loss[0.7238657474517822] | Lr[4.000000000000001e-07]
Step[44000] | Loss[0.5866641402244568] | Lr[4.000000000000001e-07]
Step[44000] | Loss[0.4889101982116699] | Lr[4.000000000000001e-07]
Step[44000] | Loss[0.91057288646698] | Lr[4.000000000000001e-07]
Step[44000] | Loss[0.6413246989250183] | Lr[4.000000000000001e-07]
Step[44500] | Loss[0.6905593872070312] | Lr[4.000000000000001e-07]
Step[44500] | Loss[0.4800262749195099] | Lr[4.000000000000001e-07]
Step[44500] | Loss[0.6758648753166199] | Lr[4.000000000000001e-07]
Step[44500] | Loss[0.6640402674674988] | Lr[4.000000000000001e-07]
Step[45000] | Loss[0.5178090929985046] | Lr[4.000000000000001e-07]
Step[45000] | Loss[0.4854864478111267] | Lr[4.000000000000001e-07]
Step[45000] | Loss[0.5703449845314026] | Lr[4.000000000000001e-07]
Step[45000] | Loss[0.8778883814811707] | Lr[4.000000000000001e-07]
Step[45500] | Loss[0.746539294719696] | Lr[4.000000000000001e-07]
Step[45500] | Loss[0.662891685962677] | Lr[4.000000000000001e-07]
Step[45500] | Loss[0.7087357044219971] | Lr[4.000000000000001e-07]
Step[45500] | Loss[0.41943812370300293] | Lr[4.000000000000001e-07]
Step[46000] | Loss[0.37437522411346436] | Lr[4.000000000000001e-07]
Step[46000] | Loss[0.5625978112220764] | Lr[4.000000000000001e-07]
Step[46000] | Loss[0.7211238145828247] | Lr[4.000000000000001e-07]
Step[46000] | Loss[0.5126907825469971] | Lr[4.000000000000001e-07]
Step[46500] | Loss[0.4227546453475952] | Lr[4.000000000000001e-07]
Step[46500] | Loss[0.5943425893783569] | Lr[4.000000000000001e-07]
Step[46500] | Loss[0.40948382019996643] | Lr[4.000000000000001e-07]
Step[46500] | Loss[0.6608114838600159] | Lr[4.000000000000001e-07]
Step[47000] | Loss[0.6556044220924377] | Lr[4.000000000000001e-07]
Step[47000] | Loss[0.456716924905777] | Lr[4.000000000000001e-07]
Step[47000] | Loss[0.44593802094459534] | Lr[4.000000000000001e-07]
Step[47000] | Loss[0.8934441804885864] | Lr[4.000000000000001e-07]
Step[47500] | Loss[1.2622376680374146] | Lr[4.000000000000001e-07]
Step[47500] | Loss[0.5723616480827332] | Lr[4.000000000000001e-07]
Step[47500] | Loss[0.4548882842063904] | Lr[4.000000000000001e-07]
Step[47500] | Loss[0.5251781940460205] | Lr[4.000000000000001e-07]
Step[48000] | Loss[0.49880993366241455] | Lr[4.000000000000001e-07]
Step[48000] | Loss[0.4264950454235077] | Lr[4.000000000000001e-07]
Step[48000] | Loss[0.841616690158844] | Lr[4.000000000000001e-07]
Step[48000] | Loss[0.7948557734489441] | Lr[4.000000000000001e-07]
Step[48500] | Loss[0.4103546440601349] | Lr[4.000000000000001e-07]
Step[48500] | Loss[0.4500162899494171] | Lr[4.000000000000001e-07]
Step[48500] | Loss[0.7643962502479553] | Lr[4.000000000000001e-07]
Step[48500] | Loss[0.41462332010269165] | Lr[4.000000000000001e-07]
Step[49000] | Loss[0.4953625202178955] | Lr[4.000000000000001e-07]
Step[49000] | Loss[0.652165412902832] | Lr[4.000000000000001e-07]
Step[49000] | Loss[0.661650538444519] | Lr[4.000000000000001e-07]
Step[49000] | Loss[0.9438544511795044] | Lr[4.000000000000001e-07]
Step[49500] | Loss[0.49327853322029114] | Lr[4.000000000000001e-07]
Step[49500] | Loss[0.8896174430847168] | Lr[4.000000000000001e-07]
Step[49500] | Loss[0.7463722229003906] | Lr[4.000000000000001e-07]
Step[49500] | Loss[0.5625471472740173] | Lr[4.000000000000001e-07]
Step[50000] | Loss[0.6622087955474854] | Lr[4.000000000000001e-07]
Step[50000] | Loss[0.4806729257106781] | Lr[4.000000000000001e-07]
Step[50000] | Loss[0.5457420945167542] | Lr[4.000000000000001e-07]
Step[50000] | Loss[0.8458629846572876] | Lr[4.000000000000001e-07]
Step[50500] | Loss[0.8228009343147278] | Lr[4.000000000000001e-07]
Step[50500] | Loss[1.1725773811340332] | Lr[4.000000000000001e-07]
Step[50500] | Loss[0.8181569576263428] | Lr[4.000000000000001e-07]
Step[50500] | Loss[0.8227843046188354] | Lr[4.000000000000001e-07]
Step[51000] | Loss[0.45549264550209045] | Lr[4.000000000000001e-07]
Step[51000] | Loss[0.36736398935317993] | Lr[4.000000000000001e-07]
Step[51000] | Loss[0.46279457211494446] | Lr[4.000000000000001e-07]
Step[51000] | Loss[0.5895705223083496] | Lr[4.000000000000001e-07]
Step[51500] | Loss[0.5643425583839417] | Lr[4.000000000000001e-07]
Step[51500] | Loss[0.4725205898284912] | Lr[4.000000000000001e-07]
Step[51500] | Loss[1.1774898767471313] | Lr[4.000000000000001e-07]
Step[51500] | Loss[0.5525643825531006] | Lr[4.000000000000001e-07]
Step[52000] | Loss[0.622177243232727] | Lr[4.000000000000001e-07]
Step[52000] | Loss[0.9216363430023193] | Lr[4.000000000000001e-07]
Step[52000] | Loss[1.0422395467758179] | Lr[4.000000000000001e-07]
Step[52000] | Loss[0.4460259974002838] | Lr[4.000000000000001e-07]
Step[52500] | Loss[0.8398536443710327] | Lr[4.000000000000001e-07]
Step[52500] | Loss[0.5804062485694885] | Lr[4.000000000000001e-07]
Step[52500] | Loss[0.5251901745796204] | Lr[4.000000000000001e-07]Step[52500] | Loss[0.878795862197876] | Lr[4.000000000000001e-07]

Step[53000] | Loss[0.6298472881317139] | Lr[4.000000000000001e-07]
Step[53000] | Loss[0.4841429591178894] | Lr[4.000000000000001e-07]
Step[53000] | Loss[0.5656071305274963] | Lr[4.000000000000001e-07]
Step[53000] | Loss[0.6249114274978638] | Lr[4.000000000000001e-07]
Step[53500] | Loss[0.7607651948928833] | Lr[4.000000000000001e-07]
Step[53500] | Loss[0.611813485622406] | Lr[4.000000000000001e-07]
Step[53500] | Loss[0.6409201622009277] | Lr[4.000000000000001e-07]
Step[53500] | Loss[0.6120414137840271] | Lr[4.000000000000001e-07]
Step[54000] | Loss[0.8583387136459351] | Lr[4.000000000000001e-07]
Step[54000] | Loss[1.2254470586776733] | Lr[4.000000000000001e-07]
Step[54000] | Loss[0.9331387281417847] | Lr[4.000000000000001e-07]
Step[54000] | Loss[0.5428245663642883] | Lr[4.000000000000001e-07]
Step[54500] | Loss[0.7690739035606384] | Lr[4.000000000000001e-07]
Step[54500] | Loss[0.7231868505477905] | Lr[4.000000000000001e-07]
Step[54500] | Loss[0.8630988597869873] | Lr[4.000000000000001e-07]
Step[54500] | Loss[0.5650327801704407] | Lr[4.000000000000001e-07]
Step[55000] | Loss[0.6700872182846069] | Lr[4.000000000000001e-07]
Step[55000] | Loss[0.5281278491020203] | Lr[4.000000000000001e-07]
Step[55000] | Loss[0.6461238861083984] | Lr[4.000000000000001e-07]
Step[55000] | Loss[0.5454567074775696] | Lr[4.000000000000001e-07]
Step[55500] | Loss[0.9552363157272339] | Lr[4.000000000000001e-07]
Step[55500] | Loss[0.6373233795166016] | Lr[4.000000000000001e-07]
Step[55500] | Loss[1.299030065536499] | Lr[4.000000000000001e-07]
Step[55500] | Loss[1.248834252357483] | Lr[4.000000000000001e-07]
Step[56000] | Loss[0.7161747813224792] | Lr[4.000000000000001e-07]
Step[56000] | Loss[0.9601109623908997] | Lr[4.000000000000001e-07]
Step[56000] | Loss[0.7132123112678528] | Lr[4.000000000000001e-07]
Step[56000] | Loss[0.5760186910629272] | Lr[4.000000000000001e-07]
Step[56500] | Loss[0.4952673017978668] | Lr[4.000000000000001e-07]
Step[56500] | Loss[1.0004451274871826] | Lr[4.000000000000001e-07]
Step[56500] | Loss[0.609775722026825] | Lr[4.000000000000001e-07]
Step[56500] | Loss[0.7271280288696289] | Lr[4.000000000000001e-07]
Step[57000] | Loss[0.8569778203964233] | Lr[4.000000000000001e-07]
Step[57000] | Loss[0.5751562714576721] | Lr[4.000000000000001e-07]
Step[57000] | Loss[0.5159032940864563] | Lr[4.000000000000001e-07]
Step[57000] | Loss[0.937166690826416] | Lr[4.000000000000001e-07]
Step[57500] | Loss[0.6104085445404053] | Lr[4.000000000000001e-07]
Step[57500] | Loss[0.7260655164718628] | Lr[4.000000000000001e-07]
Step[57500] | Loss[0.6478016376495361] | Lr[4.000000000000001e-07]
Step[57500] | Loss[0.8940908312797546] | Lr[4.000000000000001e-07]
Step[58000] | Loss[0.46283286809921265] | Lr[4.000000000000001e-07]
Step[58000] | Loss[0.6743136644363403] | Lr[4.000000000000001e-07]
Step[58000] | Loss[0.9408400654792786] | Lr[4.000000000000001e-07]
Step[58000] | Loss[0.6708647608757019] | Lr[4.000000000000001e-07]
Step[58500] | Loss[0.33404457569122314] | Lr[4.000000000000001e-07]
Step[58500] | Loss[1.1882681846618652] | Lr[4.000000000000001e-07]
Step[58500] | Loss[0.6434659957885742] | Lr[4.000000000000001e-07]
Step[58500] | Loss[0.5341047644615173] | Lr[4.000000000000001e-07]
Step[59000] | Loss[0.700822114944458] | Lr[4.000000000000001e-07]
Step[59000] | Loss[0.8023191094398499] | Lr[4.000000000000001e-07]
Step[59000] | Loss[0.6829538941383362] | Lr[4.000000000000001e-07]
Step[59000] | Loss[0.5113738775253296] | Lr[4.000000000000001e-07]
Step[59500] | Loss[0.7197087407112122] | Lr[4.000000000000001e-07]
Step[59500] | Loss[0.5930391550064087] | Lr[4.000000000000001e-07]
Step[59500] | Loss[0.478396475315094] | Lr[4.000000000000001e-07]
Step[59500] | Loss[0.38359200954437256] | Lr[4.000000000000001e-07]
Step[60000] | Loss[0.6271825432777405] | Lr[4.000000000000001e-07]
Step[60000] | Loss[0.2878062129020691] | Lr[4.000000000000001e-07]
Step[60000] | Loss[0.6978133320808411] | Lr[4.000000000000001e-07]
Step[60000] | Loss[0.5507088303565979] | Lr[4.000000000000001e-07]
Step[60500] | Loss[0.6381613612174988] | Lr[4.000000000000001e-07]
Step[60500] | Loss[0.674671471118927] | Lr[4.000000000000001e-07]
Step[60500] | Loss[0.9500067830085754] | Lr[4.000000000000001e-07]
Step[60500] | Loss[0.5688961744308472] | Lr[4.000000000000001e-07]
Step[61000] | Loss[0.5258664488792419] | Lr[4.000000000000001e-07]
Step[61000] | Loss[0.6409590244293213] | Lr[4.000000000000001e-07]
Step[61000] | Loss[0.5666733384132385] | Lr[4.000000000000001e-07]
Step[61000] | Loss[0.6733274459838867] | Lr[4.000000000000001e-07]
Step[61500] | Loss[1.3751024007797241] | Lr[4.000000000000001e-07]
Step[61500] | Loss[0.990414559841156] | Lr[4.000000000000001e-07]
Step[61500] | Loss[0.8115946650505066] | Lr[4.000000000000001e-07]
Step[61500] | Loss[0.5781232118606567] | Lr[4.000000000000001e-07]
Step[62000] | Loss[0.8612468242645264] | Lr[4.000000000000001e-07]
Step[62000] | Loss[0.7815107703208923] | Lr[4.000000000000001e-07]
Step[62000] | Loss[0.4249940812587738] | Lr[4.000000000000001e-07]
Step[62000] | Loss[0.82685387134552] | Lr[4.000000000000001e-07]
Step[62500] | Loss[0.29112961888313293] | Lr[4.000000000000001e-07]
Step[62500] | Loss[0.329944372177124] | Lr[4.000000000000001e-07]
Step[62500] | Loss[0.4063732922077179] | Lr[4.000000000000001e-07]
Step[62500] | Loss[0.5231253504753113] | Lr[4.000000000000001e-07]
Step[63000] | Loss[0.9143497347831726] | Lr[4.000000000000001e-07]
Step[63000] | Loss[0.5799410939216614] | Lr[4.000000000000001e-07]
Step[63000] | Loss[0.5227000713348389] | Lr[4.000000000000001e-07]
Step[63000] | Loss[0.9841062426567078] | Lr[4.000000000000001e-07]
Step[63500] | Loss[0.9964078664779663] | Lr[4.000000000000001e-07]
Step[63500] | Loss[0.7653259038925171] | Lr[4.000000000000001e-07]
Step[63500] | Loss[0.678714394569397] | Lr[4.000000000000001e-07]
Step[63500] | Loss[0.570885419845581] | Lr[4.000000000000001e-07]
Step[64000] | Loss[0.8871141672134399] | Lr[4.000000000000001e-07]
Step[64000] | Loss[0.4866412281990051] | Lr[4.000000000000001e-07]
Step[64000] | Loss[0.6856916546821594] | Lr[4.000000000000001e-07]Step[64000] | Loss[0.7436336278915405] | Lr[4.000000000000001e-07]

Step[64500] | Loss[0.6783298254013062] | Lr[4.000000000000001e-07]
Step[64500] | Loss[0.48964595794677734] | Lr[4.000000000000001e-07]
Step[64500] | Loss[0.5809155702590942] | Lr[4.000000000000001e-07]
Step[64500] | Loss[0.518137514591217] | Lr[4.000000000000001e-07]
Step[65000] | Loss[0.5461747646331787] | Lr[4.000000000000001e-07]
Step[65000] | Loss[1.223610281944275] | Lr[4.000000000000001e-07]
Step[65000] | Loss[0.43705591559410095] | Lr[4.000000000000001e-07]
Step[65000] | Loss[0.7154653072357178] | Lr[4.000000000000001e-07]
Step[65500] | Loss[0.8757292032241821] | Lr[4.000000000000001e-07]
Step[65500] | Loss[0.7662344574928284] | Lr[4.000000000000001e-07]
Step[65500] | Loss[0.9741323590278625] | Lr[4.000000000000001e-07]
Step[65500] | Loss[0.7309668064117432] | Lr[4.000000000000001e-07]
Step[66000] | Loss[0.5393170714378357] | Lr[4.000000000000001e-07]
Step[66000] | Loss[0.3703274130821228] | Lr[4.000000000000001e-07]
Step[66000] | Loss[0.44461241364479065] | Lr[4.000000000000001e-07]
Step[66000] | Loss[0.8367993235588074] | Lr[4.000000000000001e-07]
Step[66500] | Loss[0.5460668206214905] | Lr[4.000000000000001e-07]
Step[66500] | Loss[0.528462290763855] | Lr[4.000000000000001e-07]
Step[66500] | Loss[0.6725596189498901] | Lr[4.000000000000001e-07]
Step[66500] | Loss[0.8443812727928162] | Lr[4.000000000000001e-07]
Step[67000] | Loss[0.37698251008987427] | Lr[4.000000000000001e-07]
Step[67000] | Loss[0.5029839873313904] | Lr[4.000000000000001e-07]
Step[67000] | Loss[0.6781513690948486] | Lr[4.000000000000001e-07]
Step[67000] | Loss[0.6556413769721985] | Lr[4.000000000000001e-07]
Step[67500] | Loss[0.46378111839294434] | Lr[4.000000000000001e-07]
Step[67500] | Loss[0.634610116481781] | Lr[4.000000000000001e-07]
Step[67500] | Loss[0.8711827397346497] | Lr[4.000000000000001e-07]
Step[67500] | Loss[0.46624240279197693] | Lr[4.000000000000001e-07]
Step[68000] | Loss[0.4411114752292633] | Lr[4.000000000000001e-07]
Step[68000] | Loss[0.8292007446289062] | Lr[4.000000000000001e-07]
Step[68000] | Loss[0.6991077661514282] | Lr[4.000000000000001e-07]
Step[68000] | Loss[0.7295445799827576] | Lr[4.000000000000001e-07]
Step[68500] | Loss[0.7225023508071899] | Lr[4.000000000000001e-07]
Step[68500] | Loss[0.739575207233429] | Lr[4.000000000000001e-07]
Step[68500] | Loss[0.7428399920463562] | Lr[4.000000000000001e-07]
Step[68500] | Loss[0.6609112024307251] | Lr[4.000000000000001e-07]
Step[69000] | Loss[0.6711403131484985] | Lr[4.000000000000001e-07]
Step[69000] | Loss[1.036497712135315] | Lr[4.000000000000001e-07]
Step[69000] | Loss[0.5500901937484741] | Lr[4.000000000000001e-07]
Step[69000] | Loss[0.39782586693763733] | Lr[4.000000000000001e-07]
Step[69500] | Loss[0.5828251838684082] | Lr[4.000000000000001e-07]
Step[69500] | Loss[0.6496047377586365] | Lr[4.000000000000001e-07]
Step[69500] | Loss[0.8357937335968018] | Lr[4.000000000000001e-07]
Step[69500] | Loss[0.796074628829956] | Lr[4.000000000000001e-07]
Step[70000] | Loss[0.8734476566314697] | Lr[4.000000000000001e-07]
Step[70000] | Loss[0.9336462616920471] | Lr[4.000000000000001e-07]
Step[70000] | Loss[0.7314299941062927] | Lr[4.000000000000001e-07]
Step[70000] | Loss[1.0514764785766602] | Lr[4.000000000000001e-07]
Step[70500] | Loss[0.4858534336090088] | Lr[4.000000000000001e-07]
Step[70500] | Loss[0.6770873069763184] | Lr[4.000000000000001e-07]
Step[70500] | Loss[0.5930794477462769] | Lr[4.000000000000001e-07]
Step[70500] | Loss[0.907113790512085] | Lr[4.000000000000001e-07]
Step[71000] | Loss[0.5373644232749939] | Lr[4.000000000000001e-07]
Step[71000] | Loss[0.9180629849433899] | Lr[4.000000000000001e-07]
Step[71000] | Loss[0.5907877683639526] | Lr[4.000000000000001e-07]
Step[71000] | Loss[0.8595918416976929] | Lr[4.000000000000001e-07]
Step[71500] | Loss[0.7456795573234558] | Lr[4.000000000000001e-07]
Step[71500] | Loss[0.7566733956336975] | Lr[4.000000000000001e-07]
Step[71500] | Loss[0.7618765234947205] | Lr[4.000000000000001e-07]
Step[71500] | Loss[0.721299946308136] | Lr[4.000000000000001e-07]
Step[72000] | Loss[0.674666166305542] | Lr[4.000000000000001e-07]
Step[72000] | Loss[0.6845111846923828] | Lr[4.000000000000001e-07]
Step[72000] | Loss[0.6359392404556274] | Lr[4.000000000000001e-07]
Step[72000] | Loss[1.0437989234924316] | Lr[4.000000000000001e-07]
Step[72500] | Loss[0.7951174974441528] | Lr[4.000000000000001e-07]
Step[72500] | Loss[0.6664125919342041] | Lr[4.000000000000001e-07]
Step[72500] | Loss[0.7493785619735718] | Lr[4.000000000000001e-07]
Step[72500] | Loss[0.4816387891769409] | Lr[4.000000000000001e-07]
Step[73000] | Loss[0.7250743508338928] | Lr[4.000000000000001e-07]
Step[73000] | Loss[0.6869975924491882] | Lr[4.000000000000001e-07]
Step[73000] | Loss[0.5639868378639221] | Lr[4.000000000000001e-07]
Step[73000] | Loss[0.4771571755409241] | Lr[4.000000000000001e-07]
Step[73500] | Loss[0.607925534248352] | Lr[4.000000000000001e-07]
Step[73500] | Loss[0.40278875827789307] | Lr[4.000000000000001e-07]
Step[73500] | Loss[0.5350222587585449] | Lr[4.000000000000001e-07]
Step[73500] | Loss[0.3184380531311035] | Lr[4.000000000000001e-07]
Step[74000] | Loss[0.9209297299385071] | Lr[4.000000000000001e-07]
Step[74000] | Loss[0.8527044057846069] | Lr[4.000000000000001e-07]
Step[74000] | Loss[0.8212049603462219] | Lr[4.000000000000001e-07]
Step[74000] | Loss[1.1181386709213257] | Lr[4.000000000000001e-07]
Step[74500] | Loss[0.8019850850105286] | Lr[4.000000000000001e-07]
Step[74500] | Loss[0.8175565004348755] | Lr[4.000000000000001e-07]
Step[74500] | Loss[0.6080324649810791] | Lr[4.000000000000001e-07]
Step[74500] | Loss[0.649269163608551] | Lr[4.000000000000001e-07]
Step[75000] | Loss[0.49643558263778687] | Lr[4.000000000000001e-07]
Step[75000] | Loss[0.508632242679596] | Lr[4.000000000000001e-07]
Step[75000] | Loss[0.5684846639633179] | Lr[4.000000000000001e-07]
Step[75000] | Loss[0.5781025886535645] | Lr[4.000000000000001e-07]
Step[75500] | Loss[0.9786816835403442] | Lr[4.000000000000001e-07]
Step[75500] | Loss[0.5348544716835022] | Lr[4.000000000000001e-07]
Step[75500] | Loss[0.5289263725280762] | Lr[4.000000000000001e-07]
Step[75500] | Loss[0.38807952404022217] | Lr[4.000000000000001e-07]
Step[76000] | Loss[1.1716915369033813] | Lr[4.000000000000001e-07]
Step[76000] | Loss[0.5034030079841614] | Lr[4.000000000000001e-07]
Step[76000] | Loss[0.6085947751998901] | Lr[4.000000000000001e-07]
Step[76000] | Loss[0.5218093991279602] | Lr[4.000000000000001e-07]
Step[76500] | Loss[0.7234222292900085] | Lr[4.000000000000001e-07]
Step[76500] | Loss[0.7994254231452942] | Lr[4.000000000000001e-07]
Step[76500] | Loss[0.4895102381706238] | Lr[4.000000000000001e-07]
Step[76500] | Loss[0.6973555684089661] | Lr[4.000000000000001e-07]
Step[77000] | Loss[0.5347579121589661] | Lr[4.000000000000001e-07]
Step[77000] | Loss[0.36947688460350037] | Lr[4.000000000000001e-07]
Step[77000] | Loss[0.8237307667732239] | Lr[4.000000000000001e-07]
Step[77000] | Loss[0.619171679019928] | Lr[4.000000000000001e-07]
Step[77500] | Loss[0.7869851589202881] | Lr[4.000000000000001e-07]
Step[77500] | Loss[0.8606390357017517] | Lr[4.000000000000001e-07]
Step[77500] | Loss[0.717002809047699] | Lr[4.000000000000001e-07]
Step[77500] | Loss[0.6393595933914185] | Lr[4.000000000000001e-07]
Step[78000] | Loss[0.6700048446655273] | Lr[4.000000000000001e-07]
Step[78000] | Loss[0.4784736633300781] | Lr[4.000000000000001e-07]
Step[78000] | Loss[0.6948007345199585] | Lr[4.000000000000001e-07]
Step[78000] | Loss[0.3633398115634918] | Lr[4.000000000000001e-07]
Labels:  tensor([2, 2, 1, 1, 1, 4, 4, 4, 3, 2, 0, 3, 3, 4, 0, 3], device='cuda:0')
Preds:  tensor([3, 3, 2, 1, 0, 4, 4, 4, 2, 2, 1, 2, 4, 4, 0, 3], device='cuda:0')
Outputs:  tensor([[    0.0001,     0.0004,     0.0342,     0.5531,     0.4122],
        [    0.0001,     0.0006,     0.0216,     0.6733,     0.3045],
        [    0.0074,     0.0571,     0.5437,     0.3376,     0.0542],
        [    0.1014,     0.6040,     0.2877,     0.0068,     0.0001],
        [    0.6898,     0.2844,     0.0247,     0.0008,     0.0003],
        [    0.0000,     0.0000,     0.0012,     0.0623,     0.9364],
        [    0.0003,     0.0001,     0.0014,     0.0326,     0.9656],
        [    0.0014,     0.0020,     0.0181,     0.1319,     0.8465],
        [    0.0053,     0.0326,     0.6441,     0.2727,     0.0453],
        [    0.0037,     0.0477,     0.5455,     0.3955,     0.0076],
        [    0.0492,     0.6287,     0.3009,     0.0184,     0.0027],
        [    0.0026,     0.0644,     0.7339,     0.1726,     0.0264],
        [    0.0001,     0.0003,     0.0063,     0.3256,     0.6677],
        [    0.0001,     0.0006,     0.0018,     0.0956,     0.9018],
        [    0.9484,     0.0509,     0.0007,     0.0000,     0.0000],
        [    0.0000,     0.0001,     0.0156,     0.8782,     0.1061]],
       device='cuda:0')
Metric:  tensor(0.5000, device='cuda:0')
------------------------
Labels:  tensor([0, 4, 2, 3, 0, 1, 2, 2, 3, 2, 2, 4, 4, 1, 1, 2], device='cuda:1')
Preds:  tensor([0, 4, 1, 4, 0, 2, 4, 2, 2, 2, 0, 4, 4, 1, 1, 4], device='cuda:1')
Labels:  Labels:  tensor([3, 0, 0, 1, 0, 3, 0, 0, 3, 1, 4, 4, 4, 1, 2, 0], device='cuda:1')
Outputs:  tensor([[    0.7834,     0.2058,     0.0108,     0.0001,     0.0000],
        [    0.0002,     0.0001,     0.0008,     0.0552,     0.9437],
        [    0.0327,     0.7971,     0.1391,     0.0270,     0.0041],
        [    0.0001,     0.0000,     0.0002,     0.0185,     0.9811],
        [    0.9931,     0.0053,     0.0005,     0.0002,     0.0009],
        [    0.0744,     0.3415,     0.4741,     0.1078,     0.0022],
        [    0.0009,     0.0053,     0.0788,     0.4405,     0.4745],
        [    0.0005,     0.0143,     0.5556,     0.4223,     0.0073],
        [    0.1014,     0.4293,     0.4337,     0.0351,     0.0005],
        [    0.0019,     0.0357,     0.5901,     0.3526,     0.0196],
        [    0.6567,     0.2964,     0.0456,     0.0009,     0.0004],
        [    0.0000,     0.0000,     0.0008,     0.0673,     0.9318],
        [    0.0003,     0.0000,     0.0001,     0.0007,     0.9989],
        [    0.0121,     0.5072,     0.4113,     0.0607,     0.0087],
Preds:  tensor([3, 1, 1, 4, 0, 2, 4, 1, 3, 0, 2, 3, 2, 2, 4, 4], device='cuda:0')
        [    0.0021,     0.9956,     0.0016,     0.0006,     0.0001],
        [    0.0034,     0.0021,     0.0231,     0.3124,     0.6590]],
       device='cuda:1')
Preds:  tensor([4, 0, 2, 1, 0, 2, 0, 1, 3, 1, 2, 3, 4, 1, 2, 0], device='cuda:1')
Metric:  tensor(0.5625, device='cuda:1')
Outputs:  tensor([3, 0, 0, 4, 0, 2, 4, 1, 3, 0, 1, 4, 1, 2, 4, 4], device='cuda:0')
------------------------
Outputs:  tensor([[    0.0004,     0.0006,     0.0145,     0.3833,     0.6012],
        [    0.6832,     0.2919,     0.0234,     0.0008,     0.0007],
        [    0.1754,     0.3506,     0.4461,     0.0267,     0.0011],
        [    0.3229,     0.5455,     0.1297,     0.0017,     0.0002],
        [    0.8291,     0.1504,     0.0204,     0.0001,     0.0000],
        [    0.0196,     0.1235,     0.6426,     0.2069,     0.0074],
        [    0.8989,     0.0953,     0.0058,     0.0000,     0.0000],
        [    0.2777,     0.6910,     0.0303,     0.0009,     0.0001],
        [    0.0000,     0.0015,     0.3596,     0.5866,     0.0523],
        [    0.2286,     0.4900,     0.2720,     0.0087,     0.0007],
        [    0.2704,     0.1530,     0.2870,     0.1310,     0.1587],
        [    0.0483,     0.0580,     0.4082,     0.4131,     0.0724],
        [    0.0003,     0.0002,     0.0040,     0.1706,     0.8248],
        [    0.2077,     0.6354,     0.1158,     0.0323,     0.0087],
        [    0.0015,     0.0863,     0.8877,     0.0243,     0.0002],
        [    0.9889,     0.0110,     0.0001,     0.0000,     0.0000]],
       device='cuda:1')
Metric:  tensor([[    0.0000,     0.0011,     0.0369,     0.9618,     0.0001],
        [    0.4758,     0.4567,     0.0666,     0.0008,     0.0001],
        [    0.4460,     0.4315,     0.1182,     0.0040,     0.0003],
        [    0.0007,     0.0002,     0.0016,     0.0370,     0.9606],
        [    0.7507,     0.0960,     0.0799,     0.0401,     0.0332],
        [    0.0016,     0.0940,     0.8141,     0.0898,     0.0004],
        [    0.0021,     0.0010,     0.0069,     0.1715,     0.8185],
        [    0.4609,     0.5011,     0.0380,     0.0000,     0.0000],
        [    0.0001,     0.0010,     0.3002,     0.6761,     0.0227],
        [    0.5247,     0.2241,     0.2318,     0.0193,     0.0001],
        [    0.1954,     0.5572,     0.2437,     0.0033,     0.0003],
        [    0.0002,     0.0002,     0.0043,     0.2959,     0.6995],
        [    0.0688,     0.6566,     0.2730,     0.0015,     0.0000],
        [    0.0121,     0.0950,     0.5259,     0.3009,     0.0660],
        [    0.0001,     0.0002,     0.0109,     0.3510,     0.6377],
        [    0.0004,     0.0002,     0.0034,     0.1172,     0.8788]],
       device='cuda:0')
Metric:  tensor(0.6250, device='cuda:1')
------------------------
tensor(0.6875, device='cuda:0')
------------------------
Labels:  tensor([1, 1, 1, 1, 2, 1, 0, 0, 4, 4, 2, 1, 3, 0, 0, 1], device='cuda:0')
Preds:  tensor([3, 1, 2, 4, 2, 1, 0, 0, 4, 4, 2, 0, 2, 0, 0, 1], device='cuda:0')
Outputs:  tensor([[    0.0009,     0.0138,     0.2910,     0.5529,     0.1415],
        [    0.3242,     0.3816,     0.2842,     0.0094,     0.0005],
        [    0.0399,     0.3377,     0.5815,     0.0397,     0.0012],
        [    0.1569,     0.0923,     0.1710,     0.2075,     0.3722],
        [    0.0139,     0.4492,     0.4732,     0.0609,     0.0028],
        [    0.0721,     0.4503,     0.4481,     0.0245,     0.0052],
        [    0.8873,     0.0986,     0.0112,     0.0011,     0.0017],
        [    0.7474,     0.2457,     0.0069,     0.0000,     0.0000],
        [    0.0012,     0.0005,     0.0042,     0.1724,     0.8217],
        [    0.0004,     0.0001,     0.0013,     0.0523,     0.9459],
        [    0.0045,     0.1099,     0.8076,     0.0778,     0.0002],
        [    0.5138,     0.3630,     0.1053,     0.0083,     0.0096],
        [    0.0001,     0.0035,     0.6312,     0.3652,     0.0000],
        [    0.6455,     0.3228,     0.0305,     0.0011,     0.0000],
        [    0.7284,     0.2240,     0.0425,     0.0029,     0.0021],
        [    0.1855,     0.5800,     0.2314,     0.0031,     0.0001]],
       device='cuda:0')
Metric:  tensor(0.6875, device='cuda:0')
------------------------
Labels:  tensor([3, 2, 3, 1, 3, 4, 3, 0, 3, 1, 1, 0, 0, 3, 2, 0], device='cuda:1')
Preds:  tensor([3, 2, 3, 1, 2, 4, 3, 1, 4, 1, 1, 0, 0, 3, 2, 2], device='cuda:1')
Outputs:  tensor([[    0.0008,     0.0055,     0.3596,     0.6280,     0.0060],
        [    0.0002,     0.0133,     0.6330,     0.3473,     0.0061],
        [    0.0008,     0.0193,     0.4243,     0.5497,     0.0058],
        [    0.3997,     0.4815,     0.1177,     0.0010,     0.0001],
        [    0.0007,     0.0335,     0.9444,     0.0208,     0.0005],
        [    0.0003,     0.0003,     0.0061,     0.1905,     0.8029],
        [    0.0094,     0.0555,     0.3861,     0.4920,     0.0569],
        [    0.1894,     0.5962,     0.2131,     0.0013,     0.0000],
        [    0.0000,     0.0001,     0.0032,     0.3185,     0.6783],
        [    0.1298,     0.5983,     0.2335,     0.0342,     0.0042],
        [    0.1632,     0.5299,     0.2992,     0.0073,     0.0003],
        [    0.9499,     0.0483,     0.0017,     0.0000,     0.0000],
        [    0.6132,     0.3291,     0.0543,     0.0030,     0.0004],
        [    0.0014,     0.0306,     0.4222,     0.5189,     0.0270],
        [    0.0928,     0.3404,     0.4519,     0.0935,     0.0214],
        [    0.0498,     0.2319,     0.5967,     0.1200,     0.0016]],
       device='cuda:1')
Metric:  tensor(0.7500, device='cuda:1')
------------------------
Labels:  tensor([0, 1, 4, 2, 3, 2, 1, 0, 2, 2, 2, 0, 2, 4, 3, 4], device='cuda:0')
Preds:  tensor([0, 1, 4, 1, 0, 2, 1, 0, 1, 3, 3, 0, 2, 4, 0, 4], device='cuda:0')
Outputs:  tensor([[    0.5262,     0.4492,     0.0246,     0.0001,     0.0000],
        [    0.1305,     0.8490,     0.0203,     0.0001,     0.0000],
        [    0.0001,     0.0002,     0.0084,     0.2127,     0.7786],
        [    0.3683,     0.5119,     0.1179,     0.0017,     0.0002],
        [    0.6072,     0.2703,     0.1166,     0.0055,     0.0004],
        [    0.0255,     0.0273,     0.9102,     0.0256,     0.0114],
        [    0.1707,     0.5014,     0.3269,     0.0010,     0.0000],
        [    0.9362,     0.0616,     0.0020,     0.0001,     0.0001],
        [    0.3513,     0.3824,     0.2505,     0.0133,     0.0025],
        [    0.0003,     0.0024,     0.1201,     0.6686,     0.2085],
        [    0.0018,     0.0329,     0.4503,     0.4689,     0.0461],
        [    0.9076,     0.0881,     0.0040,     0.0002,     0.0000],
        [    0.0007,     0.0233,     0.5426,     0.4270,     0.0065],
        [    0.0002,     0.0002,     0.0079,     0.2000,     0.7918],
        [    0.5933,     0.3329,     0.0733,     0.0005,     0.0000],
        [    0.0001,     0.0002,     0.0002,     0.0179,     0.9816]],
       device='cuda:0')
Metric:  tensor(0.6250, device='cuda:0')
------------------------
Labels:  tensor([2, 0, 4, 4, 4, 0, 0, 2, 4, 0, 4, 0, 0, 0, 1, 2], device='cuda:1')
Preds:  tensor([2, 0, 4, 4, 4, 0, 0, 2, 4, 1, 4, 4, 0, 0, 2, 4], device='cuda:1')
Outputs:  tensor([[    0.0109,     0.0253,     0.5071,     0.3895,     0.0671],
        [    0.5180,     0.4333,     0.0464,     0.0017,     0.0006],
        [    0.0002,     0.0008,     0.0002,     0.0137,     0.9851],
        [    0.0001,     0.0000,     0.0003,     0.0423,     0.9573],
        [    0.0005,     0.0007,     0.0112,     0.2221,     0.7655],
        [    0.6011,     0.3222,     0.0721,     0.0037,     0.0009],
        [    0.7558,     0.2102,     0.0320,     0.0019,     0.0001],
        [    0.0342,     0.2554,     0.6924,     0.0178,     0.0002],
        [    0.0002,     0.0007,     0.0217,     0.2906,     0.6869],
        [    0.0817,     0.5068,     0.4041,     0.0071,     0.0002],
        [    0.0006,     0.0005,     0.0088,     0.2140,     0.7761],
        [    0.0972,     0.0687,     0.0809,     0.1244,     0.6289],
        [    0.6098,     0.3658,     0.0223,     0.0006,     0.0015],
        [    0.9131,     0.0857,     0.0012,     0.0000,     0.0000],
        [    0.0122,     0.2794,     0.6876,     0.0207,     0.0000],
        [    0.1141,     0.1741,     0.2645,     0.1134,     0.3339]],
       device='cuda:1')
Metric:  tensor(0.7500, device='cuda:1')
------------------------
Labels:  tensor([4, 0, 4, 0, 4, 1, 1, 3, 0, 4, 4, 3, 0, 2, 3, 0], device='cuda:0')
Preds:  tensor([4, 0, 4, 0, 4, 1, 1, 4, 0, 3, 4, 3, 1, 1, 4, 0], device='cuda:0')
Outputs:  tensor([[    0.0005,     0.0002,     0.0042,     0.1470,     0.8481],
        [    0.7428,     0.2163,     0.0399,     0.0009,     0.0001],
        [    0.0004,     0.0003,     0.0073,     0.2925,     0.6994],
        [    0.8580,     0.1367,     0.0052,     0.0000,     0.0000],
        [    0.0310,     0.0223,     0.0799,     0.1958,     0.6710],
        [    0.0024,     0.9815,     0.0145,     0.0014,     0.0002],
        [    0.1261,     0.5341,     0.3325,     0.0071,     0.0003],
        [    0.0280,     0.2099,     0.1492,     0.2042,     0.4087],
        [    0.9894,     0.0102,     0.0004,     0.0000,     0.0000],
        [    0.0011,     0.0057,     0.1963,     0.4285,     0.3683],
        [    0.0001,     0.0018,     0.0033,     0.2116,     0.7832],
        [    0.0003,     0.0043,     0.3218,     0.6338,     0.0398],
        [    0.2939,     0.6587,     0.0473,     0.0001,     0.0000],
        [    0.1266,     0.4981,     0.3592,     0.0160,     0.0002],
        [    0.0001,     0.0001,     0.0036,     0.2915,     0.7047],
        [    0.9194,     0.0760,     0.0045,     0.0001,     0.0000]],
       device='cuda:0')
Metric:  tensor(0.6875, device='cuda:0')
------------------------
Labels:  tensor([3, 2, 3, 2, 3, 0, 2, 4, 1, 1, 1, 1, 0, 0, 0, 0], device='cuda:1')
Preds:  tensor([4, 2, 2, 2, 4, 0, 1, 4, 2, 0, 1, 2, 0, 0, 0, 0], device='cuda:1')
Outputs:  tensor([[    0.0005,     0.0006,     0.0151,     0.2158,     0.7681],
        [    0.0273,     0.1405,     0.6081,     0.2178,     0.0062],
        [    0.0008,     0.0253,     0.9500,     0.0237,     0.0001],
        [    0.0027,     0.0280,     0.9556,     0.0134,     0.0003],
        [    0.0002,     0.0002,     0.0032,     0.1653,     0.8312],
        [    0.7711,     0.2203,     0.0085,     0.0002,     0.0000],
        [    0.4184,     0.4273,     0.1448,     0.0086,     0.0010],
        [    0.0009,     0.0005,     0.0029,     0.1095,     0.8861],
        [    0.0064,     0.1075,     0.7306,     0.1467,     0.0087],
        [    0.7596,     0.1017,     0.0436,     0.0258,     0.0693],
        [    0.2552,     0.6135,     0.1305,     0.0008,     0.0000],
        [    0.3259,     0.2501,     0.3946,     0.0265,     0.0029],
        [    0.9959,     0.0026,     0.0009,     0.0002,     0.0004],
        [    0.7351,     0.2311,     0.0310,     0.0018,     0.0009],
        [    0.9846,     0.0152,     0.0001,     0.0000,     0.0000],
        [    0.9996,     0.0003,     0.0001,     0.0000,     0.0000]],
       device='cuda:1')
Metric:  tensor(0.5625, device='cuda:1')
------------------------
Labels:  tensor([3, 3, 3, 2, 1, 3, 1, 1, 2, 2, 0, 3, 3, 4, 4, 2], device='cuda:0')
Preds:  tensor([3, 2, 2, 2, 1, 3, 1, 0, 2, 2, 0, 4, 2, 4, 4, 0], device='cuda:0')
Outputs:  tensor([[    0.0001,     0.0003,     0.0154,     0.5477,     0.4365],
        [    0.0003,     0.0058,     0.8360,     0.1442,     0.0137],
        [    0.0007,     0.0204,     0.7464,     0.2280,     0.0045],
        [    0.0296,     0.1859,     0.6812,     0.1023,     0.0010],
        [    0.3804,     0.5697,     0.0490,     0.0008,     0.0001],
        [    0.0257,     0.0698,     0.3940,     0.3989,     0.1116],
        [    0.2506,     0.6422,     0.1062,     0.0010,     0.0000],
        [    0.9891,     0.0107,     0.0002,     0.0000,     0.0000],
        [    0.0004,     0.0089,     0.5534,     0.4177,     0.0196],
        [    0.0552,     0.2898,     0.4634,     0.1814,     0.0101],
        [    0.5867,     0.3546,     0.0585,     0.0002,     0.0000],
        [    0.0000,     0.0000,     0.0001,     0.0096,     0.9902],
        [    0.0010,     0.0457,     0.6980,     0.2527,     0.0025],
        [    0.0001,     0.0001,     0.0026,     0.1971,     0.8001],
        [    0.0027,     0.0023,     0.0304,     0.1517,     0.8129],
        [    0.8279,     0.1597,     0.0119,     0.0004,     0.0001]],
       device='cuda:0')
Metric:  tensor(0.6250, device='cuda:0')
------------------------
Labels:  tensor([2, 3, 4, 0, 1, 3, 4, 3, 4, 2, 1, 0, 4, 4, 4, 4], device='cuda:1')
Preds:  tensor([1, 3, 4, 1, 2, 4, 4, 2, 4, 2, 0, 0, 4, 4, 3, 4], device='cuda:1')
Outputs:  tensor([[    0.0367,     0.5582,     0.4020,     0.0030,     0.0001],
        [    0.0001,     0.0004,     0.0559,     0.7850,     0.1587],
        [    0.0017,     0.0007,     0.0018,     0.0139,     0.9819],
        [    0.2735,     0.6689,     0.0570,     0.0005,     0.0001],
        [    0.0508,     0.1902,     0.4065,     0.2839,     0.0686],
        [    0.0010,     0.0014,     0.0234,     0.2450,     0.7293],
        [    0.0007,     0.0001,     0.0009,     0.0093,     0.9890],
        [    0.0056,     0.2617,     0.7255,     0.0071,     0.0001],
        [    0.0001,     0.0003,     0.0001,     0.0013,     0.9982],
        [    0.0008,     0.0296,     0.7441,     0.2203,     0.0052],
        [    0.5373,     0.4122,     0.0492,     0.0010,     0.0003],
        [    0.7953,     0.1885,     0.0159,     0.0003,     0.0000],
        [    0.0001,     0.0001,     0.0014,     0.0738,     0.9246],
        [    0.0020,     0.0013,     0.0257,     0.4094,     0.5615],
        [    0.0022,     0.0064,     0.1232,     0.6121,     0.2560],
        [    0.0003,     0.0001,     0.0021,     0.1526,     0.8449]],
       device='cuda:1')
Metric:  tensor(0.5625, device='cuda:1')
------------------------
Labels:  tensor([2, 0, 1, 3, 4, 2, 0, 0, 2, 1, 0, 1, 1, 2, 3, 4], device='cuda:0')
Preds:  tensor([4, 0, 2, 2, 4, 2, 1, 0, 1, 0, 0, 0, 0, 1, 4, 4], device='cuda:0')
Outputs:  tensor([[    0.0001,     0.0001,     0.0029,     0.1773,     0.8197],
        [    0.8379,     0.1444,     0.0171,     0.0004,     0.0001],
        [    0.0016,     0.0580,     0.8535,     0.0867,     0.0001],
        [    0.0007,     0.0467,     0.9239,     0.0285,     0.0001],
        [    0.0020,     0.0007,     0.0038,     0.0320,     0.9615],
        [    0.0048,     0.1848,     0.6285,     0.1799,     0.0019],
        [    0.4075,     0.4944,     0.0968,     0.0012,     0.0000],
        [    0.8230,     0.1472,     0.0295,     0.0003,     0.0000],
        [    0.0413,     0.7891,     0.1492,     0.0186,     0.0017],
        [    0.5409,     0.3473,     0.0979,     0.0087,     0.0051],
        [    0.9934,     0.0065,     0.0001,     0.0000,     0.0000],
        [    0.6669,     0.2484,     0.0809,     0.0038,     0.0000],
        [    0.7970,     0.1411,     0.0550,     0.0051,     0.0018],
        [    0.0181,     0.7984,     0.1580,     0.0238,     0.0016],
        [    0.0010,     0.0030,     0.0583,     0.3772,     0.5605],
        [    0.0001,     0.0001,     0.0001,     0.0412,     0.9585]],
       device='cuda:0')
Metric:  tensor(0.3750, device='cuda:0')
------------------------
Labels:  tensor([1, 1, 2, 1, 1, 4, 1, 4, 4, 1, 3, 2, 4, 3, 3, 4], device='cuda:1')
Preds:  tensor([2, 1, 2, 0, 1, 4, 0, 3, 4, 1, 2, 2, 4, 2, 4, 4], device='cuda:1')
Outputs:  tensor([[    0.0397,     0.1666,     0.4744,     0.2470,     0.0724],
        [    0.1297,     0.4515,     0.3941,     0.0242,     0.0005],
        [    0.0292,     0.2363,     0.6191,     0.1152,     0.0002],
        [    0.6291,     0.2890,     0.0812,     0.0007,     0.0000],
        [    0.3065,     0.6090,     0.0841,     0.0003,     0.0000],
        [    0.0023,     0.0024,     0.0064,     0.0870,     0.9018],
        [    0.6488,     0.3164,     0.0336,     0.0009,     0.0002],
        [    0.0001,     0.0001,     0.0064,     0.5904,     0.4029],
        [    0.0011,     0.0006,     0.0021,     0.0470,     0.9492],
        [    0.3160,     0.5925,     0.0904,     0.0011,     0.0000],
        [    0.0092,     0.1175,     0.8123,     0.0610,     0.0001],
        [    0.0008,     0.1003,     0.7122,     0.1839,     0.0029],
        [    0.0002,     0.0003,     0.0037,     0.1500,     0.8458],
        [    0.0002,     0.0107,     0.6840,     0.2955,     0.0096],
        [    0.0004,     0.0003,     0.0111,     0.1260,     0.8622],
        [    0.0001,     0.0003,     0.0122,     0.4320,     0.5553]],
       device='cuda:1')
Metric:  tensor(0.5625, device='cuda:1')
------------------------
Labels:  tensor([4, 1, 1, 0, 0, 1, 2, 4, 2, 4, 4, 1, 0, 1, 2, 1], device='cuda:0')
Preds:  tensor([4, 1, 0, 0, 0, 1, 2, 4, 2, 4, 4, 0, 0, 0, 2, 0], device='cuda:0')
Outputs:  tensor([[    0.0008,     0.0006,     0.0023,     0.0630,     0.9332],
        [    0.2371,     0.6294,     0.1299,     0.0032,     0.0003],
        [    0.9582,     0.0410,     0.0008,     0.0000,     0.0000],
        [    0.8641,     0.1271,     0.0082,     0.0003,     0.0003],
        [    0.7849,     0.2041,     0.0104,     0.0004,     0.0002],
        [    0.0686,     0.6299,     0.3006,     0.0008,     0.0000],
        [    0.0589,     0.2827,     0.4864,     0.1527,     0.0194],
        [    0.0000,     0.0000,     0.0002,     0.1216,     0.8782],
        [    0.0167,     0.3421,     0.6235,     0.0177,     0.0000],
        [    0.0016,     0.0010,     0.0090,     0.3314,     0.6569],
        [    0.0102,     0.0078,     0.0354,     0.0616,     0.8851],
        [    0.4469,     0.0966,     0.0958,     0.1026,     0.2582],
        [    0.9121,     0.0864,     0.0014,     0.0000,     0.0000],
        [    0.5520,     0.3223,     0.1201,     0.0045,     0.0010],
        [    0.1167,     0.2698,     0.4849,     0.1203,     0.0082],
        [    0.5901,     0.3073,     0.0971,     0.0050,     0.0006]],
       device='cuda:0')
Metric:  tensor(0.7500, device='cuda:0')
------------------------
Labels:  tensor([4, 4, 4, 2, 3, 2, 4, 1, 2, 1, 1, 2, 0, 1, 0, 1], device='cuda:1')
Preds:  tensor([4, 4, 4, 1, 2, 3, 4, 1, 2, 2, 1, 2, 0, 0, 0, 2], device='cuda:1')
Outputs:  tensor([[    0.0001,     0.0003,     0.0101,     0.1346,     0.8549],
        [    0.0002,     0.0001,     0.0065,     0.2778,     0.7154],
        [    0.0002,     0.0001,     0.0012,     0.0374,     0.9611],
        [    0.1977,     0.5720,     0.2285,     0.0017,     0.0000],
        [    0.0028,     0.0231,     0.6251,     0.2866,     0.0624],
        [    0.0001,     0.0017,     0.0993,     0.7676,     0.1312],
        [    0.0009,     0.0003,     0.0012,     0.0076,     0.9900],
        [    0.1040,     0.5158,     0.3466,     0.0327,     0.0008],
        [    0.0012,     0.0882,     0.8740,     0.0365,     0.0001],
        [    0.0319,     0.2789,     0.6081,     0.0801,     0.0010],
        [    0.3130,     0.3409,     0.2806,     0.0627,     0.0028],
        [    0.0024,     0.1556,     0.8229,     0.0190,     0.0002],
        [    0.9930,     0.0069,     0.0001,     0.0000,     0.0000],
        [    0.6873,     0.2907,     0.0216,     0.0004,     0.0000],
        [    0.7771,     0.2143,     0.0084,     0.0002,     0.0000],
        [    0.0048,     0.0952,     0.7364,     0.1626,     0.0010]],
       device='cuda:1')
Metric:  tensor(0.6250, device='cuda:1')
------------------------
Labels:  tensor([4, 2, 2, 0, 0, 3, 3, 0, 0, 0, 0, 1, 4, 2, 0, 4], device='cuda:0')
Preds:  tensor([4, 4, 2, 0, 0, 3, 3, 1, 0, 0, 4, 0, 3, 2, 0, 4], device='cuda:0')
Outputs:  tensor([[    0.0000,     0.0002,     0.0007,     0.1021,     0.8969],
        [    0.0007,     0.0014,     0.0206,     0.2539,     0.7234],
        [    0.0777,     0.3354,     0.4856,     0.0983,     0.0030],
        [    0.9704,     0.0290,     0.0006,     0.0000,     0.0000],
        [    0.6385,     0.3452,     0.0158,     0.0003,     0.0002],
        [    0.0001,     0.0000,     0.0008,     0.9969,     0.0023],
        [    0.0000,     0.0010,     0.1661,     0.8051,     0.0278],
        [    0.2419,     0.6679,     0.0747,     0.0073,     0.0081],
        [    0.8543,     0.1453,     0.0004,     0.0000,     0.0000],
        [    0.8338,     0.1561,     0.0096,     0.0002,     0.0003],
        [    0.0748,     0.0924,     0.0208,     0.1213,     0.6907],
        [    0.7219,     0.2674,     0.0103,     0.0003,     0.0001],
        [    0.0008,     0.0021,     0.0203,     0.8158,     0.1609],
        [    0.2169,     0.2833,     0.3465,     0.0892,     0.0641],
        [    0.7527,     0.2148,     0.0293,     0.0022,     0.0010],
        [    0.0000,     0.0001,     0.0007,     0.0985,     0.9007]],
       device='cuda:0')
Metric:  tensor(0.6875, device='cuda:0')
------------------------
Mean loss[0.9338012269614905] | Mean metric[0.602214494875549]
Stupid loss[0.0] | Naive soulution metric[0.2]
Labels:  tensor([0, 4, 0, 3, 0, 1, 2, 1, 4, 2, 1, 1, 4, 3, 1, 3], device='cuda:1')
Preds:  tensor([0, 4, 0, 3, 0, 0, 2, 2, 3, 3, 1, 2, 4, 3, 1, 2], device='cuda:1')
Outputs:  tensor([[    0.5339,     0.4471,     0.0168,     0.0005,     0.0017],
        [    0.0007,     0.0014,     0.0085,     0.1036,     0.8858],
        [    0.8690,     0.1163,     0.0130,     0.0014,     0.0002],
        [    0.0000,     0.0004,     0.0439,     0.7526,     0.2031],
        [    0.8435,     0.1547,     0.0018,     0.0000,     0.0000],
        [    0.6450,     0.3105,     0.0430,     0.0015,     0.0001],
        [    0.1392,     0.3631,     0.4062,     0.0696,     0.0217],
        [    0.0258,     0.4016,     0.5570,     0.0150,     0.0006],
        [    0.0390,     0.0796,     0.3871,     0.4298,     0.0644],
        [    0.0003,     0.0053,     0.3184,     0.5996,     0.0765],
        [    0.0273,     0.5774,     0.3826,     0.0121,     0.0006],
        [    0.0105,     0.1496,     0.7514,     0.0860,     0.0025],
        [    0.0002,     0.0001,     0.0016,     0.2146,     0.7834],
        [    0.0000,     0.0001,     0.0435,     0.8942,     0.0622],
        [    0.0826,     0.4626,     0.4393,     0.0145,     0.0009],
        [    0.0053,     0.2746,     0.3823,     0.2985,     0.0393]],
       device='cuda:1')
Metric:  tensor(0.6250, device='cuda:1')
------------------------
Mean loss[0.9261952450270767] | Mean metric[0.6032210834553441]
Stupid loss[0.0] | Naive soulution metric[0.2]
EPOCH 4
--------------
Labels:  tensor([1, 1, 2, 4, 2, 4, 0, 2, 3, 2, 0, 1, 1, 3, 2, 0], device='cuda:0')
Preds:  tensor([1, 2, 2, 4, 0, 4, 0, 4, 4, 2, 0, 2, 0, 3, 4, 1], device='cuda:0')
Outputs:  tensor([[    0.2539,     0.5352,     0.2104,     0.0005,     0.0000],
        [    0.0888,     0.3619,     0.4273,     0.0851,     0.0370],
        [    0.0001,     0.0028,     0.9957,     0.0014,     0.0000],
        [    0.0001,     0.0002,     0.0003,     0.0466,     0.9528],
        [    0.7471,     0.1827,     0.0664,     0.0034,     0.0004],
        [    0.0003,     0.0001,     0.0004,     0.0154,     0.9838],
        [    0.9830,     0.0168,     0.0001,     0.0000,     0.0000],
        [    0.0001,     0.0000,     0.0013,     0.1139,     0.8847],
        [    0.0000,     0.0000,     0.0033,     0.3747,     0.6219],
        [    0.0581,     0.4051,     0.5317,     0.0050,     0.0000],
        [    0.4068,     0.3372,     0.2150,     0.0403,     0.0007],
        [    0.0120,     0.1799,     0.7212,     0.0856,     0.0013],
        [    0.7180,     0.2156,     0.0400,     0.0076,     0.0188],
        [    0.0017,     0.0026,     0.0395,     0.5978,     0.3584],
        [    0.0088,     0.0018,     0.0052,     0.0204,     0.9638],
        [    0.0889,     0.5615,     0.3355,     0.0141,     0.0001]],
       device='cuda:0')
Metric:  tensor(0.5000, device='cuda:0')
------------------------
Mean loss[0.9332406294380763] | Mean metric[0.6061188384577842]
Stupid loss[0.0] | Naive soulution metric[0.2]
EPOCH 4
--------------
Labels:  tensor([4, 4, 2, 0, 0, 4, 4, 1, 4, 2, 0, 1, 1, 2, 2, 1], device='cuda:1')
Preds:  tensor([4, 4, 1, 3, 0, 4, 4, 1, 4, 2, 3, 1, 2, 1, 2, 2], device='cuda:1')
Outputs:  tensor([[    0.0010,     0.0004,     0.0061,     0.0923,     0.9002],
        [    0.0011,     0.0007,     0.0046,     0.1337,     0.8599],
        [    0.4297,     0.4984,     0.0691,     0.0026,     0.0002],
        [    0.0005,     0.0028,     0.0970,     0.5488,     0.3509],
        [    0.4560,     0.1939,     0.2311,     0.0704,     0.0486],
        [    0.0020,     0.0012,     0.0044,     0.0352,     0.9572],
        [    0.0008,     0.0005,     0.0074,     0.1932,     0.7981],
        [    0.1927,     0.6393,     0.1671,     0.0009,     0.0000],
        [    0.0001,     0.0002,     0.0077,     0.1984,     0.7936],
        [    0.0554,     0.1984,     0.5766,     0.1616,     0.0081],
        [    0.0007,     0.0107,     0.3281,     0.5917,     0.0689],
        [    0.3098,     0.3726,     0.2480,     0.0537,     0.0160],
        [    0.0030,     0.0706,     0.9069,     0.0192,     0.0003],
        [    0.1911,     0.5328,     0.2671,     0.0089,     0.0001],
        [    0.0291,     0.3266,     0.4276,     0.2027,     0.0140],
        [    0.0182,     0.3365,     0.6234,     0.0216,     0.0004]],
       device='cuda:1')
Metric:  tensor(0.6250, device='cuda:1')
------------------------
Mean loss[0.9300561165187113] | Mean metric[0.6012384089799903]
Stupid loss[0.0] | Naive soulution metric[0.2]
EPOCH 4
--------------
Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
EPOCH 4
--------------
Step[500] | Loss[0.6453540921211243] | Lr[8.000000000000003e-08]
Step[500] | Loss[0.45251449942588806] | Lr[8.000000000000003e-08]
Step[500] | Loss[0.535637617111206] | Lr[8.000000000000003e-08]
Step[500] | Loss[0.7805356979370117] | Lr[8.000000000000003e-08]
Step[1000] | Loss[0.7190725207328796] | Lr[8.000000000000003e-08]
Step[1000] | Loss[0.695747435092926] | Lr[8.000000000000003e-08]
Step[1000] | Loss[0.8053614497184753] | Lr[8.000000000000003e-08]
Step[1000] | Loss[0.9201666116714478] | Lr[8.000000000000003e-08]
Step[1500] | Loss[0.5803354978561401] | Lr[8.000000000000003e-08]
Step[1500] | Loss[0.7000271677970886] | Lr[8.000000000000003e-08]
Step[1500] | Loss[0.7367249727249146] | Lr[8.000000000000003e-08]
Step[1500] | Loss[0.8239904642105103] | Lr[8.000000000000003e-08]
Step[2000] | Loss[0.596989631652832] | Lr[8.000000000000003e-08]
Step[2000] | Loss[0.678735613822937] | Lr[8.000000000000003e-08]
Step[2000] | Loss[1.0082807540893555] | Lr[8.000000000000003e-08]
Step[2000] | Loss[0.5715625882148743] | Lr[8.000000000000003e-08]
Step[2500] | Loss[0.5078453421592712] | Lr[8.000000000000003e-08]
Step[2500] | Loss[0.7512864470481873] | Lr[8.000000000000003e-08]
Step[2500] | Loss[0.5363385081291199] | Lr[8.000000000000003e-08]
Step[2500] | Loss[0.6734621524810791] | Lr[8.000000000000003e-08]
Step[3000] | Loss[0.655681312084198] | Lr[8.000000000000003e-08]
Step[3000] | Loss[0.8483362793922424] | Lr[8.000000000000003e-08]
Step[3000] | Loss[0.9580681920051575] | Lr[8.000000000000003e-08]
Step[3000] | Loss[0.7204206585884094] | Lr[8.000000000000003e-08]
Step[3500] | Loss[0.8877910375595093] | Lr[8.000000000000003e-08]
Step[3500] | Loss[0.3017788827419281] | Lr[8.000000000000003e-08]
Step[3500] | Loss[0.5375449061393738] | Lr[8.000000000000003e-08]
Step[3500] | Loss[0.47503092885017395] | Lr[8.000000000000003e-08]
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** JOB 60797 ON gpu003 CANCELLED AT 2023-11-10T22:58:36 ***
slurmstepd: error: *** STEP 60797.1 ON gpu003 CANCELLED AT 2023-11-10T22:58:36 ***
WARNING:torch.distributed.elastic.agent.server.api:Received 15 death signal, shutting down workers
WARNING:torch.distributed.elastic.agent.server.api:Received 15 death signal, shutting down workers
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 503225 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 269005 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 503226 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 269006 closing signal SIGTERM
